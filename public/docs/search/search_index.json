{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Common Knowledge Scout Documentation","text":"<p>Welcome to the Common Knowledge Scout documentation.</p>"},{"location":"index.html#quick-start","title":"Quick Start","text":"<ul> <li>Use Cases - Step-by-step guides for common tasks</li> <li>Architecture - System architecture and module structure</li> <li>Analysis - Current runtime behavior and decisions</li> <li>Reference - Complete file index and API reference</li> </ul>"},{"location":"index.html#documentation-structure","title":"Documentation Structure","text":""},{"location":"index.html#use-cases","title":"Use Cases","text":"<p>Practical guides for end users: - Library Setup - File Transformation (PDF, Audio, Video) - Web Scraping &amp; Event Import - Publishing &amp; Gallery - Chat &amp; Story Mode - Batch Operations</p>"},{"location":"index.html#architecture","title":"Architecture","text":"<p>System design and module documentation: - Module Hierarchy - Dependency Graph</p>"},{"location":"index.html#analysis","title":"Analysis","text":"<p>Current runtime behavior and validated decisions: - Shadow-Twin v2-only runtime - Wizard &amp; External Jobs (contracts) - Ingestion (MongoDB Vector Search) - Storage providers (filesystem/OneDrive)  - Audio/Video transcript-only when no template is selected</p>"},{"location":"index.html#reference","title":"Reference","text":"<p>Technical reference documentation: - File Index - Module Documentation (Storage, Library, Chat)</p>"},{"location":"index.html#getting-help","title":"Getting Help","text":"<p>For detailed technical information, see the Reference Documentation.</p>"},{"location":"index.html#notes","title":"Notes","text":"<ul> <li><code>docs/_analysis/</code> contains short-lived scratch notes and is intentionally not linked from MkDocs navigation.</li> </ul>"},{"location":"Frage%20stellung.html","title":"Frage stellung","text":"<p>Gesucht wird eine konzeptionelle Beschreibung der Webseite, die erkl\u00e4rt,</p> <ul> <li> <p>wie die Produktwelt auf der Landing Page vermittelt wird,</p> </li> <li> <p>wie Nutzer gezielt und niederschwellig in den Konfigurator gef\u00fchrt werden</p> </li> <li> <p>und wie das begleitende Stil- und Beratungserlebnis aufgebaut ist.</p> </li> </ul> <p>Der Einstiegspunkt ist die Landing Page mit einem klaren prim\u00e4ren Call to Action: Start in den Konfigurator. Nach dem Einstieg soll eine kurze Begr\u00fc\u00dfungsseite die kommenden Schritte erkl\u00e4ren und Erwartungssicherheit geben (Produkt ausw\u00e4hlen, konfigurieren, Mehrwerte entdecken).</p> <p>Der Konfigurator selbst f\u00fchrt Schritt f\u00fcr Schritt durch Produkt, Varianten und Eigenschaften. Die abschlie\u00dfende Zusammenfassung markiert nicht das Ende, sondern den \u00dcbergang in eine neue Phase: eine zentrale \u201eStartseite\u201c des Erlebnisses, auf der zus\u00e4tzliche Mehrwerte sichtbar werden (Stilberatung, Konfiguration speichern, H\u00e4ndler finden, Termin vereinbaren).</p> <p>Diese Seite ist als scrollende \u00dcbersichtsseite gedacht, auf der die einzelnen Features erkl\u00e4rt und emotional aufgeladen werden. Der Einstieg in einzelne Funktionen erfolgt jeweils \u00fcber klar abgegrenzte Interaktionsmodi (z. B. modal / gef\u00fchrtes Fenster), inklusive einer Lead-Abfrage zum passenden Zeitpunkt.</p> <p>Wichtig ist eine klare Trennung der Phasen:</p> <ul> <li> <p>Scrollende Seiten f\u00fcr Orientierung, Inspiration und \u00dcberblick</p> </li> <li> <p>Gef\u00fchrte, nicht-scrollende Flows f\u00fcr Entscheidungen und Beratung</p> </li> </ul> <p>Die zentrale Frage lautet: Wie l\u00e4sst sich diese Dramaturgie aus Orientierung, Entscheidung und Beratung konzeptuell so strukturieren, dass Nutzer jederzeit verstehen, wo sie sich befinden und was der n\u00e4chste sinnvolle Schritt ist?</p>"},{"location":"Frage%20stellung.html#concept-paper","title":"Concept Paper","text":"<p>Gef\u00fchrtes Produkterlebnis &amp; Stilberatung im digitalen Raum</p>"},{"location":"Frage%20stellung.html#1-ausgangspunkt-zielsetzung","title":"1. Ausgangspunkt &amp; Zielsetzung","text":"<p>Das digitale Erlebnis dient nicht dem direkten Verkauf, sondern dem Aufbau von Vertrauen, Orientierung und Beziehung bei einer hochpreisigen Kaufentscheidung. Die Webseite ersetzt kein Verkaufsgespr\u00e4ch, sondern \u00fcbersetzt es in eine digitale, gef\u00fchrte Form.</p> <p>Ziel ist es, Nutzer:innen:</p> <ul> <li> <p>sicher durch eine komplexe Produktwelt zu f\u00fchren,</p> </li> <li> <p>emotional f\u00fcr ihr pers\u00f6nliches Ergebnis zu begeistern,</p> </li> <li> <p>und am H\u00f6hepunkt dieses Erlebnisses eine freiwillige Kontaktaufnahme zu erm\u00f6glichen.</p> </li> </ul> <p>Der Konfigurator ist dabei kein technisches Werkzeug, sondern das Herzst\u00fcck eines Beratungserlebnisses.</p>"},{"location":"Frage%20stellung.html#2-grundidee-des-nutzererlebnisses","title":"2. Grundidee des Nutzererlebnisses","text":"<p>Das gesamte Erlebnis folgt einer klaren Dramaturgie:</p> <ol> <li> <p>Einladung &amp; Orientierung</p> </li> <li> <p>Gef\u00fchrte Entscheidung</p> </li> <li> <p>Belohnung &amp; Vertiefung</p> </li> <li> <p>Beziehungsaufbau</p> </li> </ol> <p>Wichtig ist die klare Trennung zwischen zwei Erlebnis-Modi:</p> <ul> <li> <p>Erkl\u00e4render, ruhiger Modus (scrollende Seiten)     \u2192 Vertrauen, Verst\u00e4ndnis, Inspiration</p> </li> <li> <p>Fokussierter Entscheidungsmodus (gef\u00fchrte Fenster / Wizard)     \u2192 Auswahl, Konzentration, Sicherheit</p> </li> </ul> <p>Der Wechsel zwischen diesen Modi macht jederzeit sp\u00fcrbar, wo sich der Nutzer gerade befindet und was von ihm erwartet wird.</p>"},{"location":"Frage%20stellung.html#3-phase-1-landing-page-einladung-in-die-produktwelt","title":"3. Phase 1 \u2013 Landing Page: Einladung in die Produktwelt","text":"<p>Die Landing Page ist der erste Ber\u00fchrungspunkt mit der Produktwelt. Sie erkl\u00e4rt nicht den gesamten Prozess, sondern l\u00e4dt bewusst in ein gef\u00fchrtes Erlebnis ein.</p>"},{"location":"Frage%20stellung.html#funktion-der-landing-page","title":"Funktion der Landing Page","text":"<ul> <li> <p>Emotionale Positionierung im Premiumsegment</p> </li> <li> <p>Aufbau von Vertrauen und Erwartung</p> </li> <li> <p>Reduktion von Unsicherheit</p> </li> </ul>"},{"location":"Frage%20stellung.html#kernaussagen","title":"Kernaussagen","text":"<ul> <li> <p>Hochwertige M\u00f6bel sind eine Frage von Stil, Beratung und Sicherheit</p> </li> <li> <p>Der Weg zum passenden Produkt ist gef\u00fchrt</p> </li> <li> <p>Am Ende steht ein pers\u00f6nliches Ergebnis</p> </li> </ul>"},{"location":"Frage%20stellung.html#primarer-call-to-action","title":"Prim\u00e4rer Call to Action","text":"<p>Der wichtigste Handlungsimpuls ist:</p> <p>Einstieg in den Konfigurator</p> <p>Nicht als Kaufentscheidung, sondern als Start einer Reise:</p> <p>\u201eJetzt konfigurieren &amp; deinen Stil entdecken\u201c</p>"},{"location":"Frage%20stellung.html#4-phase-2-begruungsseite-orientierung-versprechen","title":"4. Phase 2 \u2013 Begr\u00fc\u00dfungsseite: Orientierung &amp; Versprechen","text":"<p>Nach dem Klick auf den Call to Action folgt bewusst kein sofortiger Konfigurator, sondern eine kurze Begr\u00fc\u00dfungs- und Einf\u00fchrungsseite.</p>"},{"location":"Frage%20stellung.html#zweck-dieser-seite","title":"Zweck dieser Seite","text":"<ul> <li> <p>Erwartungen kl\u00e4ren</p> </li> <li> <p>Hemmschwellen abbauen</p> </li> <li> <p>Mehrwert sichtbar machen</p> </li> </ul>"},{"location":"Frage%20stellung.html#inhaltlich-wird-vermittelt","title":"Inhaltlich wird vermittelt:","text":"<ul> <li> <p>Der Nutzer wird Schritt f\u00fcr Schritt begleitet</p> </li> <li> <p>Es gibt kein \u201erichtig\u201c oder \u201efalsch\u201c</p> </li> <li> <p>Am Ende warten konkrete Vorteile (\u201eZuckerln\u201c)</p> </li> </ul>"},{"location":"Frage%20stellung.html#die-drei-schritte","title":"Die drei Schritte","text":"<ol> <li> <p>Produkt finden     Einstieg in die Auswahl des passenden M\u00f6belst\u00fccks</p> </li> <li> <p>Stil entdecken     Farben, Materialien und Wirkung im Raum erleben</p> </li> <li> <p>Mehrwert erhalten     Stilberatung, Speichern, H\u00e4ndler finden, Ergebnis sichern</p> </li> </ol> <p>Diese Vorteile werden angeteasert, nicht erkl\u00e4rt. Der Fokus liegt auf Vorfreude, nicht auf Details.</p>"},{"location":"Frage%20stellung.html#5-phase-3-konfigurator-gefuhrte-entscheidung","title":"5. Phase 3 \u2013 Konfigurator: Gef\u00fchrte Entscheidung","text":"<p>Mit dem Start des Konfigurators wechselt das Erlebnis in einen klar fokussierten Entscheidungsmodus.</p>"},{"location":"Frage%20stellung.html#charakter-des-konfigurators","title":"Charakter des Konfigurators","text":"<ul> <li> <p>Schrittweise F\u00fchrung</p> </li> <li> <p>Keine Scroll-Seite</p> </li> <li> <p>Konzentration auf eine Aufgabe zur Zeit</p> </li> </ul> <p>Der Konfigurator f\u00fchlt sich an wie ein pers\u00f6nliches Beratungsgespr\u00e4ch:</p> <ul> <li> <p>ruhig</p> </li> <li> <p>sicher</p> </li> <li> <p>nachvollziehbar</p> </li> </ul> <p>Wichtig:</p> <ul> <li> <p>Keine Lead-Abfrage</p> </li> <li> <p>Kein Verkaufsdruck</p> </li> <li> <p>Keine Ablenkung</p> </li> </ul> <p>Der Nutzer soll das Gef\u00fchl haben:</p> <p>\u201eIch kann mich hier ausprobieren, ohne mich festlegen zu m\u00fcssen.\u201c</p>"},{"location":"Frage%20stellung.html#6-phase-4-summary-ubergang-statt-abschluss","title":"6. Phase 4 \u2013 Summary: \u00dcbergang statt Abschluss","text":"<p>Die Zusammenfassung ist kein Checkout und kein Ende.</p> <p>Sie ist der emotionale Abschluss der Konfiguration und gleichzeitig der \u00dcbergang in den n\u00e4chsten Abschnitt.</p>"},{"location":"Frage%20stellung.html#bedeutung-der-summary","title":"Bedeutung der Summary","text":"<ul> <li> <p>Best\u00e4tigung des Erreichten</p> </li> <li> <p>Sichtbarmachen des pers\u00f6nlichen Ergebnisses</p> </li> <li> <p>Aufbau von Stolz und Identifikation</p> </li> </ul>"},{"location":"Frage%20stellung.html#zentraler-button","title":"Zentraler Button","text":"<p>\u201eJetzt geht\u2019s los\u201c</p> <p>Dieser Button markiert bewusst den Wechsel:</p> <ul> <li> <p>von Auswahl \u2192 zu Vertiefung</p> </li> <li> <p>von Konfiguration \u2192 zu Erlebnis</p> </li> </ul>"},{"location":"Frage%20stellung.html#7-phase-5-starting-page-erlebnis-mehrwert","title":"7. Phase 5 \u2013 Starting Page: Erlebnis &amp; Mehrwert","text":"<p>Nach dem Klick auf \u201eJetzt geht\u2019s los\u201c \u00f6ffnet sich wieder eine scrollende Seite \u2013 die eigentliche Erlebnis- und Feature-Seite.</p>"},{"location":"Frage%20stellung.html#rolle-dieser-seite","title":"Rolle dieser Seite","text":"<ul> <li> <p>Vertiefung des emotionalen H\u00f6hepunkts</p> </li> <li> <p>Sichtbarmachen des Mehrwerts</p> </li> <li> <p>Einladung zur n\u00e4chsten Interaktion</p> </li> </ul>"},{"location":"Frage%20stellung.html#aufbau","title":"Aufbau","text":"<ul> <li> <p>Kurze Einordnung: \u201eBasierend auf deiner Konfiguration\u201c</p> </li> <li> <p>Danach eine Abfolge von Features:</p> <ul> <li> <p>Stilberatung</p> </li> <li> <p>Konfiguration speichern</p> </li> <li> <p>H\u00e4ndler finden</p> </li> <li> <p>Termin vereinbaren</p> </li> <li> <p>Ergebnisse teilen</p> </li> </ul> </li> </ul> <p>Jedes Feature wird als n\u00e4chster sinnvoller Schritt pr\u00e4sentiert \u2013 nicht als Pflicht.</p>"},{"location":"Frage%20stellung.html#8-lead-logik-beziehung-statt-barriere","title":"8. Lead-Logik: Beziehung statt Barriere","text":"<p>Die Lead-Abfrage erfolgt nicht am Anfang, sondern am H\u00f6hepunkt der Motivation.</p>"},{"location":"Frage%20stellung.html#prinzip","title":"Prinzip","text":"<ul> <li> <p>Klick auf ein Feature \u00f6ffnet erneut den gef\u00fchrten Modus</p> </li> <li> <p>Erst dort erscheint eine dezente Lead-Blende</p> </li> </ul> <p>Begr\u00fcndung aus Nutzersicht:</p> <p>\u201eDamit wir dein Ergebnis speichern / deine Beratung vorbereiten k\u00f6nnen \u2026\u201c</p> <p>Der Lead ist:</p> <ul> <li> <p>freiwillig</p> </li> <li> <p>logisch</p> </li> <li> <p>nutzenorientiert</p> </li> </ul> <p>Nicht:</p> <ul> <li> <p>aggressiv</p> </li> <li> <p>versteckt</p> </li> <li> <p>vorzeitig</p> </li> </ul>"},{"location":"Frage%20stellung.html#9-klarer-rhythmus-durch-moduswechsel","title":"9. Klarer Rhythmus durch Moduswechsel","text":"<p>Das Erlebnis folgt einem wiederkehrenden Muster:</p> <ul> <li> <p>Scrollen = Erkunden &amp; Verstehen</p> </li> <li> <p>Fenster/Wizard = Entscheiden &amp; Arbeiten</p> </li> </ul> <p>Diese Klarheit reduziert kognitive Last und st\u00e4rkt das Vertrauen.</p>"},{"location":"Frage%20stellung.html#10-zusammenfassung-der-leitprinzipien","title":"10. Zusammenfassung der Leitprinzipien","text":"<ul> <li> <p>Die Webseite verkauft kein Produkt, sondern Sicherheit</p> </li> <li> <p>Der Konfigurator ist ein Beratungsgespr\u00e4ch</p> </li> <li> <p>Der Lead ist der H\u00f6hepunkt, nicht die Eintrittsbedingung</p> </li> <li> <p>Klare Phasen schaffen Orientierung</p> </li> <li> <p>Moduswechsel machen Entscheidungen bewusst</p> </li> </ul> <p>Wenn du m\u00f6chtest, kann ich daraus als N\u00e4chstes:</p> <ul> <li> <p>eine Executive Summary (1 Seite) ableiten</p> </li> <li> <p>eine grafische User-Flow-Darstellung erstellen</p> </li> <li> <p>oder das Concept Paper direkt auf eure bestehende Seite mappen (Ist \u2192 Soll).</p> </li> </ul>"},{"location":"github-branch-protection-setup.html","title":"GitHub Branch Protection Setup - Schritt-f\u00fcr-Schritt Anleitung","text":"<p>Diese Anleitung erkl\u00e4rt, wie du Branch Protection Rules f\u00fcr den <code>master</code>-Branch einrichtest, sodass nur du direkt committen kannst, w\u00e4hrend GitHub Actions weiterhin automatisch pushen k\u00f6nnen.</p>"},{"location":"github-branch-protection-setup.html#voraussetzungen","title":"Voraussetzungen","text":"<ul> <li>\u2705 Repository auf GitHub erstellt</li> <li>\u2705 Repository als \u00f6ffentlich gesetzt</li> <li>\u2705 Lokales Repository mit GitHub verbunden</li> <li>\u2705 Du bist Repository-Owner oder hast Admin-Rechte</li> </ul>"},{"location":"github-branch-protection-setup.html#schritt-1-repository-auf-github-veroffentlichen","title":"Schritt 1: Repository auf GitHub ver\u00f6ffentlichen","text":""},{"location":"github-branch-protection-setup.html#11-repository-erstellen-falls-noch-nicht-vorhanden","title":"1.1 Repository erstellen (falls noch nicht vorhanden)","text":"<ol> <li>Gehe zu GitHub</li> <li>Klicke auf \"+\" (oben rechts) \u2192 \"New repository\"</li> <li>Repository-Name: <code>CommonKnowledgeScout</code></li> <li>Owner: <code>bCommonsLAB</code></li> <li>Beschreibung: \"Common Knowledge Scout - Modern Document Management System\"</li> <li>Wichtig: W\u00e4hle \"Public\" aus</li> <li>NICHT \"Initialize with README\" aktivieren (du hast bereits ein lokales Repo)</li> <li>Klicke auf \"Create repository\"</li> </ol>"},{"location":"github-branch-protection-setup.html#12-lokales-repository-mit-github-verbinden","title":"1.2 Lokales Repository mit GitHub verbinden","text":"<p>Falls noch nicht geschehen, f\u00fchre im Terminal aus:</p> <pre><code># Pr\u00fcfe, ob remote bereits existiert\ngit remote -v\n\n# Falls nicht vorhanden, f\u00fcge GitHub-Repository hinzu\ngit remote add origin https://github.com/bCommonsLAB/CommonKnowledgeScout.git\n\n# Oder falls bereits vorhanden, aktualisiere die URL\ngit remote set-url origin https://github.com/bCommonsLAB/CommonKnowledgeScout.git\n\n# Pushe alle Branches und Tags\ngit push -u origin --all\ngit push -u origin --tags\n</code></pre>"},{"location":"github-branch-protection-setup.html#schritt-2-branch-protection-rules-einrichten","title":"Schritt 2: Branch Protection Rules einrichten","text":""},{"location":"github-branch-protection-setup.html#21-navigation-zu-den-branch-settings","title":"2.1 Navigation zu den Branch Settings","text":"<ol> <li>Gehe zu deinem Repository auf GitHub: <code>https://github.com/bCommonsLAB/CommonKnowledgeScout</code></li> <li>Klicke auf \"Settings\" (oben im Repository-Men\u00fc)</li> <li>Im linken Men\u00fc: \"Branches\" (unter \"Code and automation\")</li> </ol>"},{"location":"github-branch-protection-setup.html#22-branch-protection-rule-erstellen","title":"2.2 Branch Protection Rule erstellen","text":"<ol> <li>Unter \"Branch protection rules\" findest du einen Button \"Add rule\" \u2192 Klicke darauf</li> <li>Im Feld \"Branch name pattern\" gib ein: <code>master</code></li> <li>Es erscheint eine Vorschau: \"This rule will apply to: 1 branch\"</li> </ol>"},{"location":"github-branch-protection-setup.html#23-wichtige-einstellungen-konfigurieren","title":"2.3 Wichtige Einstellungen konfigurieren","text":""},{"location":"github-branch-protection-setup.html#option-1-restrict-who-can-push-to-matching-branches","title":"\u2705 Option 1: \"Restrict who can push to matching branches\"","text":"<p>Das ist die Hauptregel f\u00fcr deinen Anwendungsfall!</p> <ol> <li>Aktiviere das Kontrollk\u00e4stchen: \"Restrict who can push to matching branches\"</li> <li>Klicke auf \"Select people and teams\"</li> <li>Suche nach deinem GitHub-Username (z. B. <code>peter-aichner</code> oder wie auch immer dein GitHub-Username lautet)</li> <li>W\u00e4hle dich selbst aus</li> <li>Klicke auf \"Save changes\"</li> </ol> <p>Ergebnis: Nur du kannst jetzt direkt auf <code>master</code> pushen.</p>"},{"location":"github-branch-protection-setup.html#option-2-github-actions-bypass-einrichten","title":"\u2705 Option 2: GitHub Actions Bypass einrichten","text":"<p>Wichtig: Dein Workflow (<code>ci-main.yml</code>) pusht automatisch auf <code>master</code>. Damit das weiterhin funktioniert:</p> <ol> <li>Scrolle nach unten zu \"Rules applied to everyone including administrators\"</li> <li>Aktiviere: \"Allow specified actors to bypass required pull requests\"</li> <li>Klicke auf \"Select actors\"</li> <li>Suche nach: <code>github-actions[bot]</code></li> <li>W\u00e4hle <code>github-actions[bot]</code> aus</li> <li>Klicke auf \"Save changes\"</li> </ol> <p>Alternative: Falls die Option oben nicht verf\u00fcgbar ist: - Aktiviere: \"Allow force pushes\" \u2192 \"Specify who can force push\" \u2192 <code>github-actions[bot]</code> - Aktiviere: \"Allow deletions\" \u2192 \"Specify who can delete\" \u2192 <code>github-actions[bot]</code></p>"},{"location":"github-branch-protection-setup.html#option-3-do-not-allow-bypassing-the-above-settings","title":"\u2705 Option 3: \"Do not allow bypassing the above settings\"","text":"<p>Sehr wichtig f\u00fcr maximale Sicherheit:</p> <ol> <li>Aktiviere: \"Do not allow bypassing the above settings\"</li> <li>Wichtig: Stelle sicher, dass <code>github-actions[bot]</code> in den Bypass-Regeln enthalten ist, sonst funktionieren deine Workflows nicht mehr!</li> </ol>"},{"location":"github-branch-protection-setup.html#schritt-3-optionale-aber-empfohlene-einstellungen","title":"Schritt 3: Optionale, aber empfohlene Einstellungen","text":""},{"location":"github-branch-protection-setup.html#31-pull-request-requirements","title":"3.1 Pull Request Requirements","text":"<p>Falls du in Zukunft auch Pull Requests nutzen m\u00f6chtest:</p> <ol> <li>Aktiviere: \"Require a pull request before merging\"</li> <li>\"Require approvals\": <code>1</code></li> <li>\"Dismiss stale pull request approvals when new commits are pushed\": \u2705</li> <li>\"Require review from Code Owners\": Optional</li> </ol>"},{"location":"github-branch-protection-setup.html#32-status-checks","title":"3.2 Status Checks","text":"<p>Falls du automatische Checks einrichten m\u00f6chtest:</p> <ol> <li>Aktiviere: \"Require status checks to pass before merging\"</li> <li>\"Require branches to be up to date before merging\": \u2705</li> <li>W\u00e4hle die Checks aus, die durchlaufen m\u00fcssen (z. B. <code>lint-check</code>)</li> </ol>"},{"location":"github-branch-protection-setup.html#33-weitere-optionen","title":"3.3 Weitere Optionen","text":"<ul> <li>\"Require conversation resolution before merging\": \u2705 (empfohlen)</li> <li>\"Require linear history\": Optional</li> <li>\"Require signed commits\": Optional (erfordert GPG-Setup)</li> </ul>"},{"location":"github-branch-protection-setup.html#schritt-4-regel-speichern","title":"Schritt 4: Regel speichern","text":"<ol> <li>Scrolle nach oben oder unten</li> <li>Klicke auf \"Create\" (oder \"Save changes\" falls du eine bestehende Regel bearbeitest)</li> <li>Die Regel ist jetzt aktiv!</li> </ol>"},{"location":"github-branch-protection-setup.html#schritt-5-testen-der-konfiguration","title":"Schritt 5: Testen der Konfiguration","text":""},{"location":"github-branch-protection-setup.html#51-test-direkter-push-sollte-funktionieren","title":"5.1 Test: Direkter Push (sollte funktionieren)","text":"<pre><code># Erstelle einen Test-Commit\necho \"# Test\" &gt;&gt; TEST.md\ngit add TEST.md\ngit commit -m \"Test: Branch Protection\"\ngit push origin master\n</code></pre> <p>Erwartetes Ergebnis: \u2705 Push sollte erfolgreich sein (du bist der erlaubte User)</p>"},{"location":"github-branch-protection-setup.html#52-test-github-actions-sollte-funktionieren","title":"5.2 Test: GitHub Actions (sollte funktionieren)","text":"<ol> <li>Gehe zu \"Actions\" im Repository</li> <li>F\u00fchre den Workflow <code>ci-master</code> manuell aus (falls <code>workflow_dispatch</code> aktiviert ist)</li> <li>Oder pushe einen Commit, der den Workflow triggert</li> </ol> <p>Erwartetes Ergebnis: \u2705 Workflow sollte erfolgreich pushen k\u00f6nnen (dank Bypass-Regel)</p>"},{"location":"github-branch-protection-setup.html#53-test-anderer-user-sollte-fehlschlagen","title":"5.3 Test: Anderer User (sollte fehlschlagen)","text":"<p>Falls du einen zweiten GitHub-Account hast oder jemand anderes testet:</p> <pre><code># Als anderer User versuchen zu pushen\ngit push origin master\n</code></pre> <p>Erwartetes Ergebnis: \u274c Push sollte mit Fehler fehlschlagen: <pre><code>remote: error: GH006: Protected branch update failed for refs/heads/master.\nremote: error: You are not allowed to push code to master in this repository\n</code></pre></p>"},{"location":"github-branch-protection-setup.html#schritt-6-workflow-berechtigungen-prufen","title":"Schritt 6: Workflow-Berechtigungen pr\u00fcfen","text":"<p>Dein Workflow (<code>ci-main.yml</code>) hat bereits die richtigen Berechtigungen:</p> <pre><code>permissions:\n  contents: write  # \u2705 Erlaubt das Pushen\n</code></pre> <p>Das ist korrekt! Keine \u00c4nderungen n\u00f6tig.</p>"},{"location":"github-branch-protection-setup.html#zusammenfassung-der-finalen-konfiguration","title":"Zusammenfassung der finalen Konfiguration","text":"<pre><code>Branch: master\n\n\u2705 Restrict who can push to matching branches\n   \u2192 Nur: [Dein GitHub-Username]\n\n\u2705 Allow specified actors to bypass required pull requests\n   \u2192 github-actions[bot]\n\n\u2705 Do not allow bypassing the above settings\n   \u2192 Aktiviert\n\nOptional:\n\u2705 Require a pull request before merging\n\u2705 Require status checks to pass before merging\n\u2705 Require conversation resolution before merging\n</code></pre>"},{"location":"github-branch-protection-setup.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"github-branch-protection-setup.html#problem-github-actions-konnen-nicht-pushen","title":"Problem: GitHub Actions k\u00f6nnen nicht pushen","text":"<p>L\u00f6sung: 1. Gehe zu Settings \u2192 Branches 2. \u00d6ffne die <code>master</code>-Regel 3. Pr\u00fcfe, ob <code>github-actions[bot]</code> in den Bypass-Regeln enthalten ist 4. Falls nicht, f\u00fcge es hinzu</p>"},{"location":"github-branch-protection-setup.html#problem-do-not-allow-bypassing-blockiert-github-actions","title":"Problem: \"Do not allow bypassing\" blockiert GitHub Actions","text":"<p>L\u00f6sung: - Stelle sicher, dass <code>github-actions[bot]</code> vor dem Aktivieren von \"Do not allow bypassing\" hinzugef\u00fcgt wurde - Die Bypass-Regel muss explizit <code>github-actions[bot]</code> enthalten</p>"},{"location":"github-branch-protection-setup.html#problem-ich-kann-selbst-nicht-pushen","title":"Problem: Ich kann selbst nicht pushen","text":"<p>L\u00f6sung: 1. Pr\u00fcfe, ob dein GitHub-Username korrekt in \"Restrict who can push\" eingetragen ist 2. Pr\u00fcfe, ob du Repository-Admin-Rechte hast 3. Pr\u00fcfe, ob \"Do not allow bypassing\" aktiviert ist und du trotzdem in der Liste stehst</p>"},{"location":"github-branch-protection-setup.html#nachste-schritte","title":"N\u00e4chste Schritte","text":"<p>Nach erfolgreicher Einrichtung:</p> <ol> <li>\u2705 Repository ist \u00f6ffentlich</li> <li>\u2705 Nur du kannst auf <code>master</code> committen</li> <li>\u2705 GitHub Actions k\u00f6nnen weiterhin automatisch pushen</li> <li>\u2705 Andere k\u00f6nnen das Repository forken und Pull Requests erstellen</li> <li>\u2705 Lizenz-Dateien sind vorhanden (LICENSE, LICENSE_CONTENT.txt)</li> </ol> <p>Das Repository ist jetzt bereit f\u00fcr die Open-Source-Ver\u00f6ffentlichung! \ud83c\udf89</p>"},{"location":"github-branch-protection-setup.html#referenzen","title":"Referenzen","text":"<ul> <li>GitHub Docs: About protected branches</li> <li>GitHub Docs: Configuring protected branches</li> <li>GitHub Docs: Bypassing branch protection</li> </ul>"},{"location":"mongodb-indexes.html","title":"MongoDB Indexe f\u00fcr QueryLog Collection","text":""},{"location":"mongodb-indexes.html#ubersicht","title":"\u00dcbersicht","text":"<p>Die <code>queries</code> Collection verwendet mehrere optimierte Indexe f\u00fcr schnelle Cache-Abfragen.</p>"},{"location":"mongodb-indexes.html#indexe","title":"Indexe","text":""},{"location":"mongodb-indexes.html#basis-indexe","title":"Basis-Indexe","text":"<ul> <li><code>queryId_unique</code>: Eindeutiger Index auf <code>queryId</code></li> <li><code>library_createdAt_desc</code>: Index auf <code>libraryId</code> und <code>createdAt</code> (absteigend)</li> <li><code>user_createdAt_desc</code>: Index auf <code>userEmail</code> und <code>createdAt</code> (absteigend)</li> <li><code>sessionId_createdAt_desc</code>: Index auf <code>sessionId</code> und <code>createdAt</code> (absteigend)</li> <li><code>chatId_createdAt_desc</code>: Index auf <code>chatId</code> und <code>createdAt</code> (absteigend)</li> </ul>"},{"location":"mongodb-indexes.html#cache-lookup-indexe-fur-toc-cache-abfragen","title":"Cache-Lookup-Indexe (f\u00fcr TOC-Cache-Abfragen)","text":""},{"location":"mongodb-indexes.html#fur-authentifizierte-nutzer","title":"F\u00fcr authentifizierte Nutzer","text":"<ul> <li><code>cache_lookup_user_toc</code>: Zusammengesetzter Index f\u00fcr vollst\u00e4ndige Cache-Abfragen</li> <li>Felder: <code>libraryId</code>, <code>question</code>, <code>userEmail</code>, <code>queryType</code>, <code>status</code>, <code>targetLanguage</code>, <code>character</code>, <code>socialContext</code>, <code>genderInclusive</code>, <code>retriever</code>, <code>createdAt</code></li> <li> <p>Partial Filter: Nur f\u00fcr Dokumente mit <code>userEmail</code></p> </li> <li> <p><code>cache_lookup_user_basic</code>: Fallback-Index f\u00fcr Basis-Abfragen</p> </li> <li>Felder: <code>libraryId</code>, <code>question</code>, <code>userEmail</code>, <code>queryType</code>, <code>status</code>, <code>createdAt</code></li> <li>Partial Filter: Nur f\u00fcr Dokumente mit <code>userEmail</code></li> </ul>"},{"location":"mongodb-indexes.html#fur-anonyme-nutzer","title":"F\u00fcr anonyme Nutzer","text":"<ul> <li><code>cache_lookup_session_toc</code>: Zusammengesetzter Index f\u00fcr vollst\u00e4ndige Cache-Abfragen</li> <li>Felder: <code>libraryId</code>, <code>question</code>, <code>sessionId</code>, <code>queryType</code>, <code>status</code>, <code>targetLanguage</code>, <code>character</code>, <code>socialContext</code>, <code>genderInclusive</code>, <code>retriever</code>, <code>createdAt</code></li> <li> <p>Partial Filter: Nur f\u00fcr Dokumente mit <code>sessionId</code></p> </li> <li> <p><code>cache_lookup_session_basic</code>: Fallback-Index f\u00fcr Basis-Abfragen</p> </li> <li>Felder: <code>libraryId</code>, <code>question</code>, <code>sessionId</code>, <code>queryType</code>, <code>status</code>, <code>createdAt</code></li> <li>Partial Filter: Nur f\u00fcr Dokumente mit <code>sessionId</code></li> </ul>"},{"location":"mongodb-indexes.html#index-uberprufung","title":"Index-\u00dcberpr\u00fcfung","text":""},{"location":"mongodb-indexes.html#indexe-in-mongodb-anzeigen","title":"Indexe in MongoDB anzeigen","text":"<pre><code>// In MongoDB Shell oder Compass\ndb.queries.getIndexes()\n</code></pre>"},{"location":"mongodb-indexes.html#index-performance-prufen","title":"Index-Performance pr\u00fcfen","text":"<pre><code>// Erkl\u00e4re eine Query, um zu sehen, welche Indexe verwendet werden\ndb.queries.find({\n  libraryId: \"...\",\n  question: \"...\",\n  userEmail: \"...\",\n  queryType: \"toc\",\n  status: { $in: [\"ok\", \"pending\"] }\n}).sort({ createdAt: -1 }).limit(1).explain(\"executionStats\")\n</code></pre>"},{"location":"mongodb-indexes.html#index-statistiken-anzeigen","title":"Index-Statistiken anzeigen","text":"<pre><code>// Zeige Statistiken f\u00fcr alle Indexe\ndb.queries.aggregate([{ $indexStats: {} }])\n</code></pre>"},{"location":"mongodb-indexes.html#performance-optimierung","title":"Performance-Optimierung","text":"<p>Die Cache-Abfragen verwenden: 1. Zusammengesetzte Indexe mit den h\u00e4ufigsten Filter-Feldern 2. Partial Filter Expressions, um Index-Gr\u00f6\u00dfe zu reduzieren 3. <code>limit(50)</code> in der Query, um die Anzahl der geladenen Dokumente zu begrenzen 4. Sortierung nach <code>createdAt: -1</code> f\u00fcr neueste Ergebnisse zuerst</p>"},{"location":"mongodb-indexes.html#wartung","title":"Wartung","text":"<p>Die Indexe werden automatisch beim ersten Zugriff auf die Collection erstellt. Falls Indexe manuell erstellt werden m\u00fcssen:</p> <pre><code>// In MongoDB Shell\ndb.queries.createIndex(\n  { \n    libraryId: 1, \n    question: 1, \n    userEmail: 1, \n    queryType: 1, \n    status: 1, \n    targetLanguage: 1,\n    character: 1,\n    socialContext: 1,\n    genderInclusive: 1,\n    retriever: 1,\n    createdAt: -1 \n  }, \n  { \n    name: 'cache_lookup_user_toc',\n    partialFilterExpression: { userEmail: { $exists: true } }\n  }\n)\n</code></pre>"},{"location":"_analysis/event-filesystem-contract.html","title":"Filesystem-Contract: Event + Testimonials + Final-Runs","text":"<p>Datum: 2026-01-11 Status: Arbeitsgrundlage (f\u00fcr Implementierung der 3 Wizards)</p>"},{"location":"_analysis/event-filesystem-contract.html#ziel","title":"Ziel","text":"<p>Wir brauchen eine klare, stabile Dateistruktur, damit drei zusammenh\u00e4ngende Flows sauber arbeiten:</p> <ul> <li>Flow A legt einen Event-Container an (und indexiert den Original-Event).</li> <li>Flow B schreibt Testimonials (Audio + Metadaten) in den Event-Container (filesystem-only, keine Ingestion).</li> <li>Flow C erzeugt versionierte Final-Runs (filesystem-only) und kann optional einen Final-Run publizieren (Index-Swap).</li> </ul> <p>Wichtig: Im Filesystem wird nichts \u00fcberschrieben (Finalisierung erzeugt neue Dateien). Der \u201eReplace\u201c-Effekt passiert nur im Index.</p>"},{"location":"_analysis/event-filesystem-contract.html#begriffe","title":"Begriffe","text":"<ul> <li>Event-Container: Ein Storage-Ordner, der alle Event-bezogenen Dateien enth\u00e4lt.</li> <li>Original-Event-Datei: Das Markdown, das aus Flow A entsteht.</li> <li>Final-Run: Ein versionierter Output aus Flow C (entsteht mehrfach, wird nicht automatisch ingestiert).</li> </ul>"},{"location":"_analysis/event-filesystem-contract.html#ordnerstruktur-minimal-kompatibel-mit-aktuellem-wizard-container-modus","title":"Ordnerstruktur (minimal, kompatibel mit aktuellem Wizard-Container-Modus)","text":"<p>Der Creation-Wizard kann bereits <code>createInOwnFolder=true</code> und speichert dann:</p> <ul> <li>Ordnername = Dateiname ohne Extension</li> <li>Source-Dateiname = Dateiname (z.B. <code>mein-event.md</code>)</li> <li>Result: <code>mein-event/mein-event.md</code></li> </ul> <p>Daraus leiten wir den Contract ab:</p> <pre><code>&lt;eventSlug&gt;/                       # Event-Container (Foldername == slug)\n  &lt;eventSlug&gt;.md                   # Original-Event (Flow A), wird ingestiert\n\n  testimonials/                    # Child-Assets (Flow B), filesystem-only\n    &lt;testimonialId&gt;/               # z.B. uuid\n      audio.webm|wav|mp3|m4a       # Originalaufnahme\n      meta.json                    # Metadaten (speakerName?, consent?, createdAt, etc.)\n      transcript.md                # optional, wenn sp\u00e4ter transkribiert\n\n  finals/                          # Output aus Flow C, filesystem-only bis Publish\n    run-&lt;timestamp&gt;/               # versionierter Run\n      event-final.md               # Final-Entwurf (mit slug des Originals)\n      final.json                   # Run-Metadaten (usedTestimonials[], generatedAt, etc.)\n</code></pre>"},{"location":"_analysis/event-filesystem-contract.html#frontmatter-contract-fur-event-markdown","title":"Frontmatter-Contract (f\u00fcr Event Markdown)","text":""},{"location":"_analysis/event-filesystem-contract.html#pflichtfelder-original-final","title":"Pflichtfelder (Original + Final)","text":"<ul> <li><code>docType: event</code>   Wird f\u00fcr Typisierung/Filter/Detail-Render genutzt.</li> <li><code>detailViewType: session</code>   F\u00fcr Detail-Renderer (SessionDetail UI).</li> <li><code>slug: &lt;eventSlug&gt;</code>   Muss stabil sein. Final-Publish verwendet denselben slug.</li> </ul>"},{"location":"_analysis/event-filesystem-contract.html#pflichtfelder-final-runs","title":"Pflichtfelder (Final-Runs)","text":"<ul> <li><code>originalFileId: &lt;fileId&gt;</code> Referenz auf den indexierten Original-Event (wird f\u00fcr Index-Swap ben\u00f6tigt).</li> <li><code>finalRunId: &lt;runId&gt;</code>   Eindeutige Kennung des Runs (z.B. timestamp oder uuid).</li> <li><code>eventStatus: finalDraft</code> (oder <code>finalPublished</code> nach Publish)   UI-Steuerung (CTA anzeigen, Status-Label).</li> </ul>"},{"location":"_analysis/event-filesystem-contract.html#empfohlene-felder-original","title":"Empfohlene Felder (Original)","text":"<ul> <li><code>eventStatus: open</code>   UI-Label, zeigt dass Testimonials noch gesammelt werden.</li> </ul>"},{"location":"_analysis/event-filesystem-contract.html#id-slug-generierung","title":"ID-/Slug-Generierung","text":"<ul> <li>Dateiname/Slug kann \u00fcber <code>buildCreationFileName()</code> erzeugt werden: <code>src/lib/creation/file-name.ts</code> (Windows-sicher, diakritika-safe).</li> </ul>"},{"location":"_analysis/event-filesystem-contract.html#ingestion-index-contract","title":"Ingestion-/Index-Contract","text":"<ul> <li>Original-Event wird ingestiert (damit er in Explorer sichtbar ist).</li> <li>Testimonials werden nicht ingestiert (filesystem-only).</li> <li>Final-Run wird erst ingestiert, wenn explizit \u201ePublish final\u201c ausgef\u00fchrt wird.</li> <li>Publish final = ingest final + delete original from index (docs/delete).</li> </ul>"},{"location":"_analysis/event-filesystem-contract.html#offene-punkte-bewusst-offen-gelassen","title":"Offene Punkte (bewusst offen gelassen)","text":"<ul> <li>Audio-Format: wir akzeptieren mehrere (<code>webm</code>, <code>wav</code>, <code>m4a</code>, <code>mp3</code>). Standard h\u00e4ngt von Recorder-Komponente ab.</li> <li>Welche Metadaten in <code>meta.json</code> minimal sind (Consent/Name/etc.) \u2013 h\u00e4ngt von UX-Formular ab.</li> </ul>"},{"location":"_analysis/event-testimonials-wizards.html","title":"Analyse: Event \u2192 Testimonials \u2192 Finalize/Publish (3 Wizard-Flows)","text":"<p>Datum: 2026-01-11 Scope: CommonKnowledgeScout \u2013 Wizard-UX, Storage-Datenhaltung, Ingestion/Explorer, Event-Detail-UI</p>"},{"location":"_analysis/event-testimonials-wizards.html#1-zielbild-fachlich","title":"1) Zielbild (fachlich)","text":"<p>Es sollen drei getrennte Wizard-Flows einen zusammenh\u00e4ngenden Prozess bedienen:</p> <ol> <li>Flow A \u2013 Event anlegen: Ein Moderator erstellt eine Event-Seite (wie heute: Session/Event-Detailansicht). Der Event soll in der Explorer/Gallery-Ansicht ganz normal erscheinen (\u00f6ffentlich/publiziert, je nach Library-Konfiguration).</li> <li>Flow B \u2013 Testimonials einsammeln: \u00dcber einen QR-Code auf der Event-Seite werden Testimonials aufgenommen (Audio). Die Audio-Dateien + Artefakte werden im Event-Kontext abgelegt.</li> <li>Flow C \u2013 Co\u2011Creation / Finalisieren: Aus Event-Text + Testimonials wird ein \u201efinaler\u201c Event generiert. Wichtig: Im Filesystem wird nichts \u00fcberschrieben (Original bleibt erhalten). Im Explorer/Index soll bei \u201ePublish final\u201c jedoch der Original-Event im Index ersetzt werden.</li> </ol>"},{"location":"_analysis/event-testimonials-wizards.html#2-festgelegte-entscheidungen-aus-gesprach","title":"2) Festgelegte Entscheidungen (aus Gespr\u00e4ch)","text":"<p>Diese Punkte gelten als \u201egegeben\u201c und beeinflussen Architektur/Implementierung:</p> <ul> <li>Datenhaltung (Source of Truth): Prim\u00e4r Storage/Filesystem (Markdown + Artefakte im Event-Ordner). MongoDB wird weiterhin f\u00fcr Templates/konfigurationale Daten genutzt, nicht als prim\u00e4res Event/Testimonial-DB-Modell.</li> <li>Moderator vs anonym (QR-Sichtbarkeit): Entscheidung \u00fcber Login/Session (Clerk) \u2013 Moderator sieht QR, anonyme Nutzer nicht.</li> <li>Slug/Ersetzung beim Final-Publish: Finaler Event bekommt denselben <code>slug</code> wie der urspr\u00fcngliche Event, um denselben \u201ePlatz\u201c im Explorer zu belegen.</li> <li>Mehrfaches Finalisieren: Flow C darf mehrfach laufen und erzeugt versionierte Final-Entw\u00fcrfe im Filesystem, die nicht automatisch in den Index gehen. Erst ein expliziter Publish-Schritt f\u00fchrt zum Index-Swap.</li> </ul>"},{"location":"_analysis/event-testimonials-wizards.html#3-ist-zustand-verifiziert-durch-code-lesung","title":"3) Ist-Zustand (verifiziert durch Code-Lesung)","text":""},{"location":"_analysis/event-testimonials-wizards.html#31-explorergallery-woher-kommen-die-items","title":"3.1 Explorer/Gallery \u2013 woher kommen die Items?","text":"<p>Die Gallery l\u00e4dt Dokumente \u00fcber: - <code>GET /api/chat/[libraryId]/docs</code> (<code>src/app/api/chat/[libraryId]/docs/route.ts</code>)</p> <p>Diese Route nutzt Vektor-/Meta-Daten aus MongoDB-Collections (Vector-Repo). Das bedeutet: - Explorer-\u201eWahrheit\u201c ist der Ingestion-Index, nicht das Filesystem. - Dateien k\u00f6nnen im Storage existieren, aber ohne Ingestion erscheinen sie nicht in der Gallery.</p> <p>Konsequenz: - \u201eEvent ersetzen\u201c (ohne Files zu l\u00f6schen) muss als Index-Operation modelliert werden.</p>"},{"location":"_analysis/event-testimonials-wizards.html#32-index-loschen-ohne-dateien-zu-loschen-existiert-bereits","title":"3.2 Index l\u00f6schen ohne Dateien zu l\u00f6schen (existiert bereits)","text":"<p>Es gibt bereits: - <code>DELETE /api/chat/[libraryId]/docs/delete</code> (<code>src/app/api/chat/[libraryId]/docs/delete/route.ts</code>)</p> <p>Diese Route: - l\u00f6scht nur MongoDB-Vektordokumente (Chunks/Meta/\u2026) - l\u00f6scht NICHT die Dateien im Storage</p> <p>Das passt exakt zu \u201eOriginal bleibt im Filesystem, aber verschwindet aus Explorer\u201c.</p>"},{"location":"_analysis/event-testimonials-wizards.html#33-ingestion-fur-markdown-existiert-bereits","title":"3.3 Ingestion f\u00fcr Markdown (existiert bereits)","text":"<p>Es gibt bereits: - <code>POST /api/chat/[libraryId]/ingest-markdown</code> (<code>src/app/api/chat/[libraryId]/ingest-markdown/route.ts</code>)</p> <p>Diese Route: - l\u00e4dt eine Markdown-Datei aus Storage via <code>fileId</code> - upsertet diese in den Ingestion-Index (\u00fcber <code>IngestionService.upsertMarkdown</code>)</p> <p>Konsequenz: - Ein Index-Swap kann prinzipiell aus (a) ingest final + (b) delete original zusammengesetzt werden.</p>"},{"location":"_analysis/event-testimonials-wizards.html#34-detail-rendering-session-vs-testimonial","title":"3.4 Detail-Rendering: Session vs Testimonial","text":"<p>Es gibt einen generischen Renderer: - <code>DetailViewRenderer</code> (<code>src/components/library/detail-view-renderer.tsx</code>)   - kann <code>book</code>, <code>session</code>, <code>testimonial</code> rendern (Mapping via <code>doc-meta-mappers.ts</code>)</p> <p>Wichtig: Der Explorer-Detail-Overlay (<code>DetailOverlay</code>) ist aktuell typisch auf <code>viewType: 'book' | 'session'</code> begrenzt: - <code>src/components/library/gallery/detail-overlay.tsx</code></p> <p>Konsequenz: - F\u00fcr Testimonials und/oder weitere Detailtypen ist entweder   - das Overlay zu erweitern, oder   - Testimonials nur als Teil der SessionDetail-UI darzustellen, ohne eigenen Overlay-Typ.</p>"},{"location":"_analysis/event-testimonials-wizards.html#35-templatecreation-flow-was-ist-heute-wirklich-unterstutzt","title":"3.5 Template/Creation-Flow \u2013 was ist heute \u201ewirklich\u201c unterst\u00fctzt?","text":"<p>Die Typen erlauben bestimmte Step-Presets: - <code>CreationFlowStepPreset</code> in <code>src/lib/templates/template-types.ts</code>   - u.a. <code>welcome</code>, <code>chooseSource</code>, <code>collectSource</code>, <code>reviewMarkdown</code>, <code>generateDraft</code>, <code>editDraft</code>, <code>uploadImages</code>, <code>previewDetail</code>, <code>publish</code>, <code>selectRelatedTestimonials</code></p> <p>Beobachtung aus deinen MongoDB-JSONs: - <code>rawFrontmatter</code> enth\u00e4lt teils Presets wie <code>briefing</code>, <code>reviewSources</code> (in einem Beispiel), - im gespeicherten <code>creation.flow.steps</code> fehlen diese.</p> <p>Interpretation (muss in Tests best\u00e4tigt werden): - unbekannte Presets werden wahrscheinlich nicht verarbeitet (oder beim Speichern/Parser nicht \u00fcbernommen).   - Das ist relevant, weil neue Flows nur dann \u201etemplategesteuert\u201c bleiben, wenn wir bei den implementierten Presets bleiben oder neue Presets end-to-end hinzuf\u00fcgen.</p>"},{"location":"_analysis/event-testimonials-wizards.html#36-publish-step-im-wizard-aktuell-nicht-generisch","title":"3.6 Publish-Step im Wizard: aktuell nicht generisch","text":"<p>Der <code>publish</code> Step existiert als Preset, aber die Implementierung im Wizard ist aktuell stark auf einen speziellen Case (PDFAnalyse) zugeschnitten: - <code>src/components/creation-wizard/creation-wizard.tsx</code> (Publish-Case enth\u00e4lt Guard auf <code>templateId === 'pdfanalyse'</code>)</p> <p>Konsequenz: - F\u00fcr Flow C (\u201ePublish final Event\u201c) brauchen wir einen neuen Publish-Mechanismus (oder eine Generalisierung), der Index-Swap unterst\u00fctzt.</p>"},{"location":"_analysis/event-testimonials-wizards.html#4-soll-modell-datenhaltung-vs-index-ohne-uberschreiben","title":"4) Soll-Modell: Datenhaltung vs Index (ohne \u00dcberschreiben)","text":""},{"location":"_analysis/event-testimonials-wizards.html#41-filesystem-layout-vorschlag-anpassbar","title":"4.1 Filesystem-Layout (Vorschlag, anpassbar)","text":"<p>Ziel: Original bleibt erhalten, Final-Runs werden versioniert gespeichert, Testimonials liegen im Event-Kontext.</p> <p>Beispiel:</p> <pre><code>events/&lt;eventSlug&gt;/\n  original/\n    event.md\n    event.json\n  testimonials/\n    &lt;testimonialId&gt;/\n      audio.&lt;ext&gt;\n      transcript.md (optional)\n      testimonial.md (optional)\n      artifacts.json (optional)\n  finals/\n    run-&lt;timestamp&gt;/\n      event-final.md\n      final.json\n</code></pre> <p>Wichtig: - Der \u201eoriginale Event\u201c ist eine Datei im Storage und bleibt dauerhaft bestehen. - Jeder Final-Run schreibt in einen eigenen Unterordner. - Der finale Publish-Mechanismus entscheidet, welche Datei in den Index gelangt.</p>"},{"location":"_analysis/event-testimonials-wizards.html#42-indexexplorer-logik-ersetzten-durch-swap","title":"4.2 Index/Explorer-Logik: \u201eersetzten\u201c durch Swap","text":"<p>Da Explorer aus dem Ingestion-Index liest, ist \u201eErsetzen\u201c im Kern:</p> <ol> <li>Final erzeugen (Filesystem-only): Final-Run schreiben, NICHT ingestieren.</li> <li>Publish final (Index-Swap):</li> <li>(a) final ingestieren (mit <code>docType: 'event'</code> und <code>slug</code> wie Original)</li> <li>(b) original aus Index l\u00f6schen (via <code>/docs/delete</code> mit original <code>fileId</code>)</li> </ol> <p>Offener Punkt (muss entschieden/validiert werden): - Reihenfolge (a\u2192b) vs (b\u2192a) und Fehlerf\u00e4lle:   - a\u2192b minimiert \u201eleeren Slot\u201c, kann aber kurzzeitig Duplikate im Index erzeugen, falls slug nicht als Unique-Constraint wirkt.   - b\u2192a minimiert Duplikate, kann aber kurzzeitig \u201ekein Event\u201c in Explorer bedeuten.</p>"},{"location":"_analysis/event-testimonials-wizards.html#5-was-muss-programmiert-werden-anderungsflachen","title":"5) Was muss programmiert werden? (\u00c4nderungsfl\u00e4chen)","text":""},{"location":"_analysis/event-testimonials-wizards.html#51-wizardcreation-flow-frontend","title":"5.1 Wizard/Creation-Flow (Frontend)","text":"<p>Neue F\u00e4higkeiten (wahrscheinlich n\u00f6tig): - Kontextgebundener Output: Flow B &amp; Flow C m\u00fcssen in einen bestehenden Event-Ordner schreiben (statt \u201eneuen Root-Output\u201c). - Flow C Aggregation: Inputs aus mehreren Quellen (Original-Event + N Testimonials) m\u00fcssen geb\u00fcndelt und an LLM/Transformation \u00fcbergeben werden. - Generischer Publish-Step f\u00fcr \u201ePublish final Event\u201c:   - ruft Ingestion f\u00fcr Final an   - ruft Delete f\u00fcr Original an   - erzwingt <code>slug</code> Gleichheit im Final</p> <p>Risiko: - Wenn Wizard-Presets nicht ausreichen, braucht es neue Step-Presets oder eine \u201eCustom Step\u201c-Erweiterung.</p>"},{"location":"_analysis/event-testimonials-wizards.html#52-backendapi","title":"5.2 Backend/API","text":"<p>F\u00fcr die Event/Testimonial-Beziehung braucht das Frontend klare APIs. Zwei m\u00f6gliche Richtungen:</p> <p>1) Index-basiert (empfohlen, konsistent zum Explorer): - Endpoint \u201eTestimonials zu Event\u201c: Query im Index nach <code>docType='testimonial'</code> und <code>parentId=&lt;eventFileId&gt;</code> (oder <code>parentSlug/eventId</code>).</p> <p>2) Filesystem-basiert (nur wenn Index nicht reicht): - Endpoint liest Storage-Ordner <code>events/&lt;slug&gt;/testimonials/...</code> und liefert Liste + Streaming URLs.</p> <p>Zus\u00e4tzlich n\u00f6tig: - Upload/Save Testimonial (Audio + Metadaten) als Server-Route, die sauber authorisiert (anonym erlaubt, aber nur f\u00fcr spezifischen Event-Kontext).   - Hier ist Security besonders wichtig (Rate Limits, Event-Token oder zumindest event-spezifische Write-Grenzen).</p>"},{"location":"_analysis/event-testimonials-wizards.html#53-event-detail-ui-sessiondetail","title":"5.3 Event Detail UI (SessionDetail)","text":"<p>SessionDetail (<code>src/components/library/session-detail.tsx</code>) zeigt aktuell: - Titel/Teaser - PDF-Link (falls <code>url</code>) - Markdown (aus <code>data.markdown</code> oder <code>data.summary</code>)</p> <p>Erweiterungen f\u00fcr euer Ziel: - QR-Block oben (nur Moderator):   - braucht Auth-Infos + Owner/Moderator Check - Testimonials-Block:   - Liste + Audioplayer/Quotes/Summaries   - optional \u201eStart Finalize/Close\u201c-CTA (Moderator) - Final-Status:   - UI unterscheidet: \u201eopen\u201c vs \u201efinal published\u201c</p> <p>Wichtig: Der Explorer-Overlay nutzt aktuell <code>IngestionSessionDetail</code> (nicht direkt <code>SessionDetail</code>). Wir m\u00fcssen analysieren, wo genau wir UI einh\u00e4ngen: - Entweder in <code>IngestionSessionDetail</code> (wahrscheinlich), oder - in einer h\u00f6heren Schicht, die die Daten zusammenf\u00fchrt.</p>"},{"location":"_analysis/event-testimonials-wizards.html#6-offene-fragen-noch-nicht-validiert","title":"6) Offene Fragen (noch nicht validiert)","text":"<p>Diese Punkte m\u00fcssen vor Implementierung gekl\u00e4rt oder per Test verifiziert werden:</p> <ul> <li>Flow B/C als Template-Wizards: Wenn Flow B (Testimonial-Erfassung) und Flow C (Finalisierung/Publikation) zwingend \u00fcber den Creation-Wizard laufen sollen, muss klar sein, ob diese Flows</li> <li>nur f\u00fcr angemeldete User (Moderator/Owner) gedacht sind, oder</li> <li>auch \u201e\u00f6ffentlich\u201c/anonym laufen sollen (dann brauchen wir eine Public-Variante des Wizards oder einen separaten Public-Wrapper).</li> <li>Template-Samples vs. Mongo Templates: <code>template-samples/*</code> sind nur Beispiele. F\u00fcr die echte Wizard-Auswahl m\u00fcssen diese Templates in MongoDB importiert werden (Creation-Typen werden aus Templates mit <code>creation</code>-Block abgeleitet).</li> <li>Slug-Constraints im Index: Gibt es eine garantierte Eindeutigkeit? Oder k\u00f6nnen zwei Dokumente mit gleichem <code>slug</code> parallel existieren?</li> <li>Welche Felder bestimmt die Gallery-Karte? (<code>DocCardMeta</code> kommt aus Item-Mapping; docType/parentId existieren, m\u00fcssen aber konsistent bef\u00fcllt werden.)</li> <li>Wie sauber k\u00f6nnen wir \u201eOriginal aus Index l\u00f6schen\u201c identifizieren? (fileId ist eindeutig; slug w\u00e4re nur sekund\u00e4r.)</li> <li>Auth f\u00fcr anonyme Testimonials: Login ist f\u00fcr Moderator entschieden, aber anonyme Writes brauchen trotzdem eine Absicherung (mindestens event-spezifische Begrenzung).</li> </ul>"},{"location":"_analysis/event-testimonials-wizards.html#7-testplan-minimal-aber-aussagekraftig","title":"7) Testplan (minimal, aber aussagekr\u00e4ftig)","text":""},{"location":"_analysis/event-testimonials-wizards.html#unitintegration","title":"Unit/Integration","text":"<ul> <li>Slug-Erzeugung + Stabilit\u00e4t (Original vs Final)</li> <li>Index-Swap-Logik: ingest + delete in definierter Reihenfolge (inkl. Fehlerfall-Handling)</li> <li>Parent-Relation: testimonial.parentId (oder eventId) wird konsistent gesetzt und kann abgefragt werden</li> </ul>"},{"location":"_analysis/event-testimonials-wizards.html#smoke-test-manuell","title":"Smoke-Test (manuell)","text":"<ol> <li>Event via Flow A erstellen \u2192 erscheint in Explorer.</li> <li>Als Moderator Event \u00f6ffnen \u2192 QR sichtbar. Als anon \u00f6ffnen \u2192 QR nicht sichtbar.</li> <li>Per QR Testimonial aufnehmen \u2192 Artefakte landen im Event-Ordner.</li> <li>Flow C starten \u2192 Final-Run-Dateien werden geschrieben, erscheinen aber nicht im Explorer.</li> <li>\u201ePublish final\u201c \u2192 Original verschwindet aus Explorer, Final erscheint mit gleichem slug/\u201ePlatz\u201c.</li> </ol>"},{"location":"_analysis/event-wizard-smoke-test.html","title":"Smoke-Test Checkliste: Event \u2192 Testimonials \u2192 Finalize/Publish","text":"<p>Datum: 2026-01-11 Ziel: Manuelle Verifikation der drei Flows (A/B/C) im laufenden System.</p>"},{"location":"_analysis/event-wizard-smoke-test.html#voraussetzungen","title":"Voraussetzungen","text":"<ul> <li>Du bist als Owner/Moderator der Library angemeldet.</li> <li>Du hast das Template aus <code>template-samples/event-creation-de.md</code> in deine Template-Library importiert (oder \u00e4quivalent erstellt).</li> <li>Deine Library ist \u00f6ffentlich (f\u00fcr den anon Recorder) oder du testest im internen <code>/library</code> Bereich.</li> </ul>"},{"location":"_analysis/event-wizard-smoke-test.html#flow-a-event-erstellen-wizard","title":"Flow A: Event erstellen (Wizard)","text":"<ol> <li>\u00d6ffne den Creation-Wizard f\u00fcr <code>event-creation-de</code> (oder deinen Event-Type).</li> <li>Erstelle einen Event und speichere.</li> <li>Erwartung:</li> <li>Im Storage gibt es einen neuen Ordner <code>&lt;slug&gt;/</code> mit Datei <code>&lt;slug&gt;.md</code>.</li> <li>Der Event erscheint in der Gallery/Explore-Ansicht (Ingestion wurde beim Speichern getriggert).</li> </ol>"},{"location":"_analysis/event-wizard-smoke-test.html#flow-b-testimonial-aufnehmen-anonym","title":"Flow B: Testimonial aufnehmen (anonym)","text":"<ol> <li>\u00d6ffne den Event in der Detailansicht.</li> <li>Erwartung:</li> <li>Als Owner/Moderator siehst du einen QR-Code (und einen Link).</li> <li>\u00d6ffne den Link in einem privaten Fenster (oder kopiere ihn aufs Handy).</li> <li>URL-Form: <code>/public/testimonial?libraryId=...&amp;eventFileId=...&amp;writeKey=...</code></li> <li>Nimm ein kurzes Testimonial auf (\u201eStop &amp; senden\u201c).</li> <li>Erwartung:</li> <li>Im Storage entsteht unter <code>&lt;slug&gt;/testimonials/&lt;testimonialId&gt;/</code> mindestens:<ul> <li><code>audio.*</code></li> <li><code>meta.json</code></li> </ul> </li> <li>In der Event-Detailseite wird das Testimonial in der Liste angezeigt (Audio abspielbar).</li> </ol>"},{"location":"_analysis/event-wizard-smoke-test.html#flow-c-final-draft-erzeugen-filesystem-only","title":"Flow C: Final Draft erzeugen (filesystem-only)","text":"<ol> <li>In der Event-Detailseite (als Owner/Moderator) klicke \u201eFinal-Draft erzeugen\u201c.</li> <li>Erwartung:</li> <li>Im Storage entsteht <code>&lt;slug&gt;/finals/run-&lt;timestamp&gt;/event-final.md</code>.</li> <li>Es wird noch nichts im Explorer ersetzt (keine Ingestion, kein Delete).</li> </ol>"},{"location":"_analysis/event-wizard-smoke-test.html#flow-c-final-veroffentlichen-index-swap","title":"Flow C: Final ver\u00f6ffentlichen (Index-Swap)","text":"<ol> <li>Klicke \u201eFinal ver\u00f6ffentlichen\u201c.</li> <li>Erwartung:</li> <li>Final wird ingestiert (neuer Index-Eintrag).</li> <li>Original wird aus dem Index gel\u00f6scht (Datei bleibt im Storage).</li> <li>In der Gallery/Explore-Ansicht siehst du den Event weiterhin \u201eam selben Platz\u201c (gleicher slug), aber inhaltlich den Final.</li> </ol>"},{"location":"_analysis/event-wizard-smoke-test.html#hinweise-bei-problemen","title":"Hinweise bei Problemen","text":"<ul> <li>Wenn Final \u201epubliziert\u201c wird, aber du siehst Duplikate: pr\u00fcfen, ob der Index slug-eindeutig ist; ggf. Cleanup \u00fcber <code>/api/chat/[libraryId]/docs/delete</code>.</li> <li>Wenn Upload im anon Recorder fehlschl\u00e4gt: pr\u00fcfen, ob der Event im Frontmatter <code>testimonialWriteKey</code> hat und ob der Link diesen Key enth\u00e4lt.</li> </ul>"},{"location":"_analysis/template-transformation-test-dialog.html","title":"Analyse zur Trennung der Template-Tests in einen Dialog","text":""},{"location":"_analysis/template-transformation-test-dialog.html#kontext-und-ziel","title":"Kontext und Ziel","text":"<p>Die aktuelle Vorlagenverwaltung zeigt rechts den Block \"Transformation testen\". Das erzeugt visuelle \u00dcberfrachtung und zwingt die Template-Gestaltung in eine halbe Breite. Gew\u00fcnscht ist eine klare Trennung: die Template-Gestaltung nutzt die gesamte Breite, w\u00e4hrend die Transformationstests als eigenst\u00e4ndige Funktion per Button auf der Homepage erreichbar sind und in einem Dialog laufen.</p> <p>Zus\u00e4tzliche Anforderungen: Der Test muss weiterhin Kontext-Dateien und Freitext unterst\u00fctzen, Ergebnisse speichern k\u00f6nnen und m\u00f6glichst die aktuelle Template-Definition nutzen. Gleichzeitig soll die UI schlank bleiben, keine unn\u00f6tigen Abh\u00e4ngigkeiten einf\u00fchren und die bestehenden Atome/Services weiterverwenden.</p>"},{"location":"_analysis/template-transformation-test-dialog.html#varianten","title":"Varianten","text":""},{"location":"_analysis/template-transformation-test-dialog.html#variante-a-dialog-direkt-in-der-template-seite-kein-home-button","title":"Variante A: Dialog direkt in der Template-Seite (kein Home-Button)","text":"<p>Idee: Den Test-Block in einen Dialog innerhalb <code>TemplateManagement</code> verschieben, \u00f6ffnen \u00fcber Button in der Toolbar. Vorteile: Minimaler Code, nutzt bestehende Form-Werte (auch ungespeichert), keine zus\u00e4tzliche Logik. Nachteile: Kein Button auf der Homepage, Anforderung nicht erf\u00fcllt.</p>"},{"location":"_analysis/template-transformation-test-dialog.html#variante-b-gemeinsamer-dialog-wiederverwendbar-in-home-template-seite","title":"Variante B: Gemeinsamer Dialog, wiederverwendbar in Home + Template-Seite","text":"<p>Idee: Eigenes Dialog-Component f\u00fcr Tests. Es kann entweder mit \"aktuellen Form-Werten\" arbeiten (Template-Seite) oder mit geladenen Templates (Homepage). Vorteile: Ein UI, zwei Einstiege. Die Template-Seite bleibt breit. Anforderungen erf\u00fcllt. Nachteile: Etwas mehr Refactoring, braucht klar definierte Props/Helper.</p>"},{"location":"_analysis/template-transformation-test-dialog.html#variante-c-home-button-fuhrt-zu-templatestest1-und-offnet-dialog-dort","title":"Variante C: Home-Button f\u00fchrt zu <code>/templates?test=1</code> und \u00f6ffnet Dialog dort","text":"<p>Idee: Home-Button navigiert zur Template-Seite; dort \u00f6ffnet ein Dialog automatisch. Vorteile: Kein zus\u00e4tzlicher Test-Dialog im Home, geringe UI-Komplexit\u00e4t. Nachteile: Nicht wirklich \"auf der Homepage im Dialog\"; weniger direkt, zus\u00e4tzlicher Seitenwechsel.</p>"},{"location":"_analysis/template-transformation-test-dialog.html#entscheidung","title":"Entscheidung","text":"<p>Gew\u00e4hlt: Variante A. Der Button zum \u00d6ffnen der Testumgebung bleibt innerhalb der Template-Seite. Damit ist die Trennung der UI erreicht, ohne einen Home-Button oder zus\u00e4tzliche Navigation einzuf\u00fchren. Die Template-Gestaltung erh\u00e4lt volle Breite, und die Test-Logik bleibt direkt am Editor gebunden.</p>"},{"location":"_analysis/template-transformation-test-dialog.html#geplante-anderungen-dateien","title":"Geplante \u00c4nderungen (Dateien)","text":"<ul> <li><code>src/components/templates/template-management.tsx</code> (Dialog integrieren, rechten Block entfernen, Layout auf volle Breite)</li> </ul>"},{"location":"_analysis/testimonial-flow-consolidation.html","title":"Testimonial flow consolidation","text":""},{"location":"_analysis/testimonial-flow-consolidation.html#frage","title":"Frage","text":"<p>Der Nutzer m\u00f6chte nur einen Testimonial-Flow: den Wizard-Flow. Zus\u00e4tzlich ist ein \u201eleichter\u201c Wizard denkbar, der UX-m\u00e4\u00dfig so schnell ist wie der bisherige anonyme Flow.</p>"},{"location":"_analysis/testimonial-flow-consolidation.html#ist-zustand-beobachtbar-im-code","title":"Ist-Zustand (beobachtbar im Code)","text":"<ul> <li>Public Flow (\u00f6ffentlich, ohne Login):</li> <li>Seite: <code>/public/testimonial</code> \u2192 <code>src/app/public/testimonial/page.tsx</code> \u2192 <code>PublicTestimonialRecorder</code></li> <li>API: <code>/api/public/testimonials</code> \u2192 <code>src/app/api/public/testimonials/route.ts</code></li> <li>Zweck: Aufnahme/Erfassung via QR-Link (mit <code>libraryId</code>, <code>eventFileId</code>, optional <code>writeKey</code>)</li> <li> <p>Speicherung: in <code>&lt;eventFolder&gt;/testimonials/&lt;id&gt;/...</code> (Audio + <code>meta.json</code>, inzwischen optional <code>text</code>).</p> </li> <li> <p>Wizard Flow (authentifiziert, innerhalb der Library):</p> </li> <li>Route: <code>/library/create/&lt;templateId&gt;?seedFileId=...&amp;targetFolderId=...</code></li> <li>Zweck: Template-basiertes Erstellen von Markdown-Dateien (z.B. <code>testimonial-*.md</code>) inkl. Bearbeitungsschritten.</li> </ul>"},{"location":"_analysis/testimonial-flow-consolidation.html#warum-gibt-es-den-public-flow-uberhaupt","title":"Warum gibt es den Public Flow \u00fcberhaupt?","text":"<p>Er erf\u00fcllt eine reale UX-Anforderung: Teilnehmende sollen ohne Login (per QR) ein Testimonial abgeben k\u00f6nnen. Das ist nicht \u201eWizard\u201c, weil der Wizard aktuell im authentifizierten Bereich lebt und mehr UI/State/Steps hat.</p>"},{"location":"_analysis/testimonial-flow-consolidation.html#problem","title":"Problem","text":"<p>Zwei Flows erzeugen zwei Datenformen: - Wizard \u2192 Markdown-Dokument(e) - Public \u2192 RAW-Audio + <code>meta.json</code> (ggf. Text)</p> <p>Dadurch entstehen Inkonsistenzen im sp\u00e4teren \u201eFinalize\u201c-Schritt, wenn der Wizard ausschlie\u00dflich Markdown-Quellen erwartet.</p>"},{"location":"_analysis/testimonial-flow-consolidation.html#zielbild","title":"Zielbild","text":"<p>Einheitlicher Prozess: - Ein Entry-Flow (Wizard) f\u00fcr Owner/Moderator. - F\u00fcr Externe: entweder   - ein \u201eLight-Wizard\u201c (\u00f6ffentlich, minimal), oder   - weiterhin ein Public-Recorder, der aber immer ein Markdown-Dokument erzeugt (damit Downstream identisch ist).</p>"},{"location":"_analysis/testimonial-flow-consolidation.html#losungsvarianten-3-optionen","title":"L\u00f6sungsvarianten (3 Optionen)","text":""},{"location":"_analysis/testimonial-flow-consolidation.html#variante-1-public-flow-komplett-entfernen","title":"Variante 1: Public Flow komplett entfernen","text":"<ul> <li>Pro: Nur ein Flow, weniger Wartung, weniger Security-Oberfl\u00e4che.</li> <li>Contra: Externe/Anonyme Teilnahme ohne Login f\u00e4llt weg oder braucht neuen \u201eGuest Auth\u201c-Mechanismus.</li> </ul>"},{"location":"_analysis/testimonial-flow-consolidation.html#variante-2-public-flow-wird-zum-public-light-wizard","title":"Variante 2: Public Flow wird zum \u201ePublic Light-Wizard\u201c","text":"<ul> <li>Idee: \u00d6ffentliche Wizard-Route (sehr wenige Steps) mit denselben Speicherkonventionen wie Wizard (Markdown als Ergebnis).</li> <li>Pro: Einheitliche Datenform, gleiche Komponenten/UX-Paradigmen.</li> <li>Contra: Wizard-Framework muss public-tauglich gemacht werden (Security, State, weniger Datenzugriff).</li> </ul>"},{"location":"_analysis/testimonial-flow-consolidation.html#variante-3-public-flow-bleibt-erzeugt-aber-immer-markdown-ssot","title":"Variante 3: Public Flow bleibt, erzeugt aber immer Markdown (SSOT)","text":"<ul> <li>Idee: <code>/api/public/testimonials</code> erzeugt zus\u00e4tzlich <code>testimonial.md</code> (mit Frontmatter f\u00fcr Discovery), sodass Downstream nur noch Markdown verarbeitet.</li> <li>Pro: Minimalinvasiv, keine neue Orchestrierung, Public-UX bleibt.</li> <li>Contra: Weiterhin zwei UI-Flows (auch wenn Datenform harmonisiert ist).</li> </ul>"},{"location":"_analysis/testimonial-flow-consolidation.html#empfehlung-hypothesenbasiert-nicht-getestet","title":"Empfehlung (hypothesenbasiert, nicht getestet)","text":"<p>Kurzfristig: Variante 3 ist der kleinste Schritt, um Datenkonsistenz zu erreichen. Mittelfristig: Variante 2, wenn wirklich \u201eein Flow\u201c als Produktziel gilt.</p>"},{"location":"_analysis/testimonial-variant-b-editor-flow.html","title":"Testimonial variant b editor flow","text":""},{"location":"_analysis/testimonial-variant-b-editor-flow.html#ziel","title":"Ziel","text":"<p>Wir wollen f\u00fcr Testimonials einen Flow, der Transkription erm\u00f6glicht, aber den Nutzer zwingt, den Text vor dem finalen Speichern zu korrigieren. Gleichzeitig soll m\u00f6glichst keine neue, eigenst\u00e4ndige Logik (neue Pipelines/Worker/Jobs) erfunden werden, sondern vorhandene Komponenten aus dem Wizard wiederverwendet werden.</p>"},{"location":"_analysis/testimonial-variant-b-editor-flow.html#ausgangslage-ist-zustand","title":"Ausgangslage (Ist-Zustand)","text":"<p>Der anonyme Public-Endpoint <code>/api/public/testimonials</code> speichert derzeit nur Dateien (Audio + <code>meta.json</code>) in einem Event-Unterordner. Es gibt keine automatische Transkriptions-/Review-Phase. Der Wizard besitzt jedoch bereits eine UX-Komponente pro Feld: Textarea + Mikrofon-Icon, die Audio aufnimmt und die bestehende Route <code>/api/secretary/process-audio</code> nutzt, um eine Transkription zur\u00fcckzuliefern.</p>"},{"location":"_analysis/testimonial-variant-b-editor-flow.html#varianten","title":"Varianten","text":"<ul> <li>Variante A (rein manuell): Nur Audio speichern; Transkription/Review wird sp\u00e4ter manuell durch Owner/Moderator ausgel\u00f6st.</li> <li>Variante B (Review vor finalem Speichern): Nutzer diktiert in ein Textfeld, bekommt Transkript, korrigiert es und speichert dann final. Optional wird das Roh-Audio mitgespeichert.</li> <li>Variante C (vollautomatisch + Ingest): Nach Upload Background-Job, Statusanzeige, Transkript entsteht automatisch und wird als Dokument ingestiert.</li> </ul>"},{"location":"_analysis/testimonial-variant-b-editor-flow.html#entscheidung","title":"Entscheidung","text":"<p>Wir implementieren Variante B ohne neue Orchestrierungslogik: Wir nutzen die bereits vorhandene Transkriptions-Route <code>/api/secretary/process-audio</code> und dieselbe Diktier-UX aus dem Wizard (extrahiert als kleine Komponente). Dadurch entsteht ein sauberer Review-Schritt: Der Nutzer sieht den Text sofort, kann ihn korrigieren und erst dann final speichern.</p>"},{"location":"_analysis/testimonial-variant-b-editor-flow.html#konsequenzen-grenzen","title":"Konsequenzen / Grenzen","text":"<p>Diese Variante ist kein Background-Processing (kein Job-Queue-Status). Die Transkription passiert synchron im UI nach dem Diktat. Sp\u00e4ter kann man, falls n\u00f6tig, auf Variante C erweitern (z.B. Jobs erst nach finalem Speichern).</p>"},{"location":"_analysis/website-import-session-feature-map.html","title":"Website-Import (Sessions): File Map, Datenfluss, Contracts, Wiederverwendung","text":""},{"location":"_analysis/website-import-session-feature-map.html#kontext-ziel","title":"Kontext / Ziel","text":"<p>In dieser App gibt es ein Feature, um Sessions aus einer externen Webseite zu extrahieren und anschlie\u00dfend im Session Manager zu speichern/anzuzeigen. Es unterst\u00fctzt:</p> <ul> <li>Einzel-Import: eine Session-Seite \u2192 strukturierte Daten \u2192 Speicherung als Session.</li> <li>Batch-Import: eine \u00dcbersichtsseite \u2192 Liste von Session-Links (optional: Container-Selector) \u2192 iterativer Import jeder Session \u2192 Speicherung.</li> </ul> <p>Du m\u00f6chtest die gleiche Grundlogik in einer anderen App wiederverwenden (dort: Jobs statt Sessions), weiterhin \u00fcber den Secretary Service.</p> <p>Wichtig: Diese Doku beschreibt nur die lokale App-Seite (UI/Server/Client). Die konkrete Extraktionslogik (Template-Auswertung, Selector-Sprache, HTML-Parsing) liegt im Secretary Service und ist hier nicht vollst\u00e4ndig verifizierbar.</p>"},{"location":"_analysis/website-import-session-feature-map.html#file-map-involvierte-dateien","title":"File Map (involvierte Dateien)","text":""},{"location":"_analysis/website-import-session-feature-map.html#ui-session-manager-import-dialog","title":"UI (Session Manager + Import Dialog)","text":"<ul> <li><code>src/app/session-manager/page.tsx</code></li> <li>Rendert den Session Manager.</li> <li>\u00d6ffnet den Import-Dialog (\u201eAus Website importieren\u201c).</li> <li> <p>L\u00e4dt Sessions \u00fcber <code>GET /api/sessions</code> (Filter: search, event, track, day, source_language).</p> </li> <li> <p><code>src/components/session/session-import-modal.tsx</code></p> </li> <li>Import-Dialog mit Tabs \u201eEinzelne Session\u201c und \u201eBatch-Import\u201c.</li> <li>Ruft <code>importSessionFromUrl(...)</code> auf (Client-Lib \u2192 API Proxy \u2192 Secretary Service).</li> <li>Mappt <code>structured_data</code> in eine Session-Struktur und speichert via <code>POST /api/sessions</code>.</li> <li> <p>Batch: erwartet aus <code>structured_data</code> eine Liste von Links (Array oder Objekt-Wrapper) und importiert jeden Link seriell.</p> </li> <li> <p><code>src/components/session/session-event-filter.tsx</code></p> </li> <li>Dropdown f\u00fcr Event-Filter; l\u00e4dt Events via <code>GET /api/sessions/events</code>.</li> </ul>"},{"location":"_analysis/website-import-session-feature-map.html#client-lib-secretary-integration","title":"Client-Lib (Secretary Integration)","text":"<ul> <li><code>src/lib/secretary/client.ts</code></li> <li><code>importSessionFromUrl(url, options)</code>:<ul> <li>Ruft lokal <code>POST /api/secretary/import-from-url</code> auf.</li> <li>Setzt Default-Template: <code>ExtractSessionDataFromWebsite</code>.</li> <li>Optional: <code>container_selector</code> wird nur gesendet, wenn nicht leer.</li> </ul> </li> <li> <p>Fehlerklasse: <code>SecretaryServiceError</code>.</p> </li> <li> <p><code>src/lib/secretary/adapter.ts</code></p> </li> <li> <p><code>callTemplateExtractFromUrl(...)</code>:</p> <ul> <li>Baut die Request-Payload f\u00fcr den Secretary Service als <code>application/x-www-form-urlencoded</code>.</li> <li>Parameter: <code>url</code>, <code>source_language</code>, <code>target_language</code>, <code>template</code> oder <code>template_content</code>, <code>use_cache</code>, optional <code>container_selector</code>.</li> <li>Validiert URL-Format (lokal) und wirft <code>HttpError(400, ...)</code> bei invaliden URLs.</li> </ul> </li> <li> <p><code>src/lib/utils/fetch-with-timeout.ts</code></p> </li> <li><code>fetchWithTimeout(...)</code> + Fehlerklassen <code>TimeoutError</code>, <code>NetworkError</code>, <code>HttpError</code>.</li> <li>Wird vom Adapter genutzt (Timeout/Netzwerk-Fehler-Klassifizierung).</li> </ul>"},{"location":"_analysis/website-import-session-feature-map.html#server-nextjs-app-router-api","title":"Server (Next.js App Router API)","text":"<ul> <li><code>src/app/api/secretary/import-from-url/route.ts</code></li> <li>Proxy-Endpunkt: App \u2192 Secretary Service (<code>/transformer/template</code>).</li> <li>Holt <code>baseUrl</code>/<code>apiKey</code> aus <code>getSecretaryConfig()</code> (<code>SECRETARY_SERVICE_URL</code>, <code>SECRETARY_SERVICE_API_KEY</code>).</li> <li>Unterst\u00fctzt optional <code>templateId + libraryId</code> (Template aus MongoDB laden, serialisieren, als <code>template_content</code> senden).</li> <li> <p>Reicht Secretary-Antwort als JSON an den Client weiter.</p> </li> <li> <p><code>src/app/api/sessions/route.ts</code></p> </li> <li><code>GET /api/sessions</code>: Session-Liste + <code>total</code> (filterbar).</li> <li><code>POST /api/sessions</code>: Bulk-Anlage (Array <code>sessions</code>), Pflichtfelder: <code>session</code>, <code>filename</code>, <code>event</code>, <code>track</code>.</li> <li> <p><code>DELETE /api/sessions</code>: Bulk-L\u00f6schung via <code>ids</code>.</p> </li> <li> <p><code>src/app/api/sessions/events/route.ts</code></p> </li> <li><code>GET /api/sessions/events</code>: liefert distinct <code>event</code> Werte aus DB (ben\u00f6tigt Auth via Clerk).</li> </ul>"},{"location":"_analysis/website-import-session-feature-map.html#persistenz-typen","title":"Persistenz / Typen","text":"<ul> <li><code>src/lib/session-repository.ts</code></li> <li>MongoDB Repository f\u00fcr Sessions (Collection: <code>event_sessions</code>).</li> <li> <p>Bulk insert via <code>createSessions(...)</code> wird vom <code>/api/sessions</code> POST genutzt.</p> </li> <li> <p><code>src/types/session.ts</code></p> </li> <li>Typ <code>Session</code>, <code>SessionCreateRequest</code>, Filter-Optionen.</li> </ul>"},{"location":"_analysis/website-import-session-feature-map.html#datenfluss-single-import","title":"Datenfluss (Single Import)","text":"<ol> <li>UI: Nutzer gibt Session-URL ein.</li> <li><code>SessionImportModal.handleImport()</code> ruft:</li> <li><code>importSessionFromUrl(url, { sourceLanguage, targetLanguage, useCache:false })</code></li> <li><code>importSessionFromUrl</code> ruft App API:</li> <li><code>POST /api/secretary/import-from-url</code></li> <li><code>POST /api/secretary/import-from-url</code> ruft Secretary Service:</li> <li><code>POST ${SECRETARY_SERVICE_URL}/transformer/template</code> (Form-encoded)</li> <li>UI erwartet <code>response.data.structured_data</code> und zeigt Vorschau.</li> <li>Nutzer best\u00e4tigt \u2192 <code>handleCreateSession()</code>:</li> <li>mappt <code>structured_data</code> auf Session-Form (inkl. parse von comma-separated speakers)</li> <li><code>POST /api/sessions</code> mit <code>{ sessions: [sessionData] }</code></li> <li>Session Manager l\u00e4dt Sessions neu (<code>loadSessions()</code>), alternativ <code>window.location.reload()</code> (im Modal ist beides vorhanden; Batch nutzt reload).</li> </ol>"},{"location":"_analysis/website-import-session-feature-map.html#datenfluss-batch-import","title":"Datenfluss (Batch Import)","text":"<ol> <li>UI: Nutzer gibt \u201eURL der Session-Liste\u201c + \u201eEventname\u201c an.</li> <li>Optional: \u201eContainer-Selector (XPath)\u201c wird gesetzt und als <code>container_selector</code> \u00fcbertragen.</li> <li><code>handleExtractSessionList()</code> ruft:</li> <li><code>importSessionFromUrl(batchUrl, { template:'ExtractSessionListFromWebsite', containerSelector, ... })</code></li> <li>UI erwartet <code>structured_data</code> in einem dieser Formate:</li> <li>direktes Array: <code>[{ name, url, track? }, ...]</code></li> <li>Objekt mit <code>items</code>: <code>{ items: [...] }</code></li> <li>Objekt mit <code>sessions</code>: <code>{ sessions: [...] }</code> (R\u00fcckw\u00e4rtskompatibilit\u00e4t)</li> <li>optional: <code>{ event: \"...\" }</code> (wird als Vorschlag in UI \u00fcbernommen)</li> <li><code>handleBatchImport()</code> iteriert seriell \u00fcber <code>sessionLinks[]</code>:</li> <li>F\u00fcr jeden Link: <code>importSessionFromUrl(link.url, default template)</code></li> <li>Map \u2192 <code>POST /api/sessions</code></li> <li>Status pro Link: pending/importing/success/error + Progressbar</li> <li>Zwischen Requests: 1s Pause (Throttle)</li> </ol>"},{"location":"_analysis/website-import-session-feature-map.html#contracts-payloads-app-secretary-app","title":"Contracts / Payloads (App \u2194 Secretary \u2194 App)","text":""},{"location":"_analysis/website-import-session-feature-map.html#app-apisecretaryimport-from-url-json","title":"App \u2192 <code>/api/secretary/import-from-url</code> (JSON)","text":"<p>Das UI sendet implizit \u00fcber <code>importSessionFromUrl</code>:</p> <ul> <li><code>url</code> (required)</li> <li><code>source_language</code> (default <code>\"en\"</code>)</li> <li><code>target_language</code> (default <code>\"en\"</code>)</li> <li><code>template</code> (default <code>\"ExtractSessionDataFromWebsite\"</code>)</li> <li><code>use_cache</code> (default <code>false</code>)</li> <li>optional: <code>container_selector</code> (nur wenn nicht leer)</li> </ul>"},{"location":"_analysis/website-import-session-feature-map.html#app-secretary-service-transformertemplate-form-url-encoded","title":"App \u2192 Secretary Service <code>/transformer/template</code> (Form URL Encoded)","text":"<p>Der Server-Proxy sendet (\u00fcber <code>callTemplateExtractFromUrl</code>):</p> <ul> <li><code>url</code></li> <li><code>source_language</code></li> <li><code>target_language</code></li> <li><code>use_cache</code></li> <li>entweder <code>template</code> oder <code>template_content</code> (wenn Template aus DB geladen wird)</li> <li>optional: <code>container_selector</code></li> </ul> <p>Hinweis zum Container-Selector: In UI/Docs wird es als \u201eXPath\u201c bezeichnet. Ob es tats\u00e4chlich XPath oder ein anderes Selector-Format ist, h\u00e4ngt vom Secretary Service ab (hier nicht \u00fcberpr\u00fcft).</p>"},{"location":"_analysis/website-import-session-feature-map.html#secretary-app-response-shape","title":"Secretary \u2192 App (Response Shape)","text":"<p>Der UI-Code verl\u00e4sst sich auf:</p> <ul> <li><code>status === 'success'</code></li> <li><code>data.structured_data</code> (f\u00fcr Single: Objekt; f\u00fcr Batch: Array oder Wrapper-Objekt)</li> </ul> <p>Die genaue Struktur von <code>structured_data</code> wird in der UI bewusst tolerant behandelt (Type Guards + <code>unknown</code>).</p>"},{"location":"_analysis/website-import-session-feature-map.html#app-apisessions-json","title":"App \u2192 <code>/api/sessions</code> (JSON)","text":"<p><code>POST /api/sessions</code> erwartet:</p> <ul> <li><code>{ sessions: Array&lt;SessionInput&gt; }</code></li> <li>Pflichtfelder je Session:</li> <li><code>session</code>, <code>filename</code>, <code>event</code>, <code>track</code></li> <li>Optional u.a.:</li> <li><code>subtitle</code>, <code>description</code>, <code>url</code>, <code>day</code>, <code>starttime</code>, <code>endtime</code>, <code>speakers[]</code>,</li> <li><code>image_url</code>, <code>video_url</code>, <code>attachments_url</code>,</li> <li><code>source_language</code>, <code>target_language</code>,</li> <li><code>speakers_url[]</code>, <code>speakers_image_url[]</code></li> </ul>"},{"location":"_analysis/website-import-session-feature-map.html#wiederverwendung-in-einer-jobs-app-3-varianten","title":"Wiederverwendung in einer \u201eJobs\u201c-App: 3 Varianten","text":""},{"location":"_analysis/website-import-session-feature-map.html#variante-a-kopieren-umbenennen-schnell-aber-dupliziert","title":"Variante A \u2014 \u201eKopieren &amp; Umbenennen\u201c (schnell, aber dupliziert)","text":"<p>Du kopierst die Feature-Scheibe und passt nur Domain-Namen/Mapping/Endpoints an:</p> <ul> <li>Kopiere UI-Modal (<code>session-import-modal</code>) \u2192 <code>job-import-modal</code></li> <li>Kopiere Secretary Client-Funktion (oder nutze <code>importSessionFromUrl</code> generisch) \u2192 <code>importJobFromUrl</code></li> <li>Ersetze <code>POST /api/sessions</code> durch <code>POST /api/jobs</code></li> <li>Baue ein <code>JobRepository</code> + <code>/api/jobs</code> analog zu Sessions</li> </ul> <p>Vorteil: minimaler Umbau, schnell lauff\u00e4hig. Nachteil: Import-Logik driftet langfristig auseinander.</p>"},{"location":"_analysis/website-import-session-feature-map.html#variante-b-generisches-website-import-modul-empfohlen-fur-zwei-apps","title":"Variante B \u2014 \u201eGenerisches Website-Import-Modul\u201c (empfohlen f\u00fcr zwei Apps)","text":"<p>Du extrahierst einen generischen Kern:</p> <ul> <li>UI: generische Komponente \u201eWebsiteImportModal\u201c (URL, Batch-URL, container_selector, Templates)</li> <li>Domain Mapper: pro Zielobjekt ein kleines Mapping-Modul:</li> <li><code>mapStructuredDataToSession(...)</code></li> <li><code>mapStructuredDataToJob(...)</code></li> <li>Persistenz: pro App eigener Endpoint (<code>/api/sessions</code>, <code>/api/jobs</code>)</li> </ul> <p>Vorteil: einmalige UI/Retry/Progress/Cancel-Logik; Domain bleibt sauber getrennt. Nachteil: etwas Refactoring-Aufwand (aber lokal begrenzt).</p>"},{"location":"_analysis/website-import-session-feature-map.html#variante-c-shared-package-monorepo-library-sauber-aber-organisatorisch-schwerer","title":"Variante C \u2014 \u201eShared Package / Monorepo Library\u201c (sauber, aber organisatorisch schwerer)","text":"<p>Du machst aus Variante B ein Shared Package (z.B. internes npm package) oder ein Monorepo-Modul, das beide Apps verwenden:</p> <ul> <li><code>@common/website-import</code> (UI + client contract + types)</li> <li>App-spezifisch bleibt nur:</li> <li>Mapping</li> <li>Storage Endpoints/Repos</li> </ul> <p>Vorteil: echte Wiederverwendung \u00fcber Repos hinweg, weniger Drift. Nachteil: Build/Versioning/Release-Prozess n\u00f6tig.</p>"},{"location":"_analysis/website-import-session-feature-map.html#minimaler-was-muss-ich-ruberkopieren-spickzettel-wenn-du-es-11-nachbaust","title":"Minimaler \u201eWas muss ich r\u00fcberkopieren\u201c-Spickzettel (wenn du es 1:1 nachbaust)","text":"<p>Wenn du nur den Website-Import-Flow (Single+Batch) in einer anderen App nachbauen willst, sind typischerweise n\u00f6tig:</p> <ul> <li>UI:</li> <li><code>src/components/session/session-import-modal.tsx</code> (anpassen auf Job-Domain)</li> <li>Ein Trigger im Ziel-Screen (analog <code>src/app/session-manager/page.tsx</code>)</li> <li>Secretary Integration:</li> <li><code>src/lib/secretary/client.ts</code> (mindestens <code>importSessionFromUrl</code> und <code>SecretaryServiceError</code>)</li> <li><code>src/app/api/secretary/import-from-url/route.ts</code></li> <li><code>src/lib/secretary/adapter.ts</code></li> <li><code>src/lib/utils/fetch-with-timeout.ts</code></li> <li><code>src/lib/env.ts</code> (wegen <code>getSecretaryConfig()</code>) + Env-Variablen</li> <li>Storage:</li> <li>Ziel-API (analog <code>src/app/api/sessions/route.ts</code>) und Repository (analog <code>src/lib/session-repository.ts</code>)</li> <li>Ziel-Typen (analog <code>src/types/session.ts</code>)</li> </ul>"},{"location":"_analysis/website-import-session-feature-map.html#offene-punkte-risiken-fur-robuste-wiederverwendung","title":"Offene Punkte / Risiken (f\u00fcr robuste Wiederverwendung)","text":"<ul> <li>Selector-Semantik: Der Parameter hei\u00dft \u201eXPath\u201c, aber die Implementierung ist im Secretary Service. F\u00fcr die Jobs-App sollte die Doku/UX exakt dem entsprechen, was Secretary wirklich akzeptiert.</li> <li>Template-Namen: <code>ExtractSessionDataFromWebsite</code> und <code>ExtractSessionListFromWebsite</code> sind hier nur Strings. Sie m\u00fcssen auf Secretary-Seite existieren, sonst scheitert der Import.</li> <li>Response Shape: <code>structured_data</code> wird \u201eweich\u201c geparst. Das ist pragmatisch, aber ohne feste Contract-Tests kann es bei Template-\u00c4nderungen still brechen.</li> </ul>"},{"location":"_secretary-service-docu/audio.html","title":"Audio API Endpoints","text":"<p>Endpoints for audio file processing with transcription and optional translation.</p>"},{"location":"_secretary-service-docu/audio.html#post-apiaudioprocess","title":"POST /api/audio/process","text":"<p>Process an audio file with transcription and optional template-based transformation.</p>"},{"location":"_secretary-service-docu/audio.html#request","title":"Request","text":"<p>Content-Type: <code>multipart/form-data</code></p> <p>Parameters:</p> Parameter Type Required Default Description <code>file</code> File Yes - Audio file (MP3, WAV, M4A, FLAC, OGG, etc.) <code>source_language</code> String No <code>de</code> Source language (ISO 639-1 code, e.g., \"en\", \"de\") <code>target_language</code> String No <code>de</code> Target language for translation (ISO 639-1 code) <code>template</code> String No <code>\"\"</code> Optional template name for text transformation <code>useCache</code> Boolean No <code>true</code> Whether to use cache <code>callback_url</code> String No - If set, processing is asynchronous and results are delivered via webhook (HTTP 202 response) <code>callback_token</code> String No - Optional token sent as <code>Authorization: Bearer ...</code> and <code>X-Callback-Token</code> to the webhook <code>jobId</code> String No - Optional external job id (client-generated). Returned in the 202 ACK <code>job.id</code>"},{"location":"_secretary-service-docu/audio.html#supported-formats","title":"Supported Formats","text":"<ul> <li>FLAC, M4A, MP3, MP4, MPEG, MPGA, OGA, OGG, WAV, WEBM</li> </ul>"},{"location":"_secretary-service-docu/audio.html#request-example","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/audio/process\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -F \"file=@audio.mp3\" \\\n  -F \"source_language=en\" \\\n  -F \"target_language=de\" \\\n  -F \"template=MeetingMinutes\" \\\n  -F \"useCache=true\"\n</code></pre>"},{"location":"_secretary-service-docu/audio.html#request-example-async-via-webhook","title":"Request Example (Async via Webhook)","text":"<p>If you provide a <code>callback_url</code>, the endpoint returns immediately with <code>202 Accepted</code> and the worker sends the result to the webhook URL.</p> <pre><code>curl -X POST \"http://localhost:5001/api/audio/process\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -F \"file=@audio.mp3\" \\\n  -F \"source_language=en\" \\\n  -F \"target_language=de\" \\\n  -F \"template=MeetingMinutes\" \\\n  -F \"useCache=true\" \\\n  -F \"callback_url=https://your-client.example.com/webhook/audio\" \\\n  -F \"callback_token=YOUR_WEBHOOK_TOKEN\" \\\n  -F \"jobId=client-job-123\"\n</code></pre>"},{"location":"_secretary-service-docu/audio.html#response-success","title":"Response (Success)","text":"<p>Status Code: <code>200 OK</code></p> <pre><code>{\n  \"status\": \"success\",\n  \"request\": {\n    \"id\": \"process-id-123\",\n    \"timestamp\": \"2024-01-01T00:00:00Z\"\n  },\n  \"process\": {\n    \"duration_ms\": 5000,\n    \"llm_info\": {\n      \"total_tokens\": 1500,\n      \"total_cost\": 0.015,\n      \"requests\": [\n        {\n          \"model\": \"whisper-1\",\n          \"purpose\": \"transcription\",\n          \"tokens\": 1500,\n          \"duration_ms\": 4500\n        }\n      ]\n    }\n  },\n  \"data\": {\n    \"duration\": 120.5,\n    \"detected_language\": \"en\",\n    \"output_text\": \"Transcribed and transformed text...\",\n    \"original_text\": \"Original transcribed text...\",\n    \"translated_text\": \"Translated text...\",\n    \"llm_model\": \"whisper-1\",\n    \"translation_model\": \"gpt-4\",\n    \"token_count\": 1500,\n    \"segments\": [\n      {\n        \"id\": 0,\n        \"start\": 0.0,\n        \"end\": 10.5,\n        \"text\": \"First segment...\"\n      }\n    ],\n    \"process_id\": \"process-id-123\",\n    \"process_dir\": \"/path/to/process/dir\",\n    \"from_cache\": false\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/audio.html#response-accepted-async","title":"Response (Accepted, Async)","text":"<p>Status Code: <code>202 Accepted</code></p> <pre><code>{\n  \"status\": \"accepted\",\n  \"worker\": \"secretary\",\n  \"process\": {\n    \"id\": \"process-id-123\",\n    \"main_processor\": \"audio\",\n    \"started\": \"2026-01-01T00:00:00Z\",\n    \"is_from_cache\": false\n  },\n  \"job\": { \"id\": \"client-job-123\" },\n  \"webhook\": { \"delivered_to\": \"https://your-client.example.com/webhook/audio\" },\n  \"error\": null\n}\n</code></pre>"},{"location":"_secretary-service-docu/audio.html#webhook-payload-async-completion","title":"Webhook Payload (Async Completion)","text":"<p>The webhook receives one final message when finished. Webhook schema is standardized and uses <code>phase</code> = <code>progress</code> | <code>completed</code> | <code>error</code>.</p> <pre><code>{\n  \"phase\": \"completed\",\n  \"message\": \"Audio-Verarbeitung abgeschlossen\",\n  \"data\": {\n    \"transcription\": { \"text\": \"...\" }\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/audio.html#webhook-payload-progress","title":"Webhook Payload (Progress)","text":"<pre><code>{\n  \"phase\": \"progress\",\n  \"message\": \"Job initialisiert\",\n  \"job\": { \"id\": \"client-job-123\" },\n  \"data\": { \"progress\": 5 }\n}\n</code></pre> <p>On failure:</p> <pre><code>{\n  \"phase\": \"error\",\n  \"message\": \"Audio-Verarbeitung fehlgeschlagen\",\n  \"job\": { \"id\": \"client-job-123\" },\n  \"error\": {\n    \"code\": \"SomeError\",\n    \"message\": \"Details...\",\n    \"details\": { \"traceback\": \"...\" }\n  },\n  \"data\": null\n}\n</code></pre>"},{"location":"_secretary-service-docu/audio.html#job-status-full-results","title":"Job Status / Full Results","text":"<p>For async jobs you can query the job status and full stored results via:</p> <ul> <li><code>GET /api/jobs/&lt;job_id&gt;</code></li> </ul>"},{"location":"_secretary-service-docu/audio.html#response-error","title":"Response (Error)","text":"<p>Status Code: <code>400 Bad Request</code></p> <pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"INVALID_FORMAT\",\n    \"message\": \"The format 'xyz' is not supported. Supported formats: flac, m4a, mp3...\",\n    \"details\": {\n      \"error_type\": \"INVALID_FORMAT\",\n      \"supported_formats\": [\"flac\", \"m4a\", \"mp3\", ...]\n    }\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/audio.html#processing-flow","title":"Processing Flow","text":"<ol> <li>Audio file is uploaded and validated</li> <li>File is segmented into manageable chunks (if large)</li> <li>Each segment is transcribed using OpenAI Whisper API</li> <li>Optional: Text is transformed using template (via TransformerProcessor)</li> <li>Optional: Text is translated to target language</li> <li>Results are aggregated and returned</li> </ol>"},{"location":"_secretary-service-docu/audio.html#llm-tracking","title":"LLM Tracking","text":"<p>The response includes detailed LLM usage information: - Total tokens used - Total cost - Individual requests with model, purpose, tokens, duration</p>"},{"location":"_secretary-service-docu/audio.html#caching","title":"Caching","text":"<p>Results are cached based on: - File hash - Source language - Target language - Template name</p> <p>Use <code>useCache=false</code> to bypass cache and force reprocessing.</p>"},{"location":"_secretary-service-docu/overview.html","title":"API Reference Overview","text":"<p>Complete API reference for Common Secretary Services. All endpoints require authentication via API key unless otherwise noted.</p>"},{"location":"_secretary-service-docu/overview.html#authentication","title":"Authentication","text":"<p>All API requests require authentication via one of the following methods:</p> <ul> <li>Header: <code>Authorization: Bearer &lt;token&gt;</code></li> <li>Alternative Header: <code>X-Secretary-Api-Key: &lt;token&gt;</code></li> </ul> <p>The API key is configured via the <code>SECRETARY_SERVICE_API_KEY</code> environment variable.</p>"},{"location":"_secretary-service-docu/overview.html#exempt-paths","title":"Exempt Paths","text":"<p>The following paths do not require authentication: - <code>/api/doc</code> - Swagger UI documentation - <code>/api/swagger.json</code> - OpenAPI specification - <code>/api/health</code> - Health check endpoints</p>"},{"location":"_secretary-service-docu/overview.html#base-url","title":"Base URL","text":"<p>All endpoints are prefixed with <code>/api</code>. For example: - Production: <code>https://commonsecretaryservices.bcommonslab.org/api</code> - Local: <code>http://localhost:5001/api</code></p>"},{"location":"_secretary-service-docu/overview.html#interactive-documentation","title":"Interactive Documentation","text":"<p>The complete interactive API documentation is available via Swagger UI at: - <code>/api/doc</code> - Interactive API explorer</p>"},{"location":"_secretary-service-docu/overview.html#api-endpoints-by-category","title":"API Endpoints by Category","text":""},{"location":"_secretary-service-docu/overview.html#audio-processing","title":"Audio Processing","text":"<p>Namespace: <code>/api/audio</code></p> Method Endpoint Description POST <code>/api/audio/process</code> Process audio file with transcription and optional template-based transformation (supports async via webhook) <p>See: Audio Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#video-processing","title":"Video Processing","text":"<p>Namespace: <code>/api/video</code></p> Method Endpoint Description POST <code>/api/video/process</code> Process video file with audio extraction and transcription POST <code>/api/video/youtube</code> Process YouTube video with download and transcription POST <code>/api/video/frames</code> Extract frames from video at specific timestamps <p>See: Video Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#pdf-processing","title":"PDF Processing","text":"<p>Namespace: <code>/api/pdf</code></p> Method Endpoint Description POST <code>/api/pdf/process</code> Process PDF file with text extraction and OCR POST <code>/api/pdf/process-mistral-ocr</code> Process PDF with Mistral OCR transformation and parallel image extraction POST <code>/api/pdf/process-url</code> Process PDF from URL with text extraction and OCR GET <code>/api/pdf/text-content/&lt;path:file_path&gt;</code> Retrieve text content of a file created by PDF processor GET <code>/api/pdf/jobs/&lt;job_id&gt;/download-pages-archive</code> Download ZIP archive with PDF pages as images (Mistral OCR jobs only) GET <code>/api/pdf/jobs/&lt;job_id&gt;/mistral-ocr-raw</code> Download full Mistral OCR raw data (JSON) GET <code>/api/pdf/jobs/&lt;job_id&gt;/mistral-ocr-images</code> Download ZIP archive with Mistral OCR extracted images <p>See: PDF Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#image-ocr","title":"Image OCR","text":"<p>Namespace: <code>/api/imageocr</code></p> Method Endpoint Description POST <code>/api/imageocr/process</code> Process image file with OCR POST <code>/api/imageocr/process-url</code> Process image from URL with OCR <p>See: ImageOCR Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#text-transformation","title":"Text Transformation","text":"<p>Namespace: <code>/api/transformer</code></p> Method Endpoint Description POST <code>/api/transformer/text</code> Translate text between languages (with optional summarization) POST <code>/api/transformer/text/file</code> Transform text file (TXT, MD) between languages POST <code>/api/transformer/template</code> Transform text using template POST <code>/api/transformer/chat</code> Chat completion endpoint for direct LLM chat interactions POST <code>/api/transformer/html-table</code> Extract tables from HTML POST <code>/api/transformer/metadata</code> Extract metadata from files (images, videos, PDFs, documents) <p>See: Transformer Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#rag-embeddings","title":"RAG Embeddings","text":"<p>Namespace: <code>/api/rag</code></p> Method Endpoint Description POST <code>/api/rag/embed-text</code> Embed Markdown text and return chunks with embeddings (no backend storage) <p>See: RAG Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#session-processing","title":"Session Processing","text":"<p>Namespace: <code>/api/session</code></p> Method Endpoint Description POST <code>/api/session/process</code> Process session with URL and associated media POST <code>/api/session/process-async</code> Process session asynchronously with webhook GET <code>/api/session/cached</code> Retrieve cached sessions <p>See: Session Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#event-processing","title":"Event Processing","text":"<p>Namespace: <code>/api/events</code></p> Method Endpoint Description POST <code>/api/events/&lt;event_name&gt;/summary</code> Generate event summary <p>See: Event Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#track-processing","title":"Track Processing","text":"<p>Namespace: <code>/api/tracks</code></p> Method Endpoint Description POST <code>/api/tracks/&lt;track_name&gt;/summary</code> Generate track summary GET <code>/api/tracks/available</code> List all available tracks POST <code>/api/tracks/&lt;track_name&gt;/summarize_all</code> Summarize all tracks <p>See: Track Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#story-generation","title":"Story Generation","text":"<p>Namespace: <code>/api/story</code></p> Method Endpoint Description POST <code>/api/story/generate</code> Generate story from topic GET <code>/api/story/topics</code> List all available topics GET <code>/api/story/target-groups</code> List all available target groups <p>See: Story Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#job-management-secretary-jobs","title":"Job Management (Secretary Jobs)","text":"<p>Namespace: <code>/api/jobs</code></p> Method Endpoint Description POST <code>/api/jobs/</code> Create new job POST <code>/api/jobs/batch</code> Create batch of jobs GET <code>/api/jobs/&lt;job_id&gt;</code> Get job status and results GET <code>/api/jobs/batch/&lt;batch_id&gt;</code> Get batch status GET <code>/api/jobs/&lt;job_id&gt;/download-archive</code> Download job archive (ZIP) <p>See: Job Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#event-job-management-legacy","title":"Event Job Management (Legacy)","text":"<p>Namespace: <code>/api/event-job</code></p> Method Endpoint Description POST <code>/api/event-job/jobs</code> Create session job GET <code>/api/event-job/jobs/&lt;job_id&gt;</code> Get job details POST <code>/api/event-job/batches</code> Create batch GET <code>/api/event-job/batches/&lt;batch_id&gt;</code> Get batch details GET <code>/api/event-job/files/&lt;path&gt;</code> Download job file POST <code>/api/event-job/&lt;job_id&gt;/restart</code> Restart failed job GET <code>/api/event-job/batches/&lt;batch_id&gt;/archive</code> Download batch archive POST <code>/api/event-job/batches/&lt;batch_id&gt;/toggle-active</code> Toggle batch active status POST <code>/api/event-job/batches/fail-all</code> Fail all jobs in batch GET <code>/api/event-job/jobs/&lt;job_id&gt;/download-archive</code> Download job archive <p>See: Event Job Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#llm-configuration","title":"LLM Configuration","text":"<p>Namespace: <code>/api/llm-config</code></p> Method Endpoint Description GET <code>/api/llm-config</code> Get current LLM configuration with providers and use cases GET <code>/api/llm-config/providers</code> List all available providers GET <code>/api/llm-config/models</code> Get available models for provider and use case POST <code>/api/llm-config/test</code> Test connection to a provider GET <code>/api/llm-config/presets</code> Get preset configurations GET <code>/api/llm-config/available-models</code> Get overview of all available models per provider and use case <p>Note: These endpoints are not documented in separate endpoint files yet.</p>"},{"location":"_secretary-service-docu/overview.html#common-endpoints","title":"Common Endpoints","text":"<p>Namespace: <code>/api/common</code></p> Method Endpoint Description GET <code>/api/common/</code> API home endpoint POST <code>/api/common/notion</code> Process Notion blocks GET <code>/api/common/samples</code> List sample files GET <code>/api/common/samples/&lt;filename&gt;</code> Download sample file <p>See: Common Endpoints for detailed documentation.</p>"},{"location":"_secretary-service-docu/overview.html#root-endpoints","title":"Root Endpoints","text":"Method Endpoint Description GET <code>/api/</code> API welcome message GET <code>/api/samples</code> List sample files (alternative to <code>/api/common/samples</code>) GET <code>/api/samples/&lt;filename&gt;</code> Download sample file (alternative to <code>/api/common/samples/&lt;filename&gt;</code>)"},{"location":"_secretary-service-docu/overview.html#response-format","title":"Response Format","text":"<p>All API responses follow a standardized format:</p> <pre><code>{\n  \"status\": \"success\" | \"error\",\n  \"request\": {\n    \"id\": \"process-id\",\n    \"timestamp\": \"2024-01-01T00:00:00Z\"\n  },\n  \"process\": {\n    \"duration_ms\": 1234,\n    \"llm_info\": {\n      \"total_tokens\": 1000,\n      \"total_cost\": 0.01,\n      \"requests\": [...]\n    }\n  },\n  \"data\": {\n    // Processor-specific data\n  },\n  \"error\": {\n    \"code\": \"ERROR_CODE\",\n    \"message\": \"Error message\",\n    \"details\": {}\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/overview.html#error-handling","title":"Error Handling","text":"<p>Errors are returned with HTTP status codes:</p> <ul> <li><code>400</code> - Bad Request (validation errors)</li> <li><code>401</code> - Unauthorized (authentication required)</li> <li><code>403</code> - Forbidden (authentication failed)</li> <li><code>404</code> - Not Found (resource not found)</li> <li><code>500</code> - Internal Server Error (processing errors)</li> </ul> <p>Error responses include: - <code>code</code>: Error code identifier - <code>message</code>: Human-readable error message - <code>details</code>: Additional error information</p>"},{"location":"_secretary-service-docu/overview.html#rate-limiting","title":"Rate Limiting","text":"<p>Rate limiting is configured via <code>config.yaml</code>: - Default: 60 requests per minute per IP - Configurable via <code>rate_limiting.requests_per_minute</code></p>"},{"location":"_secretary-service-docu/overview.html#caching","title":"Caching","text":"<p>Most processors support caching: - Results are cached in MongoDB - Cache TTL is configurable per processor - Use <code>useCache=false</code> parameter to bypass cache</p>"},{"location":"_secretary-service-docu/overview.html#asynchronous-processing","title":"Asynchronous Processing","text":"<p>Some endpoints support asynchronous processing: - Jobs are created and processed in the background - Status can be queried via job endpoints - Webhooks can be configured for completion notifications</p>"},{"location":"_secretary-service-docu/overview.html#related-documentation","title":"Related Documentation","text":"<ul> <li>OpenAPI / Swagger - Interactive API documentation</li> <li>Data Models - Response data structures</li> <li>Configuration - Configuration options</li> </ul>"},{"location":"_secretary-service-docu/pdf.html","title":"PDF API Endpoints","text":"<p>Endpoints for PDF file processing with text extraction and OCR.</p>"},{"location":"_secretary-service-docu/pdf.html#post-apipdfprocess","title":"POST /api/pdf/process","text":"<p>Process a PDF file with text extraction and optional OCR.</p>"},{"location":"_secretary-service-docu/pdf.html#request","title":"Request","text":"<p>Content-Type: <code>multipart/form-data</code></p> <p>Parameters:</p> Parameter Type Required Default Description <code>file</code> File Yes - PDF file <code>extraction_method</code> String No <code>native</code> Extraction method: <code>native</code>, <code>tesseract_ocr</code>, <code>both</code>, <code>preview</code>, <code>preview_and_native</code>, <code>llm</code>, <code>llm_and_native</code>, <code>llm_and_ocr</code> <code>template</code> String No <code>\"\"</code> Optional template for text transformation <code>context</code> JSON No <code>{}</code> Additional context for template <code>useCache</code> Boolean No <code>true</code> Whether to use cache <code>includeImages</code> Boolean No <code>false</code> Base64-kodiertes ZIP-Archiv mit generierten Bildern erstellen <code>page_start</code> Integer No - Start page (1-indexed) <code>page_end</code> Integer No - End page (1-indexed) <code>target_language</code> String No - Optional: Zielsprache (z.B. <code>de</code>) f\u00fcr nachgelagerte Template-Verarbeitung <code>callback_url</code> String No - Optional: Webhook-URL f\u00fcr asynchrone Verarbeitung (Endpoint antwortet mit <code>202 Accepted</code>) <code>callback_token</code> String No - Optional: Token f\u00fcr Webhook-Auth (<code>Authorization: Bearer ...</code> und <code>X-Callback-Token</code>) <code>jobId</code> String No - Optional: Externe Job-ID (client-generated), wird im 202 ACK als <code>job.id</code> zur\u00fcckgegeben <code>wait_ms</code> Integer No <code>0</code> Optional: Wartezeit (ms) auf Abschluss (nur ohne <code>callback_url</code>) <code>force_refresh</code> Boolean No - Optional: Cache umgehen/Neuberechnung erzwingen"},{"location":"_secretary-service-docu/pdf.html#extraction-methods","title":"Extraction Methods","text":"<ul> <li>native: Extract text directly from PDF structure (fastest)</li> <li>tesseract_ocr: Use Tesseract OCR for text extraction</li> <li>both: Native + Tesseract OCR</li> <li>preview: Create preview images only</li> <li>preview_and_native: Preview images + native text</li> <li>llm: LLM-based OCR</li> <li>llm_and_native: LLM OCR + native text</li> <li>llm_and_ocr: LLM OCR + Tesseract OCR</li> </ul> <p>Note: For Mistral OCR transformation with integrated images, use the dedicated endpoint <code>POST /api/pdf/process-mistral-ocr</code> instead.</p>"},{"location":"_secretary-service-docu/pdf.html#async-processing-via-webhook-optional","title":"Async Processing via Webhook (optional)","text":"<p>Wenn du <code>callback_url</code> setzt, wird der Request asynchron abgearbeitet:</p> <ul> <li>Der Endpoint antwortet sofort mit <code>202 Accepted</code> (ACK).</li> <li>Die Verarbeitung l\u00e4uft im Secretary Worker (Job Queue).</li> <li>Am Ende sendet der Worker einen finalen Webhook (<code>phase=completed</code> oder <code>phase=error</code>).</li> </ul> <p>Job-Status und vollst\u00e4ndige Ergebnisse k\u00f6nnen zus\u00e4tzlich \u00fcber <code>GET /api/jobs/&lt;job_id&gt;</code> abgefragt werden.</p>"},{"location":"_secretary-service-docu/pdf.html#request-example","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/pdf/process\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -F \"file=@document.pdf\" \\\n  -F \"extraction_method=combined\" \\\n  -F \"template=MeetingMinutes\" \\\n  -F \"includeImages=true\"\n</code></pre>"},{"location":"_secretary-service-docu/pdf.html#response-success","title":"Response (Success)","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"extracted_text\": \"Full extracted text from PDF...\",\n    \"metadata\": {\n      \"page_count\": 10,\n      \"author\": \"Author Name\",\n      \"title\": \"Document Title\",\n      \"text_contents\": [\n        {\n          \"page\": 1,\n          \"text\": \"Page 1 text...\",\n          \"method\": \"native\"\n        }\n      ],\n      \"image_paths\": [\n        \"/path/to/page_1.jpg\",\n        \"/path/to/page_2.jpg\"\n      ]\n    },\n    \"images_archive_filename\": \"document_images.zip\",\n    \"images_archive_data\": \"base64_encoded_zip_data\"\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/pdf.html#post-apipdfprocess-mistral-ocr","title":"POST /api/pdf/process-mistral-ocr","text":"<p>Process a PDF file with Mistral OCR transformation and parallel page image extraction.</p> <p>This endpoint is specifically designed for Mistral OCR transformation with integrated images. It runs two processes in parallel: 1. Mistral OCR Transformation: Converts PDF to Markdown with embedded images (recognized by Mistral OCR) 2. Page Image Extraction: Extracts PDF pages as images and returns them as a ZIP archive</p>"},{"location":"_secretary-service-docu/pdf.html#request_1","title":"Request","text":"<p>Content-Type: <code>multipart/form-data</code></p> <p>Parameters:</p> Parameter Type Required Default Description <code>file</code> File Yes - PDF file <code>page_start</code> Integer No - Start page (1-indexed) <code>page_end</code> Integer No - End page (1-indexed, inclusive) <code>includeOCRImages</code> Boolean No <code>true</code> Hinweis: Der Server liefert Bilder nicht als Base64 im <code>mistral_ocr_raw</code> zur\u00fcck. Bilder werden immer separat extrahiert und \u00fcber <code>mistral_ocr_images_url</code> / Download-Endpoint bereitgestellt. Empfehlung: <code>includeOCRImages=false</code>, um Payload/Overhead zu reduzieren. <code>includePageImages</code> Boolean No <code>true</code> Extract PDF pages as images and return as ZIP archive. Runs in parallel to Mistral OCR transformation. <code>useCache</code> Boolean No <code>true</code> Whether to use cache <code>callback_url</code> String No - Absolute HTTPS URL for webhook callback <code>callback_token</code> String No - Per-job secret for webhook callback <code>jobId</code> String No - Unique job ID for callback <code>wait_ms</code> Integer No <code>0</code> Optional: Wait time in milliseconds for completion (only without callback_url)"},{"location":"_secretary-service-docu/pdf.html#request-example_1","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/pdf/process-mistral-ocr\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -F \"file=@document.pdf\" \\\n  -F \"includeOCRImages=true\" \\\n  -F \"includePageImages=true\" \\\n  -F \"page_start=1\" \\\n  -F \"page_end=10\"\n</code></pre>"},{"location":"_secretary-service-docu/pdf.html#response-success_1","title":"Response (Success)","text":"<p>Important: Images are NEVER embedded in <code>mistral_ocr_raw</code>. They are always extracted and stored separately. Use <code>mistral_ocr_images_url</code> to download images.</p> <pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"extracted_text\": \"--- Seite 1 ---\\n![img-0.jpeg](img-0.jpeg)\\n\\nText content...\",\n    \"metadata\": {\n      \"page_count\": 10,\n      \"file_name\": \"document.pdf\",\n      \"file_size\": 753504,\n      \"extraction_method\": \"mistral_ocr_with_pages\"\n    },\n    \"mistral_ocr_raw\": {\n      \"pages\": [\n        {\n          \"index\": 0,\n          \"markdown\": \"![img-0.jpeg](img-0.jpeg)\\n\\nText content...\",\n          \"images\": [\n            {\n              \"id\": \"img-0.jpeg\",\n              \"top_left_x\": 93,\n              \"top_left_y\": 221,\n              \"bottom_right_x\": 1577,\n              \"bottom_right_y\": 508\n            }\n          ]\n        }\n      ],\n      \"model\": \"mistral-ocr-latest\",\n      \"usage_info\": {\n        \"pages_processed\": 10,\n        \"doc_size_bytes\": 753504\n      }\n    },\n    \"mistral_ocr_images_url\": \"/api/pdf/jobs/{job_id}/mistral-ocr-images\",\n    \"pages_archive_filename\": \"pages.zip\",\n    \"pages_archive_data\": \"base64_encoded_zip_data\",\n    \"images_archive_data\": null,\n    \"images_archive_filename\": null\n  }\n}\n</code></pre> <p>For async jobs (with <code>callback_url</code> or <code>wait_ms=0</code>), the webhook callback structure differs:</p> <pre><code>{\n  \"phase\": \"completed\",\n  \"message\": \"Extraktion abgeschlossen\",\n  \"data\": {\n    \"extracted_text\": \"--- Seite 1 ---\\n![img-0.jpeg](img-0.jpeg)\\n\\nText content...\",\n    \"metadata\": {\n      \"text_contents\": [...]\n    },\n    \"mistral_ocr_raw_url\": \"/api/pdf/jobs/{job_id}/mistral-ocr-raw\",\n    \"mistral_ocr_raw_metadata\": {\n      \"model\": \"mistral-ocr-latest\",\n      \"pages_count\": 235,\n      \"usage_info\": {\n        \"pages_processed\": 235,\n        \"doc_size_bytes\": 7094411\n      }\n    },\n    \"pages_archive_url\": \"/api/pdf/jobs/{job_id}/download-pages-archive\"\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/pdf.html#response-structure","title":"Response Structure","text":"<p>The response contains two types of images:</p> <ol> <li>Mistral OCR Images:</li> <li>IMPORTANT: Images are NEVER embedded in <code>mistral_ocr_raw</code>. They are ALWAYS extracted and stored separately.</li> <li>Images recognized and extracted by Mistral OCR</li> <li>Embedded in the Markdown text as references (e.g., <code>![img-0.jpeg](img-0.jpeg)</code>)</li> <li>Available as separate files in a ZIP archive</li> <li>Include coordinates and annotations in <code>mistral_ocr_raw</code> (without image data)</li> <li>Download: Use <code>mistral_ocr_images_url</code> in webhook callback or <code>GET /api/pdf/jobs/{job_id}/mistral-ocr-images</code> endpoint</li> <li> <p>Note: <code>mistral_ocr_raw</code> contains image metadata (IDs, coordinates, etc.) but NO image data</p> </li> <li> <p>Page Images (<code>data.pages_archive_data</code>):</p> </li> <li>All PDF pages converted to images</li> <li>Packaged as a Base64-encoded ZIP archive</li> <li>Filename available in <code>data.pages_archive_filename</code></li> <li>Extracted in parallel to Mistral OCR processing</li> <li>For async jobs, use <code>data.pages_archive_url</code> to download</li> </ol>"},{"location":"_secretary-service-docu/pdf.html#differences-to-apipdfprocess","title":"Differences to <code>/api/pdf/process</code>","text":"<ul> <li>Dedicated endpoint: Simplified interface specifically for Mistral OCR workflows</li> <li>Parallel processing: Page image extraction runs in parallel to OCR transformation</li> <li>Two image types: Returns both Mistral OCR images and page images</li> <li>No template support: Focused on OCR transformation only</li> <li>Simplified parameters: Fewer options, clearer purpose</li> </ul>"},{"location":"_secretary-service-docu/pdf.html#use-cases","title":"Use Cases","text":"<ul> <li>Document digitization with full page images and OCR results</li> <li>Archival systems requiring both searchable text and page images</li> <li>Quality assurance workflows comparing OCR results with original pages</li> <li>Multi-format export (Markdown with embedded images + page images)</li> </ul>"},{"location":"_secretary-service-docu/pdf.html#downloading-page-images-archive","title":"Downloading Page Images Archive","text":"<p>There are two ways to download the ZIP archive with PDF pages as images:</p>"},{"location":"_secretary-service-docu/pdf.html#option-1-direct-from-response-base64","title":"Option 1: Direct from Response (Base64)","text":"<p>The <code>pages_archive_data</code> field in the response contains the ZIP file as a Base64-encoded string. You can decode it directly:</p> <pre><code>// Extract from response\nconst response = await fetch('/api/pdf/process-mistral-ocr', {...});\nconst data = await response.json();\n\nif (data.data.pages_archive_data) {\n  // Decode Base64 to binary\n  const binaryString = atob(data.data.pages_archive_data);\n  const bytes = new Uint8Array(binaryString.length);\n  for (let i = 0; i &lt; binaryString.length; i++) {\n    bytes[i] = binaryString.charCodeAt(i);\n  }\n\n  // Create blob and download\n  const blob = new Blob([bytes], { type: 'application/zip' });\n  const url = URL.createObjectURL(blob);\n  const a = document.createElement('a');\n  a.href = url;\n  a.download = data.data.pages_archive_filename || 'pages.zip';\n  a.click();\n  URL.revokeObjectURL(url);\n}\n</code></pre> <pre><code>import base64\n\n# Extract from response\nresponse_data = {...}  # Your API response\n\nif response_data.get('data', {}).get('pages_archive_data'):\n    # Decode Base64\n    archive_data = base64.b64decode(response_data['data']['pages_archive_data'])\n    filename = response_data['data'].get('pages_archive_filename', 'pages.zip')\n\n    # Save to file\n    with open(filename, 'wb') as f:\n        f.write(archive_data)\n</code></pre>"},{"location":"_secretary-service-docu/pdf.html#option-2-download-endpoint-for-async-jobs","title":"Option 2: Download Endpoint (for Async Jobs)","text":"<p>If you're using async job processing (with <code>callback_url</code> or <code>wait_ms=0</code>), you can download the archive via a dedicated endpoint:</p> <p>Endpoint: <code>GET /api/pdf/jobs/{job_id}/download-pages-archive</code></p> <p>Example: <pre><code>curl -X GET \"http://localhost:5001/api/pdf/jobs/{job_id}/download-pages-archive\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -o pages.zip\n</code></pre></p> <p>Response: Binary ZIP file with <code>Content-Type: application/zip</code> and <code>Content-Disposition: attachment</code></p> <p>Status Codes: - <code>200</code>: Success - ZIP file returned - <code>202</code>: Processing - Job still running, try again later - <code>400</code>: No archive available (check if <code>includePageImages=true</code> was set) - <code>404</code>: Job not found - <code>500</code>: Server error</p> <p>Note: The download endpoint only works for jobs that were processed with <code>includePageImages=true</code>. The archive is stored in the job results and can be downloaded even after the initial response.</p>"},{"location":"_secretary-service-docu/pdf.html#downloading-mistral-ocr-raw-data","title":"Downloading Mistral OCR Raw Data","text":"<p>For large documents, <code>mistral_ocr_raw</code> is stored as a separate JSON file instead of being included in the response or MongoDB. You can download it via a dedicated endpoint:</p> <p>Endpoint: <code>GET /api/pdf/jobs/{job_id}/mistral-ocr-raw</code></p> <p>Example: <pre><code>curl -X GET \"http://localhost:5001/api/pdf/jobs/{job_id}/mistral-ocr-raw\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -o mistral_ocr_raw.json\n</code></pre></p> <p>Response: JSON file with <code>Content-Type: application/json</code> and <code>Content-Disposition: attachment</code></p> <p>Status Codes: - <code>200</code>: Success - JSON file returned - <code>202</code>: Processing - Job still running, try again later - <code>400</code>: No Mistral OCR data available - <code>404</code>: Job not found - <code>500</code>: Server error</p> <p>Note: This endpoint is only available for jobs processed with the Mistral OCR endpoint (<code>/api/pdf/process-mistral-ocr</code>). The file contains the complete Mistral OCR response WITHOUT image data. Images are stored separately and must be downloaded via the <code>mistral_ocr_images_url</code> endpoint.</p>"},{"location":"_secretary-service-docu/pdf.html#downloading-mistral-ocr-images","title":"Downloading Mistral OCR Images","text":"<p>Mistral OCR images are always stored separately and never embedded in <code>mistral_ocr_raw</code>. Download them via a dedicated endpoint:</p> <p>Endpoint: <code>GET /api/pdf/jobs/{job_id}/mistral-ocr-images</code></p> <p>Example: <pre><code>curl -X GET \"http://localhost:5001/api/pdf/jobs/{job_id}/mistral-ocr-images\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -o mistral_ocr_images.zip\n</code></pre></p> <p>Response: Binary ZIP file with <code>Content-Type: application/zip</code> and <code>Content-Disposition: attachment</code></p> <p>Status Codes: - <code>200</code>: Success - ZIP file returned - <code>202</code>: Processing - Job still running, try again later - <code>400</code>: No Mistral OCR images available - <code>404</code>: Job not found - <code>500</code>: Server error</p> <p>Note: This endpoint is only available for jobs processed with the Mistral OCR endpoint (<code>/api/pdf/process-mistral-ocr</code>). The ZIP file contains all images extracted from the Mistral OCR response. Image references in the Markdown text (e.g., <code>![img-0.jpeg](img-0.jpeg)</code>) correspond to files in this ZIP archive.</p>"},{"location":"_secretary-service-docu/pdf.html#error-handling","title":"Error Handling","text":"<p>If MongoDB document size limits are exceeded (e.g., for very large documents with many images), an error webhook is sent:</p> <pre><code>{\n  \"phase\": \"error\",\n  \"message\": \"Fehler beim Speichern der Ergebnisse\",\n  \"error\": {\n    \"code\": \"DocumentTooLarge\",\n    \"message\": \"'update' command document too large\",\n    \"details\": {\n      \"error_type\": \"mongodb_document_too_large\",\n      \"suggestion\": \"mistral_ocr_raw wurde als separate Datei gespeichert und kann \u00fcber die API abgerufen werden\"\n    }\n  },\n  \"data\": {\n    \"extracted_text\": \"...\",\n    \"mistral_ocr_raw_url\": \"/api/pdf/jobs/{job_id}/mistral-ocr-raw\"\n  }\n}\n</code></pre> <p>In this case, the processing completed successfully, but the results were too large to store in MongoDB. The <code>mistral_ocr_raw</code> data is still available via the download endpoint.</p>"},{"location":"_secretary-service-docu/pdf.html#post-apipdfjob-deprecated-nicht-mehr-aktuell","title":"POST /api/pdf/job (Deprecated / nicht mehr aktuell)","text":"<p>Dieser Abschnitt ist nicht mehr aktuell: Im aktuellen System wird Async-Processing \u00fcber <code>POST /api/pdf/process</code> bzw. <code>POST /api/pdf/process-mistral-ocr</code> mit <code>callback_url</code> (Webhook) realisiert, oder generisch \u00fcber <code>POST /api/jobs/</code> (Job-Queue).</p>"},{"location":"_secretary-service-docu/pdf.html#request_2","title":"Request","text":"<p>Content-Type: <code>application/json</code></p> <p>Body:</p> <pre><code>{\n  \"filename\": \"/path/to/file.pdf\",\n  \"extraction_method\": \"combined\",\n  \"template\": \"MeetingMinutes\",\n  \"use_cache\": true,\n  \"webhook\": {\n    \"url\": \"https://example.com/webhook\",\n    \"token\": \"webhook_token\",\n    \"jobId\": \"client_job_id\"\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/pdf.html#response-success_2","title":"Response (Success)","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"job_id\": \"job-id-123\",\n    \"status\": \"pending\"\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/pdf.html#job-status","title":"Job Status","text":"<p>Query job status via <code>/api/jobs/{job_id}</code>:</p> <pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"job_id\": \"job-id-123\",\n    \"status\": \"completed\",\n    \"progress\": {\n      \"step\": \"completed\",\n      \"percent\": 100,\n      \"message\": \"Processing completed\"\n    },\n    \"results\": {\n      \"structured_data\": {\n        \"extracted_text\": \"...\",\n        \"metadata\": {...}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/text2image.html","title":"Text2Image API Endpoints","text":"<p>Endpoints for text-to-image generation using configured LLM providers (e.g., OpenRouter with DALL-E models).</p>"},{"location":"_secretary-service-docu/text2image.html#post-apitext2imagegenerate","title":"POST /api/text2image/generate","text":"<p>Generate an image from a text prompt.</p>"},{"location":"_secretary-service-docu/text2image.html#request","title":"Request","text":"<p>Content-Type: <code>application/json</code> oder <code>multipart/form-data</code></p> <p>Parameters:</p> Parameter Type Required Default Description <code>prompt</code> String Yes - Text prompt for image generation <code>size</code> String No <code>1024x1024</code> Image size (e.g., \"1024x1024\", \"1792x1024\", \"1024x1792\") <code>quality</code> String No <code>standard</code> Image quality (\"standard\" or \"hd\") <code>n</code> Integer No <code>1</code> Number of images (most models support only n=1) <code>seed</code> Integer No - Optional seed for reproducibility <code>seeds</code> Array/String No - Optional list of seeds (JSON array or comma-separated string) <code>useCache</code> Boolean No <code>true</code> Whether to use cache"},{"location":"_secretary-service-docu/text2image.html#supported-sizes","title":"Supported Sizes","text":"<ul> <li><code>1024x1024</code> - Square image (default)</li> <li><code>1792x1024</code> - Landscape image</li> <li><code>1024x1792</code> - Portrait image</li> </ul>"},{"location":"_secretary-service-docu/text2image.html#request-example-json","title":"Request Example (JSON)","text":"<pre><code>curl -X POST \"http://localhost:5001/api/text2image/generate\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"prompt\": \"A serene mountain lake at sunset with snow-capped peaks in the background\",\n    \"size\": \"1024x1024\",\n    \"quality\": \"standard\",\n    \"useCache\": true\n  }'\n</code></pre>"},{"location":"_secretary-service-docu/text2image.html#request-example-json-4-vorschauen-mit-seeds","title":"Request Example (JSON, 4 Vorschauen mit Seeds)","text":"<pre><code>curl -X POST \"http://localhost:5001/api/text2image/generate\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"prompt\": \"A serene mountain lake at sunset with snow-capped peaks in the background\",\n    \"size\": \"256x256\",\n    \"quality\": \"standard\",\n    \"n\": 4,\n    \"seeds\": [101, 102, 103, 104],\n    \"useCache\": false\n  }'\n</code></pre>"},{"location":"_secretary-service-docu/text2image.html#request-example-form-data","title":"Request Example (Form Data)","text":"<pre><code>curl -X POST \"http://localhost:5001/api/text2image/generate\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -F \"prompt=A serene mountain lake at sunset with snow-capped peaks in the background\" \\\n  -F \"size=1024x1024\" \\\n  -F \"quality=standard\" \\\n  -F \"useCache=true\"\n</code></pre>"},{"location":"_secretary-service-docu/text2image.html#response-success","title":"Response (Success)","text":"<p>Status Code: <code>200 OK</code></p> <pre><code>{\n  \"status\": \"success\",\n  \"request\": {\n    \"processor\": \"text2image\",\n    \"timestamp\": \"2024-01-01T00:00:00Z\",\n    \"parameters\": {\n      \"prompt\": \"A serene mountain lake at sunset...\",\n      \"size\": \"1024x1024\",\n      \"quality\": \"standard\",\n      \"n\": 1\n    }\n  },\n  \"process\": {\n    \"id\": \"process-id-123\",\n    \"main_processor\": \"text2image\",\n    \"started\": \"2024-01-01T00:00:00Z\",\n    \"completed\": \"2024-01-01T00:00:05Z\",\n    \"duration\": 5000.0,\n    \"sub_processors\": [],\n    \"llm_info\": {\n      \"total_tokens\": 150,\n      \"total_cost\": 0.02,\n      \"requests\": [\n        {\n          \"model\": \"openai/dall-e-3\",\n          \"purpose\": \"text2image\",\n          \"tokens\": 150,\n          \"duration_ms\": 4500,\n          \"processor\": \"OpenRouterProvider\"\n        }\n      ]\n    },\n    \"is_from_cache\": false,\n    \"cache_key\": null\n  },\n  \"data\": {\n    \"image_base64\": \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==\",\n    \"image_format\": \"png\",\n    \"size\": \"1024x1024\",\n    \"model\": \"openai/dall-e-3\",\n    \"prompt\": \"A serene mountain lake at sunset with snow-capped peaks in the background\",\n    \"seed\": null,\n    \"images\": [\n      {\n        \"image_base64\": \"iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==\",\n        \"image_format\": \"png\",\n        \"size\": \"1024x1024\",\n        \"seed\": 101\n      }\n    ]\n  },\n  \"error\": null\n}\n</code></pre>"},{"location":"_secretary-service-docu/text2image.html#response-error","title":"Response (Error)","text":"<p>Status Code: <code>400 Bad Request</code> or <code>500 Internal Server Error</code></p> <pre><code>{\n  \"status\": \"error\",\n  \"request\": {\n    \"processor\": \"text2image\",\n    \"timestamp\": \"2024-01-01T00:00:00Z\",\n    \"parameters\": {}\n  },\n  \"process\": {\n    \"id\": \"process-id-123\",\n    \"main_processor\": \"text2image\",\n    \"started\": \"2024-01-01T00:00:00Z\",\n    \"completed\": null,\n    \"duration\": null,\n    \"sub_processors\": [],\n    \"llm_info\": null,\n    \"is_from_cache\": false,\n    \"cache_key\": null\n  },\n  \"data\": null,\n  \"error\": {\n    \"code\": \"MISSING_PROMPT\",\n    \"message\": \"Prompt darf nicht leer sein\",\n    \"details\": {}\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/text2image.html#error-codes","title":"Error Codes","text":"Code Description <code>MISSING_PROMPT</code> Prompt parameter is missing or empty <code>INVALID_SIZE</code> Invalid size format (must be WIDTHxHEIGHT) <code>INVALID_QUALITY</code> Invalid quality (must be \"standard\" or \"hd\") <code>PROVIDER_NOT_CONFIGURED</code> No provider configured for text2image use case <code>MODEL_NOT_CONFIGURED</code> No model configured for text2image use case <code>TEXT2IMAGE_ERROR</code> Error during image generation <code>INTERNAL_ERROR</code> Unexpected internal error"},{"location":"_secretary-service-docu/text2image.html#configuration","title":"Configuration","text":"<p>The text2image endpoint requires configuration in <code>config.yaml</code>:</p> <pre><code>llm_config:\n  use_cases:\n    text2image:\n      provider: openrouter\n      model: openai/dall-e-3\n\nllm_providers:\n  openrouter:\n    available_models:\n      text2image:\n        - openai/dall-e-3\n        - stability-ai/stable-diffusion-xl-base-1.0\n        - black-forest-labs/flux-pro\n        - black-forest-labs/flux-schnell\n</code></pre>"},{"location":"_secretary-service-docu/text2image.html#notes","title":"Notes","text":"<ul> <li>The generated image is returned as base64-encoded data in the <code>data.image_base64</code> field</li> <li>For multiple images, the first image is mirrored in <code>data.image_base64</code> for backward compatibility</li> <li>Use <code>data.images[*].seed</code> to re-generate a selected preview in higher resolution</li> <li>To display the image in a client, build a data URL with the reported format:   <code>data:image/{image_format};base64,{image_base64}</code></li> <li>Example (Browser):   <pre><code>const imageDataUrl = `data:image/${response.data.image_format};base64,${response.data.image_base64}`;\ndocument.querySelector(\"img\").src = imageDataUrl;\n</code></pre></li> <li>Caching is enabled by default and uses a hash of the prompt, size, quality, model, and n parameters</li> <li>Most image generation models support only <code>n=1</code> (single image generation)</li> <li>The <code>seed</code> parameter can be used for reproducible image generation (if supported by the model)</li> </ul>"},{"location":"_secretary-service-docu/transformer.html","title":"Transformer API Endpoints","text":"<p>Endpoints for text transformation, translation, and template processing.</p>"},{"location":"_secretary-service-docu/transformer.html#post-apitransformertext","title":"POST /api/transformer/text","text":"<p>Translate text between languages.</p>"},{"location":"_secretary-service-docu/transformer.html#request","title":"Request","text":"<p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Body Parameters:</p> <ul> <li><code>text</code> (required): Text to translate</li> <li><code>source_language</code> (required): Source language (ISO 639-1 code, e.g., \"en\", \"de\")</li> <li><code>target_language</code> (required): Target language (ISO 639-1 code, e.g., \"en\", \"de\")</li> <li><code>summarize</code> (optional): Whether to summarize the text (true/false, default: false)</li> <li><code>target_format</code> (optional): Target format (TEXT, HTML, MARKDOWN, JSON)</li> <li><code>context</code> (optional): JSON string with context for transformation</li> <li><code>use_cache</code> (optional): Whether to use cache (true/false, default: true)</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#request-example","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/text\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"text=Hello, world!\" \\\n  -d \"source_language=en\" \\\n  -d \"target_language=de\" \\\n  -d \"use_cache=true\"\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#response-success","title":"Response (Success)","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"original_text\": \"Hello, world!\",\n    \"translated_text\": \"Hallo, Welt!\",\n    \"source_language\": \"en\",\n    \"target_language\": \"de\"\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#post-apitransformertemplate","title":"POST /api/transformer/template","text":"<p>Transform text using a template.</p>"},{"location":"_secretary-service-docu/transformer.html#authentication","title":"Authentication","text":"<p>Required Headers (one of the following):</p> <ul> <li><code>Authorization: Bearer &lt;YOUR_API_KEY&gt;</code> (recommended)</li> <li><code>X-Secretary-Api-Key: &lt;YOUR_API_KEY&gt;</code> (alternative)</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#request_1","title":"Request","text":"<p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Body Parameters:</p> <ul> <li><code>text</code> (optional): Input text to transform (required if <code>url</code> not provided)</li> <li><code>url</code> (optional): URL of the webpage (required if <code>text</code> not provided)</li> <li><code>template</code> (optional): Template name (without .md extension, required if <code>template_content</code> not provided)</li> <li><code>template_content</code> (optional): Direct template content (Markdown, required if <code>template</code> not provided)</li> <li><code>source_language</code> (optional): Source language (ISO 639-1 code, default: \"de\")</li> <li><code>target_language</code> (optional): Target language (ISO 639-1 code, default: \"de\")</li> <li><code>context</code> (optional): JSON string with context for template processing</li> <li><code>additional_field_descriptions</code> (optional): JSON string with additional field descriptions</li> <li><code>use_cache</code> (optional): Whether to use cache (true/false, default: true)</li> <li><code>container_selector</code> (optional): CSS selector for event container (e.g., \"li.single-element\")</li> <li><code>callback_url</code> (optional): Absolute HTTPS URL for webhook callback</li> <li><code>callback_token</code> (optional): Per-job secret for webhook callback</li> <li><code>jobId</code> (optional): Unique job ID for callback</li> <li><code>wait_ms</code> (optional): Wait time in milliseconds for completion (only without callback_url, default: 0)</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#alternative-template-content","title":"Alternative: Template Content","text":"<p>Instead of template name, provide template content directly:</p> <pre><code>curl -X POST \"http://localhost:5001/api/transformer/template\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"text=Input text\" \\\n  -d \"template_content=Extract: {summary}\\nParticipants: {participants}\" \\\n  -d 'additional_field_descriptions={\"summary\":\"Brief summary\",\"participants\":\"List of participants\"}'\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#request-example_1","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/template\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"text=Meeting notes...\" \\\n  -d \"template=MeetingMinutes\" \\\n  -d \"source_language=en\" \\\n  -d 'context={\"meeting_date\":\"2024-01-01\",\"participants\":[\"Alice\",\"Bob\"]}'\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#response-success_1","title":"Response (Success)","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"original_text\": \"Meeting notes...\",\n    \"transformed_text\": \"Structured meeting minutes...\",\n    \"template_fields\": {\n      \"summary\": \"Meeting summary\",\n      \"participants\": [\"Alice\", \"Bob\"],\n      \"action_items\": [...]\n    }\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#post-apitransformerhtml-table","title":"POST /api/transformer/html-table","text":"<p>Extract tables from HTML webpage.</p>"},{"location":"_secretary-service-docu/transformer.html#request_2","title":"Request","text":"<p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Body Parameters:</p> <ul> <li><code>source_url</code> (required): URL of the webpage containing HTML tables</li> <li><code>output_format</code> (optional): Output format (currently only \"json\" supported, default: \"json\")</li> <li><code>table_index</code> (optional): Index of the desired table (0-based)</li> <li><code>start_row</code> (optional): Start row for paging (0-based)</li> <li><code>row_count</code> (optional): Number of rows to return</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#request-example_2","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/html-table\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"source_url=https://example.com/table-page\" \\\n  -d \"output_format=json\" \\\n  -d \"table_index=0\" \\\n  -d \"start_row=0\" \\\n  -d \"row_count=10\"\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#response-success_2","title":"Response (Success)","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"input\": {\n      \"text\": \"https://example.com/table-page\",\n      \"language\": \"\",\n      \"format\": \"URL\"\n    },\n    \"output\": {\n      \"text\": \"JSON representation of tables\",\n      \"language\": \"\",\n      \"format\": \"JSON\",\n      \"structured_data\": {\n        \"url\": \"https://example.com/table-page\",\n        \"table_count\": 1,\n        \"tables\": [\n          {\n            \"table_index\": 0,\n            \"headers\": [\"Column 1\", \"Column 2\"],\n            \"rows\": [\n              {\"Column 1\": \"Value 1\", \"Column 2\": \"Value 2\"}\n            ],\n            \"metadata\": {\n              \"total_rows\": 1,\n              \"column_count\": 2,\n              \"has_group_info\": false,\n              \"paging\": {\n                \"start_row\": 0,\n                \"row_count\": 1,\n                \"has_more\": false\n              }\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#post-apitransformerchat","title":"POST /api/transformer/chat","text":"<p>LLM Broker endpoint for chat completions. This endpoint is the single integration point for all LLM usage in the app. Clients are LLM consumers: they send <code>messages</code> and optionally request structured output (with a schema). The Transformer is the broker: it chooses the provider, enforces output contracts, validates structured output, and returns a stable response format.</p>"},{"location":"_secretary-service-docu/transformer.html#authentication_1","title":"Authentication","text":"<p>Required Headers (one of the following):</p> <ul> <li><code>Authorization: Bearer &lt;YOUR_API_KEY&gt;</code> (recommended)</li> <li><code>X-Secretary-Api-Key: &lt;YOUR_API_KEY&gt;</code> (alternative)</li> </ul> <p>Both headers are accepted. The API key must match the <code>SECRETARY_SERVICE_API_KEY</code> environment variable.</p>"},{"location":"_secretary-service-docu/transformer.html#request_3","title":"Request","text":"<p>Content-Type: <code>application/x-www-form-urlencoded</code></p> <p>Body Parameters:</p> <ul> <li><code>messages</code> (required): JSON string with list of messages in format <code>[{\"role\": \"system|user|assistant\", \"content\": \"...\"}]</code></li> <li><code>model</code> (optional): Model name (uses default from config if not provided)</li> <li><code>provider</code> (optional): Provider name (uses default from config if not provided)</li> <li><code>temperature</code> (optional): Temperature for response (0.0-2.0, default: 0.7)</li> <li><code>max_tokens</code> (optional): Maximum number of tokens</li> <li><code>stream</code> (optional): Whether to enable streaming (default: false, currently not supported)</li> <li><code>use_cache</code> (optional): Whether to use cache (true/false, default: true)</li> <li>Note: Cache applies to structured requests as well. Cached responses maintain their <code>structured_data</code> format.</li> <li><code>timeout_ms</code> (optional): Request timeout in milliseconds</li> <li>Note: Server may clamp timeout to a maximum value (implementation-dependent)</li> <li>If not provided, uses provider default timeout</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#structured-output-optional-recommended-for-app-features","title":"Structured Output (optional, recommended for app features)","text":"<ul> <li><code>response_format</code> (optional): <code>text</code> | <code>json_object</code> (default: <code>text</code>)</li> <li><code>text</code>: normal text response</li> <li><code>json_object</code>: broker guarantees that <code>data.structured_data</code> is a JSON object (never null when <code>status=success</code>)</li> <li><code>schema_json</code> (optional): JSON Schema as string (recommended when <code>response_format=json_object</code>)</li> <li>Format: JSON Schema Draft 7 (draft-07)</li> <li>Example: <code>'{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"properties\":{\"name\":{\"type\":\"string\"}}}'</code></li> <li><code>schema_id</code> (optional): Server-known schema identifier (alternative to <code>schema_json</code>)</li> <li>Predefined schemas: <code>metadata</code>, <code>meeting_minutes</code> (see schema registry)</li> <li><code>strict</code> (optional): true/false (default: true when <code>response_format=json_object</code>)</li> <li>If <code>true</code>: broker validates output against the schema and returns <code>status=error</code> on mismatch</li> <li>If <code>false</code>: broker logs validation warnings but returns <code>status=success</code> even on schema mismatch</li> </ul> <p>Schema Validation Behavior:</p> <ul> <li>Invalid <code>schema_json</code>: Returns <code>status=error</code> with <code>code=\"InvalidSchema\"</code> (400)</li> <li>Unknown <code>schema_id</code>: Returns <code>status=error</code> with <code>code=\"SchemaNotFound\"</code> (400)</li> <li>Valid JSON but schema mismatch:</li> <li>If <code>strict=true</code>: Returns <code>status=error</code> with <code>code=\"SchemaValidationError\"</code> (400)</li> <li>If <code>strict=false</code>: Returns <code>status=success</code> with <code>data.structured_data</code> containing the (invalid) JSON, validation warning logged</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#chat-history-support","title":"Chat History Support","text":"<p>The endpoint supports full chat history by passing multiple messages:</p> <ul> <li><code>system</code>: System prompt (optional, should be at the beginning)</li> <li><code>user</code>: User messages</li> <li><code>assistant</code>: Previous assistant responses (for context)</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#request-example_3","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/chat\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"messages=[{\\\"role\\\":\\\"system\\\",\\\"content\\\":\\\"You are a helpful assistant.\\\"},{\\\"role\\\":\\\"user\\\",\\\"content\\\":\\\"What is 2+2?\\\"}]\" \\\n  -d \"model=openai/gpt-4\" \\\n  -d \"provider=openrouter\" \\\n  -d \"temperature=0.7\"\n</code></pre> <p>Alternative Authentication:</p> <pre><code>curl -X POST \"http://localhost:5001/api/transformer/chat\" \\\n  -H \"X-Secretary-Api-Key: YOUR_API_KEY\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"messages=[{\\\"role\\\":\\\"user\\\",\\\"content\\\":\\\"Hello\\\"}]\"\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#request-example-with-chat-history","title":"Request Example with Chat History","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/chat\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d 'messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},{\"role\":\"user\",\"content\":\"Hello!\"},{\"role\":\"assistant\",\"content\":\"Hello! How can I help you?\"},{\"role\":\"user\",\"content\":\"What is 2+2?\"}]' \\\n  -d \"model=openai/gpt-4\" \\\n  -d \"provider=openrouter\"\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#request-example-with-structured-output","title":"Request Example with Structured Output","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/chat\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d 'messages=[{\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},{\"role\":\"user\",\"content\":\"Extract metadata from this text: ...\"}]' \\\n  -d \"model=openai/gpt-4\" \\\n  -d \"provider=openrouter\" \\\n  -d \"response_format=json_object\" \\\n  -d \"schema_id=metadata\" \\\n  -d \"strict=true\"\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#response-success-text","title":"Response (Success, Text)","text":"<p>Stable TransformerResponse contract:</p> <pre><code>{\n  \"status\": \"success\",\n  \"request\": {\n    \"processor\": \"transformer\",\n    \"timestamp\": \"2025-12-22T18:00:00\",\n    \"parameters\": {\n      \"messages_count\": 2,\n      \"model\": \"openai/gpt-4\",\n      \"provider\": \"openrouter\",\n      \"temperature\": 0.7,\n      \"max_tokens\": null,\n      \"response_format\": \"text\",\n      \"duration_ms\": 1234\n    }\n  },\n  \"process\": {\n    \"id\": \"uuid-here\",\n    \"main_processor\": \"transformer\",\n    \"started\": \"2025-12-22T18:00:00\",\n    \"completed\": \"2025-12-22T18:00:00.234\",\n    \"duration\": 1234.0,\n    \"llm_info\": {\n      \"requests\": [\n        {\n          \"model\": \"openai/gpt-4\",\n          \"purpose\": \"chat_completion\",\n          \"tokens\": 150,\n          \"duration\": 1234.0,\n          \"processor\": \"transformer\",\n          \"timestamp\": \"2025-12-22T18:00:00\"\n        }\n      ],\n      \"requests_count\": 1,\n      \"total_tokens\": 150,\n      \"total_duration\": 1234.0\n    }\n  },\n  \"data\": {\n    \"text\": \"2+2 equals 4.\",\n    \"language\": \"\",\n    \"format\": \"TEXT\",\n    \"summarized\": false,\n    \"structured_data\": null\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#response-success-structured","title":"Response (Success, Structured)","text":"<p>When <code>response_format=json_object</code>:</p> <pre><code>{\n  \"status\": \"success\",\n  \"request\": {\n    \"processor\": \"transformer\",\n    \"timestamp\": \"2025-12-22T18:00:00\",\n    \"parameters\": {\n      \"messages_count\": 2,\n      \"model\": \"openai/gpt-4\",\n      \"provider\": \"openrouter\",\n      \"temperature\": 0.7,\n      \"response_format\": \"json_object\",\n      \"schema_id\": \"metadata\",\n      \"strict\": true,\n      \"duration_ms\": 1234\n    }\n  },\n  \"process\": {\n    \"id\": \"uuid-here\",\n    \"main_processor\": \"transformer\",\n    \"started\": \"2025-12-22T18:00:00\",\n    \"completed\": \"2025-12-22T18:00:00.234\",\n    \"duration\": 1234.0,\n    \"llm_info\": {\n      \"requests\": [\n        {\n          \"model\": \"openai/gpt-4\",\n          \"purpose\": \"chat_completion\",\n          \"tokens\": 150,\n          \"duration\": 1234.0,\n          \"processor\": \"transformer\",\n          \"timestamp\": \"2025-12-22T18:00:00\"\n        }\n      ],\n      \"requests_count\": 1,\n      \"total_tokens\": 150,\n      \"total_duration\": 1234.0\n    }\n  },\n  \"data\": {\n    \"text\": \"\",\n    \"language\": \"\",\n    \"format\": \"TEXT\",\n    \"summarized\": false,\n    \"structured_data\": {\n      \"recommendation\": \"chunk\",\n      \"confidence\": \"high\",\n      \"reasoning\": \"...\"\n    }\n  }\n}\n</code></pre> <p>Guarantees: - <code>status=\"success\"</code> implies <code>data.text</code> exists (string, can be empty). - Structured Output Guarantee: If <code>response_format=json_object</code> AND <code>status=success</code>, then <code>data.structured_data</code> is never null and is always a JSON object (dict). - If <code>strict=true</code> and schema validation fails, the response is <code>status=\"error\"</code>. - If <code>strict=false</code> and schema validation fails, the response is <code>status=\"success\"</code> but validation warnings are logged.</p>"},{"location":"_secretary-service-docu/transformer.html#erkennung-von-structured-output","title":"Erkennung von Structured Output","text":"<p>Um zu erkennen, ob eine Response Structured Output enth\u00e4lt, gibt es zwei M\u00f6glichkeiten:</p> <ol> <li> <p>Pr\u00fcfe <code>data.structured_data</code>:    <pre><code>if (response.data &amp;&amp; response.data.structured_data !== null &amp;&amp; typeof response.data.structured_data === 'object') {\n    // Structured Output vorhanden\n    const structuredData = response.data.structured_data;\n}\n</code></pre></p> </li> <li> <p>Pr\u00fcfe <code>request.parameters.response_format</code>:    <pre><code>if (response.request &amp;&amp; response.request.parameters &amp;&amp; response.request.parameters.response_format === 'json_object') {\n    // Structured Output wurde angefordert\n    // Pr\u00fcfe zus\u00e4tzlich ob structured_data vorhanden ist\n}\n</code></pre></p> </li> </ol> <p>Empfehlung: Pr\u00fcfe prim\u00e4r <code>data.structured_data !== null</code>, da dies die tats\u00e4chlichen Daten widerspiegelt. <code>request.parameters.response_format</code> zeigt nur an, was angefordert wurde, nicht was tats\u00e4chlich zur\u00fcckgegeben wurde.</p>"},{"location":"_secretary-service-docu/transformer.html#response-error","title":"Response (Error)","text":"<pre><code>{\n  \"status\": \"error\",\n  \"error\": {\n    \"code\": \"InvalidMessages\",\n    \"message\": \"messages muss eine Liste sein\",\n    \"details\": {}\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#error-codes","title":"Error Codes","text":"<ul> <li><code>InvalidMessages</code>: Invalid message format</li> <li><code>InvalidJSON</code>: Invalid JSON in messages parameter</li> <li><code>InvalidRequest</code>: Invalid request parameters (e.g., invalid response_format)</li> <li><code>InvalidSchema</code>: Invalid JSON Schema</li> <li><code>SchemaNotFound</code>: Schema ID not found</li> <li><code>SchemaValidationError</code>: JSON does not match schema (only when strict=true)</li> <li><code>JSONParseError</code>: JSON could not be parsed from LLM response</li> <li><code>StreamingNotSupported</code>: Streaming requested but not supported</li> <li><code>NoDefaultModel</code>: No default model configured</li> <li><code>NoProvider</code>: No provider configured</li> <li><code>ProviderNotFound</code>: Provider not found</li> <li><code>ChatCompletionError</code>: Error during chat completion</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#usagetokens","title":"Usage/Tokens","text":"<p>Token-Informationen sind in <code>process.llm_info</code> verf\u00fcgbar:</p> <p>Stabile Usage-Ableitung: <pre><code>// Aggregierte Token-Informationen\nconst llmInfo = response.process?.llm_info;\nconst usage = {\n  total_tokens: llmInfo?.total_tokens || 0,\n  requests_count: llmInfo?.requests_count || 0,\n  total_duration: llmInfo?.total_duration || 0\n};\n\n// Einzelne Request-Details\nconst requests = llmInfo?.requests || [];\nrequests.forEach(req =&gt; {\n  console.log(`Model: ${req.model}, Tokens: ${req.tokens}, Duration: ${req.duration}ms`);\n});\n</code></pre></p> <p>Hinweis: <code>prompt_tokens</code> und <code>completion_tokens</code> sind aktuell nicht separat verf\u00fcgbar. Nur <code>total_tokens</code> wird getrackt. Dies kann in zuk\u00fcnftigen Versionen erweitert werden, wenn Provider diese Informationen liefern.</p>"},{"location":"_secretary-service-docu/transformer.html#notes","title":"Notes","text":"<ul> <li>This endpoint is the preferred integration point for LLM usage in the app.</li> <li>The broker may apply provider/model policies, retries, caching and safety checks.</li> <li>Streaming is currently not supported (will return error if <code>stream=true</code>)</li> <li>The endpoint uses the standard TransformerResponse format for consistency</li> <li>LLM usage is tracked in <code>process.llm_info</code> with aggregated <code>total_tokens</code>, <code>requests_count</code>, and <code>total_duration</code></li> <li>Chat history is fully supported - pass all previous messages in the conversation</li> <li>Do not return secrets/tokens in <code>data</code> or logs</li> <li>Cache Semantik: <code>use_cache=true</code> (default) gilt auch f\u00fcr structured requests. Cached responses behalten ihr <code>structured_data</code> Format bei.</li> <li>Timeout: <code>timeout_ms</code> wird serverseitig auf einen maximalen Wert begrenzt (implementation-dependent). Wenn nicht angegeben, wird der Provider-Default verwendet.</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#hinweis-zu-asyncwebhooks","title":"Hinweis zu Async/Webhooks","text":"<p>Einige Endpoints (z.B. PDF und Audio) unterst\u00fctzen asynchrone Verarbeitung \u00fcber <code>callback_url</code> + <code>callback_token</code> mit einem <code>202 Accepted</code> ACK und einem finalen Webhook-Callback (<code>phase=completed/error</code>). F\u00fcr Details siehe die jeweiligen Endpoint-Dokumentationen.</p>"},{"location":"_secretary-service-docu/transformer.html#post-apitransformertextfile","title":"POST /api/transformer/text/file","text":"<p>Transform a text file (TXT, MD) from one language to another.</p>"},{"location":"_secretary-service-docu/transformer.html#request_4","title":"Request","text":"<p>Content-Type: <code>multipart/form-data</code></p> <p>Body Parameters:</p> <ul> <li><code>file</code> (required): Text file to transform (.txt or .md)</li> <li><code>source_language</code> (required): Source language (ISO 639-1 code, e.g., \"de\", \"en\")</li> <li><code>target_language</code> (required): Target language (ISO 639-1 code, e.g., \"de\", \"en\")</li> <li><code>summarize</code> (optional): Whether to summarize the text (true/false, default: false)</li> <li><code>target_format</code> (optional): Target format (TEXT, HTML, MARKDOWN, JSON)</li> <li><code>context</code> (optional): JSON string with context for transformation</li> <li><code>use_cache</code> (optional): Whether to use cache (true/false, default: true)</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#request-example_4","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/text/file\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -F \"file=@document.txt\" \\\n  -F \"source_language=en\" \\\n  -F \"target_language=de\" \\\n  -F \"use_cache=true\"\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#post-apitransformerxxl-text","title":"POST /api/transformer/xxl-text","text":"<p>Summarize a very large text file (TXT, MD) using chunking and a final \"summary-of-summaries\".</p> <p>This endpoint uses the dedicated LLM Use-Case <code>transformer_xxl</code> (configurable via <code>/llm-config</code>) to pick provider/model. Default should be set to <code>openrouter/google/gemini-2.5-flash</code>.</p>"},{"location":"_secretary-service-docu/transformer.html#request_5","title":"Request","text":"<p>Content-Type: <code>multipart/form-data</code></p> <p>Form Parameters:</p> <ul> <li><code>file</code> (required): Text file (<code>.txt</code>, <code>.md</code>)</li> <li><code>target_language</code> (optional): Output language (ISO 639-1, default: <code>de</code>)</li> <li><code>max_parallel</code> (optional): Parallel chunk processing (1..3, default: 3)</li> <li><code>overlap_ratio</code> (optional): Overlap ratio relative to chunk size (default: 0.04)</li> <li><code>use_cache</code> (optional): Whether to use cache (<code>true</code>/<code>false</code>, default: <code>true</code>)</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#request-example_5","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/xxl-text\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -F \"file=@big-document.txt\" \\\n  -F \"target_language=de\" \\\n  -F \"max_parallel=3\" \\\n  -F \"overlap_ratio=0.04\" \\\n  -F \"use_cache=true\"\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#response-success_3","title":"Response (Success)","text":"<p>Response follows the standardized format and includes aggregated <code>process.llm_info</code>.</p>"},{"location":"_secretary-service-docu/transformer.html#response-success_4","title":"Response (Success)","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"text\": \"Transformed text content...\",\n    \"language\": \"de\",\n    \"format\": \"TEXT\",\n    \"summarized\": false,\n    \"structured_data\": null\n  }\n}\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#post-apitransformermetadata","title":"POST /api/transformer/metadata","text":"<p>Extract metadata from files (images, videos, PDFs, and other documents).</p>"},{"location":"_secretary-service-docu/transformer.html#request_6","title":"Request","text":"<p>Content-Type: <code>multipart/form-data</code></p> <p>Body Parameters:</p> <ul> <li><code>file</code> (optional): File to extract metadata from</li> <li><code>content</code> (optional): Text content to extract metadata from (required if <code>file</code> not provided)</li> <li><code>context</code> (optional): JSON string with context for metadata extraction</li> <li><code>use_cache</code> (optional): Whether to use cache (true/false, default: true)</li> </ul>"},{"location":"_secretary-service-docu/transformer.html#request-example_6","title":"Request Example","text":"<pre><code>curl -X POST \"http://localhost:5001/api/transformer/metadata\" \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -F \"file=@document.pdf\" \\\n  -F \"use_cache=true\"\n</code></pre>"},{"location":"_secretary-service-docu/transformer.html#response-success_5","title":"Response (Success)","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data\": {\n    \"technical_metadata\": {\n      \"file_size\": 12345,\n      \"format\": \"pdf\",\n      \"mime_type\": \"application/pdf\"\n    },\n    \"content_metadata\": {\n      \"title\": \"Document Title\",\n      \"author\": \"Author Name\",\n      \"description\": \"Document description\"\n    }\n  }\n}\n</code></pre>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html","title":"Artifact pipeline v3 ist stand","text":""},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#ziel-und-kontext","title":"Ziel und Kontext","text":"<p>Dieses Dokument beschreibt den Ist\u2011Stand der aktuellen Implementierung der artefakt\u2011zentrierten Pipeline (V3) im Repo und gleicht ihn mit den Architektur\u2011Dokumenten ab:</p> <ul> <li><code>docs/architecture/artifact-pipeline-v3-design.md</code></li> <li><code>docs/architecture/requirements-artifact-pipeline-v3.md</code></li> <li><code>docs/architecture/shadow-twin.md</code></li> <li><code>docs/architecture/use-cases-and-personas.md</code></li> </ul> <p>Fokus: medienunabh\u00e4ngiger Flow, klare Trennung generisch vs. medium\u2011spezifisch, sowie eine Liste von Verbesserungen und Test-Guardrails, um Breaking Changes fr\u00fch zu erkennen.</p> <p>Status: Ist\u2011Stand (Code gelesen), keine produktive Verifikation durch reale Runs in diesem Dokument.</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#executive-summary-iststand","title":"Executive Summary (Ist\u2011Stand)","text":"<ul> <li>Orchestrierung ist generisch: Ein externer Job l\u00e4uft immer \u00fcber Worker \u2192 <code>/start</code> \u2192 Secretary \u2192 <code>/callback</code> und f\u00fchrt danach optional Template\u2011Phase und Ingest\u2011Phase aus.</li> <li>Artefaktmodell ist konsistent (Naming + Resolver/Writer): Transcript <code>{base}.{lang}.md</code>, Transformation <code>{base}.{template}.{lang}.md</code>.</li> <li>Medium\u2011Spezifika sind heute v.a. PDF\u2011lastig (Mistral OCR Assets, Pages/Images, chapters/pages Heuristiken).</li> <li>Audio/Video wurden repariert: Secretary darf bei aktivierter Template\u2011Phase kein Template im Extract liefern \u2192 Transcript bleibt roh.</li> <li>Dot\u2011Folder ist Zielzustand, Siblings sind Legacy\u2011Read und sollen sp\u00e4ter durch einen Repair\u2011Run eliminiert werden.</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#begriffe-kurz","title":"Begriffe (kurz)","text":"<ul> <li>Source: Originaldatei (PDF/Audio/Video/\u2026)</li> <li>Shadow\u2011Twin: abgeleitete Artefakte (Markdown + ggf. Assets) zur Source</li> <li>Transcript: roher Extract/Transkript\u2011Text als Markdown (typisch ohne Frontmatter)</li> <li>Transformation: template-basiertes Markdown mit Frontmatter/Metadata</li> <li>Dot\u2011Folder: <code>.{originalName}/</code> als kanonische Ablage f\u00fcr Artefakte</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#datenfluss-iststand-high-level","title":"Datenfluss (Ist\u2011Stand, High Level)","text":"<pre><code>flowchart TD\n  UI[FlowView_UI] --&gt;|enqueue_job| CreateJob[SecretaryJobRoute]\n  CreateJob --&gt;|jobId| ExternalJob[Mongo_external_jobs]\n  Worker[ExternalJobsWorker] --&gt;|POST /start| StartRoute[StartRoute]\n  StartRoute --&gt;|POST formData| Secretary[SecretaryService]\n  Secretary --&gt;|POST callback| CallbackRoute[CallbackRoute]\n  CallbackRoute --&gt; ExtractSave[SaveTranscriptArtifact]\n  CallbackRoute --&gt;|optional| TemplatePhase[runTemplatePhase]\n  CallbackRoute --&gt;|optional| IngestPhase[runIngestPhase]\n  ExtractSave --&gt; ShadowTwin[ShadowTwin_DotFolder]\n  TemplatePhase --&gt; ShadowTwin\n  IngestPhase --&gt; MongoVector[Mongo_VectorSearch]</code></pre>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#was-ist-generisch-medienunabhangig","title":"Was ist generisch (medienunabh\u00e4ngig)?","text":""},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#1-external-jobs-orchestrierung","title":"1) External Jobs Orchestrierung","text":"<ul> <li>Worker: <code>src/lib/external-jobs-worker.ts</code></li> <li>claimt atomar queued Jobs aus Mongo</li> <li>triggert <code>POST /api/external/jobs/{jobId}/start</code></li> <li> <p>f\u00fcgt Trace-Header hinzu (<code>X-Worker-Id</code>, <code>X-Worker-Tick-Id</code>, <code>X-Start-Request-Id</code>) f\u00fcr Debugging.</p> </li> <li> <p>StartRoute: <code>src/app/api/external/jobs/[jobId]/start/route.ts</code></p> </li> <li>l\u00e4dt Source Binary aus Storage</li> <li>pr\u00fcft Policies/Gates und entscheidet, ob Secretary aufgerufen wird</li> <li>startet Watchdog und schreibt Trace Events</li> <li> <p>Duplicate Start Requests werden geloggt, nicht blockiert (Observability statt harte Idempotenz\u2011Sperre).</p> </li> <li> <p>CallbackRoute: <code>src/app/api/external/jobs/[jobId]/route.ts</code></p> </li> <li>pr\u00fcft Callback Auth + Prozess\u2011Guard</li> <li>verarbeitet Progress Events (Short\u2011Circuit)</li> <li>erkennt Final Payload und orchestriert:<ul> <li>Extract\u2011Artefakt speichern</li> <li>Template\u2011Phase (falls aktiv/ben\u00f6tigt)</li> <li>Ingest\u2011Phase (falls aktiv)</li> </ul> </li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#2-policies-gates-konzept","title":"2) Policies / Gates (Konzept)","text":"<ul> <li>Policies kommen aus <code>job.parameters.policies</code> (oder Legacy Flags) und steuern:</li> <li>extract</li> <li>metadata (Template)</li> <li>ingest</li> </ul> <p>Relevante Dateien: - <code>src/lib/processing/phase-policy.ts</code> - <code>src/lib/processing/gates.ts</code></p> <p>Hinweis: <code>gateExtractPdf()</code> ist historisch PDF\u2011benannt, wird aber semantisch als \u201eShadow\u2011Twin existiert?\u201c genutzt. F\u00fcr neue Medien sollte die Namensgebung/Abstraktion vereinheitlicht werden (siehe Verbesserungen).</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#3-shadowtwin-contracts-namingresolverwriter","title":"3) Shadow\u2011Twin Contracts: Naming/Resolver/Writer","text":"<ul> <li>Naming/Parsing: <code>src/lib/shadow-twin/artifact-naming.ts</code></li> <li>Resolver: <code>src/lib/shadow-twin/artifact-resolver.ts</code></li> <li>Writer: <code>src/lib/shadow-twin/artifact-writer.ts</code></li> </ul> <p>Eigenschaften: - Deterministische Namen und \u201eoverwrite statt duplizieren\u201c (delete+upload). - Resolver kann Dot\u2011Folder und (legacy) Siblings finden.</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#was-ist-mediumspezifisch","title":"Was ist medium\u2011spezifisch?","text":""},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#pdf-heute-am-starksten-ausgebaut","title":"PDF (heute am st\u00e4rksten ausgebaut)","text":"<ul> <li>Secretary Request: <code>src/lib/external-jobs/secretary-request.ts</code></li> <li>unterst\u00fctzt <code>mistral_ocr</code> / <code>native</code></li> <li>Asset\u2011Parameter: <code>includePageImages</code>, <code>includeImages</code>, URLs/ZIP handling</li> <li>Callback: erkennt <code>pages_archive_url</code>, <code>mistral_ocr_raw_url</code> etc.</li> <li>Template\u2011Phase enth\u00e4lt PDF\u2011spezifische Logik rund um <code>pages</code>/<code>chapters</code> Rekonstruktion/Repair (muss perspektivisch abstrahiert werden).</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#audiovideo-aktueller-fokus-transcript-contract","title":"Audio/Video (aktueller Fokus: Transcript-Contract)","text":"<ul> <li>Secretary Request: <code>src/lib/external-jobs/secretary-request.ts</code></li> <li>Fix: wenn Template\u2011Phase aktiv ist, wird bei Audio/Video kein <code>template</code> an den Secretary gesendet.</li> <li>Resultat: Transcript <code>{base}.{lang}.md</code> bleibt roh.</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#was-wurde-konkret-repariert-delta","title":"Was wurde konkret repariert (Delta)","text":""},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#1-audiovideo-transcript-wurde-mit-template-output-uberschrieben","title":"1) Audio/Video: Transcript wurde mit Template-Output \u00fcberschrieben","text":"<p>Ursache (alt): - UI/Job sendet <code>template</code> direkt an <code>/audio/process</code> \u2192 Secretary liefert schon transformierten Text \u2192 wir speichern ihn als Transcript.</p> <p>Fix (neu): - In <code>prepareSecretaryRequest()</code> wird <code>template</code> bei Audio/Video nur gesendet, wenn Template\u2011Phase deaktiviert w\u00e4re. In unserem Zielbild (\u201enever\u201c) bedeutet das: Audio/Video Extract liefert immer nur Transcript.</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#2-artefaktwrites-falscher-parent-nicht-dotfolder","title":"2) Artefakt\u2011Writes: falscher Parent (nicht Dot\u2011Folder)","text":"<p>Fix: - In Callback/Storage Pfaden wird <code>shadowTwinFolderId</code> nach dem Transcript\u2011Save korrekt weitergereicht/aktualisiert, sodass subsequent Phasen im richtigen Dot\u2011Folder schreiben.</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#3-doppelstarts-unauthorized-callback-hash-mismatch","title":"3) Doppelstarts / Unauthorized Callback Hash Mismatch","text":"<p>Fix: - Client\u2011seitiger Start wurde entfernt; Start erfolgt \u00fcber Worker. - StartRoute blockiert Duplicate Requests nicht mehr hart, sondern schreibt Trace Events (<code>start_duplicate_request</code>) zur Ursachenanalyse.</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#4-ui-autoopen-loop","title":"4) UI Auto\u2011Open Loop","text":"<p>Fix: - Pipeline Sheet Auto\u2011Open unterscheidet \u201enicht gesetzt\u201c vs \u201evom Nutzer geschlossen\u201c \u00fcber Query\u2011Param <code>pipeline</code> (<code>'' | '1' | '0'</code>).</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#architekturbewertung-ist-das-fundament-sinnvoll-fur-mehrere-medien","title":"Architektur\u2011Bewertung: Ist das Fundament sinnvoll f\u00fcr mehrere Medien?","text":"<p>Ja \u2013 wenn wir 2 Dinge konsequent halten:</p> <p>1) Phasen\u2011Interfaces bleiben medium\u2011agnostisch (Extract \u2192 Template \u2192 Ingest), aber \u201eAdapter\u201c kapseln medien-spezifische Details (Secretary endpoint, Asset\u2011Handling). 2) Artefakt\u2011Contracts (Naming/Storage/Dot\u2011Folder, Transcript vs Transformation) sind die stabile Schnittstelle zwischen Medien.</p> <p>Aktuelles Risiko: PDF\u2011spezifische Kapitel/Pages\u2011Heuristiken sitzen in <code>phase-template.ts</code> und k\u00f6nnen unbeabsichtigt auf andere Medien \u201edurchbluten\u201c, wenn nicht sauber per UseCase/JobType gegated wird.</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#verbesserungen-3-varianten","title":"Verbesserungen (3 Varianten)","text":""},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#variante-a-minimal-kurzfristig","title":"Variante A (minimal, kurzfristig)","text":"<ul> <li>Dokumentation konsolidieren (Dot\u2011Folder kanonisch; Siblings nur Legacy\u2011Read).</li> <li>Integration Tests: Warnung, wenn Resolver ein Sibling\u2011Artefakt liefert.</li> <li>Erg\u00e4nzende Unit Tests: SecretaryRequest\u2011Contract \u201eAudio/Video niemals Template\u201c.</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#variante-b-mittel-strukturell","title":"Variante B (mittel, strukturell)","text":"<ul> <li><code>gateExtractPdf</code> in <code>gateExtract</code> umbenennen + Gate\u2011Logik so formulieren, dass sie nicht PDF\u2011spezifisch wirkt.</li> <li>Template\u2011Phase trennt klar:</li> <li>generisches Template Transform</li> <li>PDF\u2011spezifische Post\u2011Processing Schritte (pages/images/chapters) in ein separates Modul.</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#variante-c-strikt-langfristig","title":"Variante C (strikt, langfristig)","text":"<ul> <li>Ein echtes \u201eUseCase Adapter\u201c Interface:</li> <li><code>buildSecretaryRequest(job)</code> (pro medium/job_type)</li> <li><code>normalizeExtractPayload(payload)</code> (pro medium)</li> <li><code>postprocessArtifacts()</code> (optional, pro medium)</li> <li>Contract Tests pro Adapter, plus E2E Integration Suites pro UseCaseId (pdf/audio/video).</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#tests-breaking-changes-fruh-erkennen-iststand-empfehlung","title":"Tests: Breaking Changes fr\u00fch erkennen (Ist\u2011Stand + Empfehlung)","text":""},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#unit-tests-vorhanden","title":"Unit Tests (vorhanden)","text":"<ul> <li><code>tests/unit/shadow-twin/*</code>: Naming/Resolver/Writer</li> <li><code>tests/unit/external-jobs/secretary-request.test.ts</code>: Request\u2011Kontrakte</li> <li><code>tests/unit/external-jobs/progress.test.ts</code>: Progress handling (Basis)</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#integration-tests-vorhanden-pdf","title":"Integration Tests (vorhanden, PDF)","text":"<ul> <li><code>src/lib/integration-tests/*</code>: Job orchestrieren, Artefakte + Mongo validieren.</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#empfehlung-erweiterung","title":"Empfehlung (Erweiterung)","text":"<ul> <li>Kurzfristig: Integration Validators sollen warnen, wenn transformation/transcript als <code>location === 'sibling'</code> gefunden werden.</li> <li>Mittelfristig: zus\u00e4tzliche UseCases <code>audio_transcript_report.*</code> und <code>video_transcript_report.*</code> analog zu PDF\u2011Suite.</li> </ul>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#konkreter-testplan-minimal-aber-effektiv","title":"Konkreter Testplan (minimal, aber effektiv)","text":""},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#unit-tests-schnell-citauglich","title":"Unit Tests (schnell, CI\u2011tauglich)","text":"<p>1) Secretary Request Contract (bereits teilweise vorhanden)    - Audio/Video: niemals <code>template</code> an Secretary senden, wenn Template\u2011Phase aktiv (Zielbild).    - PDF: <code>mistral_ocr</code> Parameter + Asset Flags bleiben stabil.</p> <p>2) Shadow\u2011Twin Contract Tests    - <code>buildArtifactName</code>/<code>parseArtifactName</code> f\u00fcr Basenames mit Punkten.    - Resolver bevorzugt Dot\u2011Folder; Siblings nur Fallback.</p> <p>3) Writer Contract Tests    - deterministische Updates (delete+upload) bleiben update-semantisch.    - (Zielbild) Dot\u2011Folder als Write\u2011Pfad: sobald umgesetzt, Tests auf \u201ekeine Siblings erzeugt\u201c.</p>"},{"location":"analysis/artifact-pipeline-v3-ist-stand.html#integration-tests-realistisch-langsam","title":"Integration Tests (realistisch, langsam)","text":"<p>1) PDF (vorhanden)    - happy path, gate skip, force recompute, repair frontmatter, HITL publish.</p> <p>2) Audio/Video (geplant)    - Happy path: Extract (Transcript) \u2192 Template \u2192 optional Ingest.    - Contract Checks:      - <code>{base}.{lang}.md</code> = rohes Transcript (kein Template\u2011Output).      - <code>{base}.{template}.{lang}.md</code> = strukturierter Template\u2011Text.    - Gate skip / force: analog zur PDF\u2011Suite.</p> <p>3) Legacy Warning (sofort)    - Wenn Validator ein Artefakt als <code>location=sibling</code> findet: WARN, nicht FAIL.    - Nach Migration/Repair\u2011Run kann die Policy auf FAIL umgestellt werden.</p>"},{"location":"analysis/artifact-ui-unification.html","title":"Artifact ui unification","text":""},{"location":"analysis/artifact-ui-unification.html#ziel","title":"Ziel","text":"<p>Wir wollen die Artefakt-Ansicht vereinheitlichen. Heute existieren mehrere UI-Generationen parallel. Das erzeugt doppelte Benutzerfuehrung und widerspruechliche Erwartungen. Die Haupt-UI soll den gesamten Lebenszyklus sichtbar machen und trotzdem leicht bedienbar bleiben.</p> <p>Die drei Status-Icons in der Toolbar sind bereits ein klares mentales Modell. Dieses Modell soll in Tabs uebersetzt werden. So erkennt man schnell, welches Artefakt existiert und kann es direkt oeffnen. Bearbeiten bleibt moeglich, aber als gezieltes Modal pro Artefakt.</p> <p>Wir wollen moeglichst wenig neu programmieren. Wir nutzen vorhandene Bausteine wie <code>StoryView</code>, <code>JobReportTab</code>, <code>ArtifactInfoPanel</code> und <code>SourceAndTranscriptPane</code>. Das reduziert Risiko, spart Zeit und bleibt konsistent mit der Pipeline-Logik.</p>"},{"location":"analysis/artifact-ui-unification.html#varianten","title":"Varianten","text":""},{"location":"analysis/artifact-ui-unification.html#variante-a-haupt-ui-erweitern-bevorzugt","title":"Variante A: Haupt-UI erweitern (bevorzugt)","text":"<ul> <li>Haupt-UI bekommt Tabs: Original, Transcript, Transformation, Story, Uebersicht.</li> <li>Icons aus der Toolbar erscheinen als Tab-Icons.</li> <li>Legacy-Dialog wird entfernt oder umgeleitet.</li> <li>Bearbeiten oeffnet ein Modal aus dem jeweiligen Tab.</li> </ul> <p>Pro: Minimal-invasive Aenderung, beste Wiederverwendung, klare Navigation. Contra: Anpassungen in <code>FilePreview</code> notwendig.</p>"},{"location":"analysis/artifact-ui-unification.html#variante-b-legacy-dialog-als-haupt-ui","title":"Variante B: Legacy-Dialog als Haupt-UI","text":"<ul> <li>Datei-Dialog wird zur Haupt-UI ausgebaut.</li> <li>Aktuelle Haupt-UI wird reduziert oder entfernt.</li> </ul> <p>Pro: Wenig Umbau im Dialog selbst. Contra: Bricht bestehende Navigationspfade und Status-Icons, hohes Risiko.</p>"},{"location":"analysis/artifact-ui-unification.html#variante-c-hybrid-mit-zwei-ebenen","title":"Variante C: Hybrid mit zwei Ebenen","text":"<ul> <li>Haupt-UI bleibt schlank, Legacy-Dialog bleibt fuer Experten.</li> <li>Klare Rollenverteilung, z.B. \"Standard\" vs. \"Debug\".</li> </ul> <p>Pro: Niedriges Risiko. Contra: Doppelfuehrung bleibt bestehen.</p>"},{"location":"analysis/artifact-ui-unification.html#entscheidung","title":"Entscheidung","text":"<p>Wir waehlen Variante A. Sie konsolidiert die UX, nutzt vorhandene Komponenten und respektiert das Artefaktmodell. Das Risiko ist gering, weil wir keine neue Datenlogik bauen.</p>"},{"location":"analysis/artifact-ui-unification.html#konsequenzen","title":"Konsequenzen","text":"<ul> <li><code>FilePreview</code> wird zentral erweitert.  </li> <li>Der Legacy-Dialog wird entfernt oder nur noch als technischer Fallback verwendet.  </li> <li>Bearbeiten wird als Modal pro Artefakt angeboten.</li> </ul>"},{"location":"analysis/audio-integration-tests.html","title":"Audio integration tests","text":""},{"location":"analysis/audio-integration-tests.html#ziel","title":"Ziel","text":"<p>Integrationstests sollen neben PDF auch Audio-Dateien abdecken (Transkription + optional Template-Transformation) und die UI soll so vereinfacht werden, dass man nur Dateityp (PDF/AUDIO) und optional eine konkrete Datei ausw\u00e4hlt (statt File-IDs zu kopieren).</p>"},{"location":"analysis/audio-integration-tests.html#anderungen-design","title":"\u00c4nderungen (Design)","text":"<ul> <li>Testcases bekommen ein <code>target</code> (<code>pdf</code> | <code>audio</code>), damit</li> <li>der Orchestrator die richtigen Test-Targets im Ordner findet,</li> <li>die UI eine Suite-Auswahl (\u201eNur PDF / Nur Audio / Alle\u201c) anbieten kann.</li> <li>Testdatei-Listung wird generisch (<code>listIntegrationTestFiles(kind)</code>), statt nur <code>listPdfTestFiles</code>.</li> <li>Internal Create Route unterst\u00fctzt Audio:</li> <li><code>src/app/api/external/jobs/internal/create/route.ts</code> leitet <code>job_type</code> und <code>correlation.source.mediaType</code> aus <code>mimeType</code> ab (oder optional \u00fcber <code>mediaType</code>).</li> <li>Steps werden entsprechend mit <code>extract_audio</code> statt <code>extract_pdf</code> initialisiert (als Platzhalter; die Start-Route initialisiert Steps ohnehin neu).</li> <li>Validatoren werden medientyp-agnostisch:</li> <li>Extract-Step-Name wird aus <code>job.job_type</code> abgeleitet.</li> <li>F\u00fcr Extract-only Runs (<code>phases.template=false</code>) wird im Shadow\u2011Twin Transcript statt Transformation validiert.</li> <li>UI Vereinfachung:</li> <li>Auswahl: <code>Dateityp</code> + <code>Datei (optional)</code> \u2192 f\u00fcllt die (legacy) File-ID automatisch.</li> <li>Suite-Filter: \u201eAlle / Nur PDF / Nur Audio\u201c.</li> </ul>"},{"location":"analysis/audio-integration-tests.html#audio-testcases-minimal-suite","title":"Audio-Testcases (Minimal-Suite)","text":"<p>Ziel ist eine stabile Basis, die ohne spezielle Templates funktioniert:</p> <ul> <li><code>audio_transcription.happy_path</code>:</li> <li>Extract-only (Transkription), Template/Ingest deaktiviert.</li> <li>Erwartung: Job <code>completed</code>, <code>savedItemId</code> zeigt auf Transcript.</li> <li><code>audio_transcription.gate_skip_extract</code>:</li> <li>Transcript existiert bereits \u2192 Extract wird per Gate/Policy \u00fcbersprungen.</li> <li><code>audio_transcription.force_recompute</code>:</li> <li>Transcript existiert, aber Extract wird forciert.</li> </ul> <p>Optional kann sp\u00e4ter ein eigener UseCase f\u00fcr \u201eAudio + Template\u201c erg\u00e4nzt werden (wenn ein passendes Template existiert).</p>"},{"location":"analysis/audio-jobs-transcript-only.html","title":"Audio/Video (no template)","text":""},{"location":"analysis/audio-jobs-transcript-only.html#audiovideo-jobs-without-template-transcript-only-runtime-decision","title":"Audio/Video jobs without template: transcript-only (runtime decision)","text":"<p>Status: active Last verified: 2026-01-06  </p>"},{"location":"analysis/audio-jobs-transcript-only.html#scope","title":"Scope","text":"<p>This document captures the runtime contract for audio/video transcription when the user does not select a template. It focuses on preventing accidental template runs and \u201ctemplate not found\u201d failures.</p>"},{"location":"analysis/audio-jobs-transcript-only.html#glossary","title":"Glossary","text":"<ul> <li>Transcript-only: job writes a transcript Markdown and stops (no template, no ingest)</li> <li>Template phase: metadata/frontmatter transformation using a template</li> <li>Ingest phase: RAG ingestion into MongoDB Vector Search</li> </ul>"},{"location":"analysis/audio-jobs-transcript-only.html#problem","title":"Problem","text":"<p>Users can start audio/video transcription without selecting a template. In that case, the expected behavior is:</p> <ul> <li>produce the transcript Markdown (Shadow\u2011Twin transcript artifact)</li> <li>do not run template transformation</li> <li>do not run ingestion</li> <li>finish successfully with a meaningful <code>result.savedItemId</code></li> </ul>"},{"location":"analysis/audio-jobs-transcript-only.html#decision-contract","title":"Decision (contract)","text":"<p>If <code>template</code> is missing/empty, audio/video jobs must behave as transcript-only.</p> <p>That implies: - <code>policies.metadata = 'ignore'</code> - <code>policies.ingest = 'ignore'</code> - final output is the transcript artifact, and <code>result.savedItemId</code> must point to that transcript file</p>"},{"location":"analysis/audio-jobs-transcript-only.html#why","title":"Why","text":"<ul> <li>It matches explicit user intent (\u201cno template\u201d).</li> <li>It avoids implicit defaults and prevents <code>template_not_found</code> failures.</li> <li>It keeps the job semantics deterministic and easy to reason about.</li> </ul>"},{"location":"analysis/audio-jobs-transcript-only.html#implementation-notes-where-this-must-be-enforced","title":"Implementation notes (where this must be enforced)","text":"<ul> <li>Start routes must not introduce a default template when the client did not select one.</li> <li>Callback completion must treat \u201ccompleted transcription payload\u201d as final and persist <code>savedItemId</code>.</li> </ul> <p>Relevant code areas (non-exhaustive): - <code>src/app/api/secretary/process-audio/job/route.ts</code> - <code>src/app/api/secretary/process-video/job/route.ts</code> - <code>src/lib/external-jobs/progress.ts</code> - <code>src/app/api/external/jobs/[jobId]/route.ts</code></p>"},{"location":"analysis/browser-test-analysis-latest.html","title":"Browser-Test Analyse: Optimierungen validiert","text":""},{"location":"analysis/browser-test-analysis-latest.html#test-szenario","title":"Test-Szenario","text":"<ol> <li>Root-Verzeichnis laden (<code>http://localhost:3000/library</code>)</li> <li>In Unterverzeichnis navigieren (\"2. Wertephase\")</li> </ol>"},{"location":"analysis/browser-test-analysis-latest.html#test-datum","title":"Test-Datum","text":"<p>2025-11-23 00:19:18</p>"},{"location":"analysis/browser-test-analysis-latest.html#analyse-ergebnisse","title":"Analyse-Ergebnisse","text":""},{"location":"analysis/browser-test-analysis-latest.html#root-laden-initial","title":"\u2705 Root-Laden (Initial)","text":"<p>API-Calls: - \u2705 <code>action=list&amp;fileId=root</code> (1x) - Root-Items laden - \u2705 <code>action=list&amp;fileId=LmNrLW1ldGE=</code> (1x) - Favoriten laden - \u2705 <code>action=get</code> (27x) - Metadaten f\u00fcr Dateien (f\u00fcr Shadow-Twin-Analyse) - \u2705 <code>file-status</code> (9x) - Doc-Status f\u00fcr Markdown-Dateien (debounced)</p> <p>Ergebnis: - \u2705 Nur 1x Root-Request (vorher: 3x) - \u2705 Keine doppelten Root-Requests mehr!</p>"},{"location":"analysis/browser-test-analysis-latest.html#navigation-zu-unterverzeichnis-2-wertephase","title":"\u2705 Navigation zu Unterverzeichnis (\"2. Wertephase\")","text":"<p>Console-Logs: <pre><code>[INFO] [00:19:18.676Z][NAV:9][debug@nav][info] \u2139\ufe0f navigateToFolder called {folderId: Mi4gV2VydGVwaGFzZQ==}\n[INFO] [00:19:18.681Z][STATE:20][FolderNavigation][info] \u2139\ufe0f Cache miss, loading path from provider {folderId: Mi4gV2VydGVwaGFzZQ==, missingIds: Array(1)}\n[DEBUG] [00:19:18.802Z][NAV:10][debug@nav][debug] \ud83d\udd0d Using cached root items for path building {itemCount: 51}\n[DEBUG] [00:19:18.803Z][NAV:11][debug@nav][debug] \ud83d\udd0d Using cached children for path building {parentId: root, itemCount: 51}\n[INFO] [00:19:18.804Z][NAV:12][debug@nav][info] \u2139\ufe0f Loaded path items for folder {folderId: Mi4gV2VydGVwaGFzZQ==, pathLength: 2}\n[INFO] [00:19:19.244Z][UI:8][Library][info] \u2139\ufe0f Initial load triggered {currentFolderId: Mi4gV2VydGVwaGFzZQ==, lastLoadedFolder: root, tSinceMountMs: 188969.2}\n[INFO] [00:19:19.247Z][NAV:15][Library][info] \u2139\ufe0f Loading initial items {folderId: Mi4gV2VydGVwaGFzZQ==}\n[INFO] [00:19:19.250Z][NAV:16][Library][info] \u2139\ufe0f Fetching items from provider {folderId: Mi4gV2VydGVwaHFzZQ==, cacheHit: false}\n</code></pre></p> <p>API-Calls: - \u2705 <code>action=path&amp;fileId=Mi4gV2VydGVwaHFzZQ==</code> (1x) - Pfad aufbauen - \u2705 <code>action=list&amp;fileId=Mi4gV2VydGVwaHFzZQ==</code> (1x) - Zielordner-Inhalt laden - \u2705 KEIN <code>action=list&amp;fileId=root</code> - Root-Items werden aus Cache verwendet!</p> <p>Ergebnis: - \u2705 Nur 1x Zielordner-Request (vorher: 2x) - \u2705 Kein Root-Request - Root-Items werden aus Cache verwendet! - \u2705 Keine doppelten Calls mehr!</p>"},{"location":"analysis/browser-test-analysis-latest.html#validierung-der-optimierungen","title":"Validierung der Optimierungen","text":""},{"location":"analysis/browser-test-analysis-latest.html#1-race-condition-bei-loaditems-behoben","title":"\u2705 1. Race-Condition bei loadItems behoben","text":"<p>Vorher: - <code>loadItems</code> wurde zweimal aufgerufen - 2x Zielordner-Requests</p> <p>Nachher: - <code>loadItems</code> wird nur 1x aufgerufen - 1x Zielordner-Request - <code>lastLoadedFolder</code> wird optimistisch gesetzt</p> <p>Status: \u2705 FUNKTIONIERT</p>"},{"location":"analysis/browser-test-analysis-latest.html#2-root-items-fur-pfadaufbau-optimiert","title":"\u2705 2. Root-Items f\u00fcr Pfadaufbau optimiert","text":"<p>Vorher: - <code>getPathItemsById</code> l\u00e4dt Root-Items mit API-Call - 3x Root-Requests insgesamt</p> <p>Nachher: - Root-Items werden aus Cache verwendet (<code>Using cached root items for path building</code>) - Root-Children werden aus Cache verwendet (<code>Using cached children for path building</code>) - 0x Root-Requests bei Navigation</p> <p>Status: \u2705 FUNKTIONIERT</p>"},{"location":"analysis/browser-test-analysis-latest.html#performance-verbesserungen","title":"Performance-Verbesserungen","text":""},{"location":"analysis/browser-test-analysis-latest.html#root-laden","title":"Root-Laden","text":"<ul> <li>Vorher: 3x Root-Requests</li> <li>Nachher: 1x Root-Request</li> <li>Verbesserung: 66% Reduzierung</li> </ul>"},{"location":"analysis/browser-test-analysis-latest.html#navigation-zu-unterverzeichnis","title":"Navigation zu Unterverzeichnis","text":"<ul> <li>Vorher: 1x path, 1x root, 2x Zielordner = 4 API-Calls</li> <li>Nachher: 1x path, 0x root (Cache), 1x Zielordner = 2 API-Calls</li> <li>Verbesserung: 50% Reduzierung</li> </ul>"},{"location":"analysis/browser-test-analysis-latest.html#zusammenfassung","title":"Zusammenfassung","text":"<p>\u2705 Alle Optimierungen funktionieren wie erwartet!</p> <ol> <li>\u2705 Race-Condition bei <code>loadItems</code> behoben - keine doppelten Zielordner-Requests mehr</li> <li>\u2705 Root-Items werden aus Cache verwendet - keine doppelten Root-Requests mehr</li> <li>\u2705 Cache wird effizient genutzt - Root-Items werden nicht neu geladen</li> </ol> <p>Die Optimierungen haben die erwartete Wirkung und reduzieren die API-Calls deutlich.</p>"},{"location":"analysis/docs-cleanup-delete-list.html","title":"Docs cleanup delete list","text":""},{"location":"analysis/docs-cleanup-delete-list.html#docs-cleanup-delete-list-v2-only-focus","title":"Docs cleanup: delete list (v2-only focus)","text":"<p>Status: active Last verified: 2026-01-06  </p>"},{"location":"analysis/docs-cleanup-delete-list.html#scope","title":"Scope","text":"<p>This document lists the files we delete as part of the docs consolidation. Rationale and replacement targets are included so the cleanup is auditable.</p>"},{"location":"analysis/docs-cleanup-delete-list.html#files-to-delete","title":"Files to delete","text":"File Why delete Replacement <code>docs/mongodb-vector-search-index.md</code> Duplicates MongoDB Vector Search index details; also wrong placement (root) and mixed language. Merged into <code>docs/architecture/mongodb-vector-search.md</code> (\u201cToken indexes for filtering\u201d). <code>docs/_analysis/audio-transcribe-without-template-2026-01-06.md</code> Scratch note moved to canonical analysis doc. <code>docs/analysis/audio-jobs-transcript-only.md</code> <code>docs/_analysis/docs-cleanup-delete-list.md</code> Replaced by this canonical delete list in <code>docs/analysis/</code>. <code>docs/analysis/docs-cleanup-delete-list.md</code> <code>docs/_analysis/gallery-table-upsertedat-spalte.md</code> Very specific UI change; belongs in issue tracker, not docs canon. None (keep history in git). <code>docs/_analysis/email-service-provider-examples.md</code> Unrelated to the v2-only pipeline docs scope; mixed language and not maintained. None (move to product/ops docs later if needed). <code>docs/_analysis/shadow-twin-migration-and-items.md</code> Obsolete \u201cVariante 1\u201d design that contradicts v2-only runtime (moves truth into Mongo). Canon: <code>docs/architecture/shadow-twin.md</code> + <code>docs/analysis/shadow-twin-v2-only.md</code> <code>docs/_chats/cursor_ingestion_flow_strategie_und_red.md</code> Chat transcript; not a maintained doc. None. <code>docs/template-commoning-umbau.md</code> Old draft (DE) in root; not maintained and outside canon. None (rewrite into <code>docs/analysis/</code> later if still needed)."},{"location":"analysis/docs-cleanup-delete-list.html#link-fix-policy","title":"Link-fix policy","text":"<p>After deletion: - remove or replace any internal links to the deleted files - MkDocs nav must not reference deleted files</p>"},{"location":"analysis/docs-cleanup-inventory.html","title":"Docs Cleanup Inventory (v2-only focus)","text":"<p>This document is the working inventory for consolidating documentation into a small set of canonical docs.</p>"},{"location":"analysis/docs-cleanup-inventory.html#scope","title":"Scope","text":"<ul> <li>In scope: <code>docs/architecture/</code>, <code>docs/analysis/</code>, <code>docs/_analysis/</code> (+ a few root docs that clearly duplicate canon).</li> <li>Out of scope: <code>docs/reference/</code> and <code>docs/use-cases/</code> content correctness (we only classify them).</li> </ul>"},{"location":"analysis/docs-cleanup-inventory.html#rules-used-for-classification","title":"Rules used for classification","text":"<ul> <li>keep: required and correct today, or actively linked from MkDocs nav.</li> <li>merge: contains valuable content but is duplicated / in the wrong location / wrong language.</li> <li>delete: scratch, obsolete, or contradicts v2-only runtime.</li> </ul>"},{"location":"analysis/docs-cleanup-inventory.html#inventory-table","title":"Inventory table","text":"File Topic Status Target / Notes <code>docs/index.md</code> Docs entrypoint keep Canonical start page (MkDocs \u201cHome\u201d). <code>docs/architecture/shadow-twin.md</code> Shadow\u2011Twin (design) keep Canonical design doc (add standard header + glossary). <code>docs/analysis/shadow-twin-v2-only.md</code> Shadow\u2011Twin (runtime) keep Canonical runtime/decision doc. <code>docs/guides/shadow-twin.md</code> Shadow\u2011Twin (user guide) keep Keep as user-facing companion; not in MkDocs nav (optional add later). <code>docs/analysis/wizard-and-jobs.md</code> External Jobs / Wizard (runtime) keep Canonical runtime/contract doc. <code>docs/architecture/pdf-transformation-phases.md</code> PDF pipeline (design + IST) keep Canonical pipeline doc (needs naming section aligned with v2-only conventions). <code>docs/analysis/ingestion.md</code> Ingestion (runtime) keep Canonical operational ingestion doc. <code>docs/architecture/mongodb-vector-search.md</code> MongoDB Vector Search (design) keep Canonical architecture doc. <code>docs/analysis/storage.md</code> Storage (runtime) keep Canonical operational storage doc. <code>docs/architecture/module-hierarchy.md</code> Architecture overview keep In MkDocs nav. <code>docs/architecture/dependency-graph.md</code> Architecture overview keep In MkDocs nav. <code>docs/reference/file-index.md</code> Reference keep In MkDocs nav. <code>docs/reference/modules/library.md</code> Reference keep In MkDocs nav. <code>docs/reference/modules/storage.md</code> Reference keep In MkDocs nav. <code>docs/reference/modules/chat.md</code> Reference keep In MkDocs nav. <code>docs/use-cases/index.md</code> Use cases keep In MkDocs nav. <code>docs/use-cases/library-setup.md</code> Use cases keep In MkDocs nav. <code>docs/use-cases/file-transformation-pdf.md</code> Use cases keep In MkDocs nav. <code>docs/use-cases/file-transformation-media.md</code> Use cases keep In MkDocs nav. <code>docs/use-cases/web-scraping.md</code> Use cases keep In MkDocs nav. <code>docs/use-cases/publishing.md</code> Use cases keep In MkDocs nav. <code>docs/use-cases/chat-exploration.md</code> Use cases keep In MkDocs nav. <code>docs/use-cases/batch-operations.md</code> Use cases keep In MkDocs nav. <code>docs/analysis/performance-analysis-loading.md</code> Performance keep Keep; consider moving into a dedicated \u201cPerformance\u201d section later. <code>docs/analysis/browser-test-analysis-latest.md</code> QA / Browser tests keep Keep; consider moving into a dedicated \u201cQA\u201d section later. <code>docs/architecture/template-system.md</code> Templates merge Draft (DE). Either rewrite to English + standard header or move to scratch and keep out of nav. <code>docs/architecture/secretary-format-interfaces.md</code> Secretary formats keep Keep (not in nav). Consider moving under <code>docs/reference/api/</code> later. <code>docs/_secretary-service-docu/overview.md</code> Secretary API docs keep Keep (not in nav). Consider moving to <code>docs/reference/api/</code>. <code>docs/_secretary-service-docu/pdf.md</code> Secretary API docs keep Keep (not in nav). <code>docs/_secretary-service-docu/audio.md</code> Secretary API docs keep Keep (not in nav). <code>docs/_secretary-service-docu/transformer.md</code> Secretary API docs keep Keep (not in nav). <code>docs/mongodb-vector-search-index.md</code> MongoDB Vector Search merge Merge \u201ctoken index\u201d details into <code>docs/architecture/mongodb-vector-search.md</code>, then delete. <code>docs/mongodb-indexes.md</code> MongoDB indexes merge Move under <code>docs/reference/</code> (or keep as root but not canonical). <code>docs/github-branch-protection-setup.md</code> Repo ops merge Move to <code>docs/ops/</code> (or keep as root but not canonical). <code>docs/template-commoning-umbau.md</code> Template redesign delete Old draft (DE) in root; keep history in git. If still needed, rewrite as English and put into <code>docs/analysis/</code>. <code>docs/architecture/artifact-pipeline-v3-design.md</code> Artifact pipeline keep Keep (not in nav). <code>docs/architecture/requirements-artifact-pipeline-v3.md</code> Artifact pipeline keep Keep (not in nav). <code>docs/architecture/use-cases-and-personas.md</code> Personas keep Keep (not in nav). <code>docs/_analysis/audio-transcribe-without-template-2026-01-06.md</code> External Jobs (audio) merge Promote to <code>docs/analysis/</code> as validated decision (English), then delete from <code>_analysis</code>. <code>docs/_analysis/gallery-table-upsertedat-spalte.md</code> Gallery UI delete Very specific UI task; belongs in issue tracker, not canonical docs. <code>docs/_analysis/email-service-provider-examples.md</code> Email service delete Unrelated to v2-only pipeline; move to product/ops docs if needed. <code>docs/_analysis/shadow-twin-migration-and-items.md</code> Shadow\u2011Twin migration delete Contradicts v2-only runtime (moves truth into Mongo); keep history in git. <code>docs/_analysis/docs-cleanup-delete-list.md</code> Docs cleanup delete Will be replaced by <code>docs/analysis/docs-cleanup-delete-list.md</code>. <code>docs/_chats/cursor_ingestion_flow_strategie_und_red.md</code> Chat transcript delete Scratch; remove from repo docs tree."},{"location":"analysis/docs-cleanup-inventory.html#next-steps","title":"Next steps","text":"<ol> <li>Update the canonical docs to a consistent header format (status, last verified, scope, glossary, code links).</li> <li>Produce a delete list + merge plan (with replacements) in <code>docs/analysis/docs-cleanup-delete-list.md</code>.</li> <li>Apply deletes and fix internal links.</li> </ol>"},{"location":"analysis/finalize-wizard-comparison.html","title":"Vergleich: Urspr\u00fcnglicher Plan vs. Generischer Wizard","text":""},{"location":"analysis/finalize-wizard-comparison.html#ursprunglicher-plan-deterministisch","title":"Urspr\u00fcnglicher Plan (deterministisch)","text":""},{"location":"analysis/finalize-wizard-comparison.html#flow-c-finalisieren-deterministisch","title":"Flow C - Finalisieren (deterministisch)","text":"<p>Endpoint: <code>/api/library/[libraryId]/events/finalize</code></p> <p>Was passiert automatisch: 1. \u2705 Findet Event-Markdown automatisch (via <code>eventFileId</code>) 2. \u2705 Findet alle Testimonials automatisch (im <code>testimonials/</code> Ordner) 3. \u2705 Erstellt Final-Markdown deterministisch (ohne LLM):    - Event-Body bleibt erhalten    - Testimonials werden als Liste angeh\u00e4ngt    - Frontmatter wird aus Original \u00fcbernommen + <code>originalFileId</code>, <code>finalRunId</code>, <code>eventStatus: 'finalDraft'</code> 4. \u2705 Speichert in <code>finals/run-&lt;timestamp&gt;/event-final.md</code> 5. \u2705 Keine User-Interaktion n\u00f6tig - alles automatisch</p> <p>Vorteile: - \u2705 Sehr deterministisch - immer gleiches Ergebnis - \u2705 Schnell - keine LLM-Transformation - \u2705 Einfach - User muss nichts tun - \u2705 Versioniert - jeder Run erzeugt neue Datei</p> <p>Nachteile: - \u274c Keine LLM-Transformation (nur einfache Zusammenf\u00fchrung) - \u274c Keine Anpassung m\u00f6glich (User kann nichts \u00e4ndern) - \u274c Event-spezifisch (nicht generisch)</p>"},{"location":"analysis/finalize-wizard-comparison.html#flow-d-publizieren-deterministisch","title":"Flow D - Publizieren (deterministisch)","text":"<p>Endpoint: <code>/api/library/[libraryId]/events/publish-final</code></p> <p>Was passiert automatisch: 1. \u2705 Final-Datei wird ingestiert 2. \u2705 Original wird aus Index gel\u00f6scht 3. \u2705 Index-Swap komplett automatisch</p> <p>Vorteile: - \u2705 Sehr deterministisch - \u2705 Einfach - ein API-Call</p>"},{"location":"analysis/finalize-wizard-comparison.html#neuer-generischer-ansatz-weniger-deterministisch","title":"Neuer generischer Ansatz (weniger deterministisch)","text":""},{"location":"analysis/finalize-wizard-comparison.html#wizard-basiert","title":"Wizard-basiert","text":"<p>Was der User machen muss: 1. \u26a0\ufe0f Wizard starten 2. \u26a0\ufe0f Quellen ausw\u00e4hlen (welche Testimonials verwenden?) 3. \u26a0\ufe0f Transformation \u00fcberpr\u00fcfen (LLM-generiertes Markdown) 4. \u26a0\ufe0f Frontmatter bearbeiten (falls n\u00f6tig) 5. \u26a0\ufe0f Body bearbeiten (falls n\u00f6tig) 6. \u26a0\ufe0f Vorschau pr\u00fcfen 7. \u26a0\ufe0f Publizieren</p> <p>Vorteile: - \u2705 LLM-Transformation m\u00f6glich (intelligente Zusammenf\u00fchrung) - \u2705 User kann anpassen - \u2705 Generisch (funktioniert f\u00fcr beliebige Verzeichnisse) - \u2705 Konsistent mit Creation-Wizard</p> <p>Nachteile: - \u274c Mehr User-Interaktion n\u00f6tig - \u274c Weniger deterministisch - \u274c User muss wissen, was zu tun ist</p>"},{"location":"analysis/finalize-wizard-comparison.html#vergleich","title":"Vergleich","text":"Aspekt Urspr\u00fcnglicher Plan Generischer Wizard Determinismus \u2705 Sehr hoch (automatisch) \u26a0\ufe0f Niedriger (User-Interaktion) Geschwindigkeit \u2705 Schnell (kein LLM) \u26a0\ufe0f Langsamer (LLM + Review) Flexibilit\u00e4t \u274c Keine Anpassung \u2705 Vollst\u00e4ndig anpassbar Intelligenz \u274c Einfache Zusammenf\u00fchrung \u2705 LLM-Transformation User-Aufwand \u2705 Minimal (ein Klick) \u26a0\ufe0f Hoch (mehrere Schritte) Wiederverwendbarkeit \u274c Event-spezifisch \u2705 Generisch"},{"location":"analysis/finalize-wizard-comparison.html#problem","title":"Problem","text":"<p>Der neue Ansatz ist zu lose - der User muss zu viel wissen und tun. Der urspr\u00fcngliche Plan war deterministischer und einfacher.</p>"},{"location":"analysis/finalize-wizard-comparison.html#losung-hybrid-ansatz","title":"L\u00f6sung: Hybrid-Ansatz","text":"<p>Kombiniere die Vorteile beider Ans\u00e4tze:</p>"},{"location":"analysis/finalize-wizard-comparison.html#option-1-zwei-modi-im-wizard","title":"Option 1: Zwei Modi im Wizard","text":"<p>Modus A: Schnell (deterministisch) - Automatisch alle Testimonials verwenden - Einfache Zusammenf\u00fchrung (wie urspr\u00fcnglich) - Keine LLM-Transformation - Direkt speichern</p> <p>Modus B: Vollst\u00e4ndig (mit LLM) - User w\u00e4hlt Testimonials aus - LLM-Transformation - Review/Edit m\u00f6glich - Dann speichern</p>"},{"location":"analysis/finalize-wizard-comparison.html#option-2-wizard-mit-defaults","title":"Option 2: Wizard mit Defaults","text":"<p>Wizard startet mit: - \u2705 Alle Testimonials automatisch ausgew\u00e4hlt - \u2705 Transformation automatisch generiert - \u2705 User kann optional anpassen - \u2705 Wenn User nichts \u00e4ndert \u2192 wie urspr\u00fcnglicher Plan</p> <p>Vorteile: - \u2705 Determinismus durch Defaults - \u2705 Flexibilit\u00e4t durch Optionen - \u2705 User muss nichts tun, wenn Defaults OK sind</p>"},{"location":"analysis/finalize-wizard-comparison.html#option-3-beide-endpunkte-behalten","title":"Option 3: Beide Endpunkte behalten","text":"<p>F\u00fcr deterministischen Flow: - <code>/events/finalize</code> - Wie urspr\u00fcnglich (schnell, deterministisch)</p> <p>F\u00fcr flexiblen Flow: - Wizard - Mit LLM-Transformation und Anpassung</p> <p>Vorteile: - \u2705 Beste aus beiden Welten - \u2705 User kann w\u00e4hlen</p> <p>Nachteile: - \u274c Zwei verschiedene Wege (kann verwirrend sein)</p>"},{"location":"analysis/finalize-wizard-comparison.html#empfehlung-option-2-wizard-mit-defaults","title":"Empfehlung: Option 2 (Wizard mit Defaults)","text":"<p>Der Wizard sollte: 1. \u2705 Automatisch alle Testimonials finden (wie urspr\u00fcnglich) 2. \u2705 Automatisch alle ausw\u00e4hlen (Default) 3. \u2705 Automatisch Transformation generieren (wenn Template LLM verwendet) 4. \u2705 User kann optional anpassen (aber muss nicht)</p> <p>Das gibt: - Determinismus durch Defaults - Flexibilit\u00e4t durch Optionen - Einfachheit f\u00fcr Standard-Fall - Anpassbarkeit f\u00fcr Spezial-F\u00e4lle</p>"},{"location":"analysis/finalize-wizard-event-context.html","title":"Fragestellung","text":"<p>Soll im Finalize-Wizard der komplette Event\u2011Markdown inklusive Frontmatter als Kontext an den Secretary\u2011Service gesendet werden? Oder nur der Body?</p>"},{"location":"analysis/finalize-wizard-event-context.html#beobachtungen","title":"Beobachtungen","text":"<ul> <li>Das Frontmatter kann sensible Felder enthalten (z.B. <code>testimonialWriteKey</code>, interne IDs, Tracking\u2011Felder).</li> <li>Der Body ist f\u00fcr die inhaltliche Zusammenfassung zwingend relevant.</li> <li>Der Wizard nutzt den Kontext ausschlie\u00dflich zur Template\u2011Transformation (kein UI\u2011Output aus dem Rohkontext).</li> </ul>"},{"location":"analysis/finalize-wizard-event-context.html#risiken","title":"Risiken","text":"<ul> <li>Sicherheitsrisiko: Frontmatter kann Geheimnisse enthalten. Diese k\u00f6nnten im LLM\u2011Output wieder auftauchen.</li> <li>Qualit\u00e4tsrisiko: LLM k\u00f6nnte technische Metadaten in den Text \u00fcbernehmen.</li> <li>Datenschutzrisiko: Externe IDs/E-Mails k\u00f6nnten in der Zusammenfassung erscheinen.</li> </ul>"},{"location":"analysis/finalize-wizard-event-context.html#varianten","title":"Varianten","text":"<p>Variante A \u2013 Nur Body - Sende ausschlie\u00dflich den Body (Markdown ohne Frontmatter). - Vorteil: Kein Leak von Metadaten. - Nachteil: Event\u2011Titel/Teaser m\u00fcssen aus anderen Quellen kommen.</p> <p>Variante B \u2013 Gefiltertes Frontmatter + Body - Sende Body plus whitelisted Felder (z.B. <code>title</code>, <code>teaser</code>, <code>date</code>, <code>location</code>, <code>topics</code>, <code>tags</code>). - Vorteil: Mehr Kontext, kontrolliertes Risiko. - Nachteil: Zus\u00e4tzliche Mapping\u2011Logik n\u00f6tig.</p> <p>Variante C \u2013 Vollst\u00e4ndiges Markdown - Sende Frontmatter + Body unver\u00e4ndert. - Vorteil: Maximaler Kontext. - Nachteil: H\u00f6chstes Risiko, dass Secrets/IDs im Output landen.</p>"},{"location":"analysis/finalize-wizard-event-context.html#empfehlung","title":"Empfehlung","text":"<p>Variante B. Sie liefert mehr Kontext als nur der Body, ohne sensible Felder zu riskieren. Zus\u00e4tzlich sollten Felder wie <code>testimonialWriteKey</code>, <code>creationTemplateId</code> oder <code>textSources</code> explizit ausgeschlossen werden.</p>"},{"location":"analysis/ingestion.html","title":"Ingestion","text":""},{"location":"analysis/ingestion.html#ingestion-current-runtime","title":"Ingestion (current runtime)","text":"<p>Status: active Last verified: 2026-01-04  </p>"},{"location":"analysis/ingestion.html#scope","title":"Scope","text":"<p>This document describes how ingestion and vector storage work today. It is meant to be simple and operational (what to look at when something breaks).</p>"},{"location":"analysis/ingestion.html#glossary","title":"Glossary","text":"<ul> <li>Vector collection: MongoDB collection <code>vectors__${libraryId}</code></li> <li>meta: metadata-only doc (no embedding)</li> <li>chunk: text chunk + embedding</li> <li>chapterSummary: chapter summary + embedding</li> </ul>"},{"location":"analysis/ingestion.html#data-model-mongodb","title":"Data model (MongoDB)","text":"<p>We use one collection per library: - <code>vectors__${libraryId}</code></p> <p>Kinds: - <code>meta</code>: used for gallery + facets - <code>chunk</code>: used for semantic search - <code>chapterSummary</code>: used for chapter-based search</p> <p>Canonical architecture reference: - <code>docs/architecture/mongodb-vector-search.md</code></p>"},{"location":"analysis/ingestion.html#main-entry-points-code","title":"Main entry points (code)","text":"<ul> <li>Ingestion service: <code>src/lib/chat/ingestion-service.ts</code></li> <li>Vector repo: <code>src/lib/repositories/vector-repo.ts</code></li> </ul>"},{"location":"analysis/ingestion.html#practical-debugging-checklist","title":"Practical debugging checklist","text":"<p>When ingestion \u201clooks wrong\u201d, check: 1) Does a <code>meta</code> document exist for the fileId? 2) Do <code>chunk</code> documents exist for the same fileId? 3) Does <code>vector_search_idx</code> exist for the collection? 4) Are facet fields present on chunks (so filters work)?</p>"},{"location":"analysis/ingestion.html#common-failure-modes-what-it-usually-is","title":"Common failure modes (what it usually is)","text":""},{"location":"analysis/ingestion.html#1-ingestion-input-is-empty-too-short","title":"1) Ingestion input is empty / too short","text":"<p>Symptoms:</p> <ul> <li><code>ingest_rag</code> fails early</li> <li>ingestion appears \u201csuccessful\u201d but results in 0 useful chunks</li> </ul> <p>Typical causes:</p> <ul> <li>upstream artifact (transformation/transcript) is empty</li> <li>wrong artifact selected (e.g. missing/incorrect template context)</li> </ul> <p>Fix direction:</p> <ul> <li>treat empty ingestion input as a hard error (pipeline must not mark success)</li> <li>verify transformation output first (frontmatter + body)</li> </ul>"},{"location":"analysis/ingestion.html#2-vector-search-index-not-ready-initial_sync","title":"2) Vector Search index not READY (INITIAL_SYNC)","text":"<p>Symptoms:</p> <ul> <li>retrieval fails even though docs were upserted</li> <li>errors or very slow/no results right after index creation</li> </ul> <p>Fix direction:</p> <ul> <li>check index status in Atlas; INITIAL_SYNC can take minutes depending on size</li> </ul>"},{"location":"analysis/ingestion.html#3-token-index-missing-for-array-filters","title":"3) Token-index missing for array filters","text":"<p>Symptoms:</p> <ul> <li>errors like: \u201cPath 'authors' needs to be indexed as token\u201d</li> <li>filters work for scalar fields but break for array fields (authors/tags/topics/\u2026)</li> </ul> <p>Fix direction:</p> <ul> <li>update the Atlas Search index definition (token indexing for array fields you filter on)</li> <li>rebuild/recreate index if needed</li> </ul>"},{"location":"analysis/ingestion.html#4-wrong-fileid-used-for-upserts-mismatched-namespaces","title":"4) Wrong <code>fileId</code> used for upserts (mismatched namespaces)","text":"<p>Symptoms:</p> <ul> <li>meta doc exists for a different id than the file you query</li> <li>ingestion-status says \u201cnot indexed\u201d although ingestion ran</li> </ul> <p>Fix direction:</p> <ul> <li>ensure <code>fileId</code> used for vector upserts matches the source fileId used by the UI</li> </ul>"},{"location":"analysis/ingestion.html#operational-probes-fast-checks","title":"Operational probes (fast checks)","text":""},{"location":"analysis/ingestion.html#a-ingestion-status-endpoint-ui-friendly","title":"A) Ingestion status endpoint (UI-friendly)","text":"<p>Use:</p> <ul> <li><code>GET /api/chat/{libraryId}/ingestion-status?fileId=...</code></li> </ul> <p>What to look for:</p> <ul> <li><code>doc.exists=true</code></li> <li>reasonable <code>chunkCount</code> and <code>chaptersCount</code></li> <li>staleness (docModifiedAt vs stored docModifiedAt)</li> </ul>"},{"location":"analysis/ingestion.html#b-retrieval-sanity-check-chat-stream","title":"B) Retrieval sanity check (chat stream)","text":"<p>Use:</p> <ul> <li><code>POST /api/chat/{libraryId}/stream</code></li> </ul> <p>What to look for:</p> <ul> <li>retriever selection (chunk vs summary)</li> <li>retrieval steps returning sources (non-empty)</li> </ul>"},{"location":"analysis/ingestion.html#related-docs","title":"Related docs","text":"<ul> <li>End-to-end overview: <code>docs/use-cases/file-to-story.md</code></li> <li>Vector architecture: <code>docs/architecture/mongodb-vector-search.md</code></li> </ul>"},{"location":"analysis/integration-tests-agent-mode.html","title":"Integration tests agent mode","text":""},{"location":"analysis/integration-tests-agent-mode.html#ziel","title":"Ziel","text":"<p>Wir m\u00f6chten Integrationstests so ausf\u00fchren, dass ein Agent sie starten und die Ergebnisse automatisch auswerten kann, ohne manuelles Copy/Paste aus der UI. Gleichzeitig sollen Runs reproduzierbar und debugbar bleiben (JobIds, Assertions, Logs).</p>"},{"location":"analysis/integration-tests-agent-mode.html#ausgangslage-ist","title":"Ausgangslage (Ist)","text":"<ul> <li>Es existiert bereits eine Integrationstest-Seite (<code>/integration-tests</code>) sowie serverseitige Endpoints:</li> <li><code>POST /api/integration-tests/run</code>: f\u00fchrt Tests aus und liefert Ergebnisse als JSON.</li> <li><code>POST /api/integration-tests/results</code>: bewertet bestehende Jobs anhand Testcases.</li> <li>Der Orchestrator (<code>src/lib/integration-tests/orchestrator.ts</code>) startet echte External Jobs, wartet auf Abschluss und validiert.</li> <li>Problem: Ein Agent kann nicht zuverl\u00e4ssig auf den Browser-Console-Output zugreifen, und manuelles Copy/Paste der Logs ist unpraktisch.</li> </ul>"},{"location":"analysis/integration-tests-agent-mode.html#varianten","title":"Varianten","text":""},{"location":"analysis/integration-tests-agent-mode.html#variante-a-empfohlen-runid-serverseitiger-result-store-internal-token","title":"Variante A (empfohlen): \u201eRunId + serverseitiger Result-Store + Internal-Token\u201c","text":"<p>Idee: <code>POST /api/integration-tests/run</code> erzeugt ein <code>runId</code>, speichert Resultate serverseitig (in-memory, dev-sicher via <code>globalThis</code>) und gibt JSON zur\u00fcck. Zus\u00e4tzlich erlaubt ein Internal-Token (z.B. <code>INTERNAL_TEST_TOKEN</code>) die Ausf\u00fchrung auch ohne Clerk-Session (z.B. per CLI).</p> <p>Vorteile - Voll automatisierbar: Agent/CI kann per HTTP starten und Ergebnis als JSON auswerten. - Keine UI n\u00f6tig, keine Copy/Paste n\u00f6tig. - Debug bleibt gut: JobIds + Validation-Messages bleiben im JSON enthalten.</p> <p>Nachteile - In-memory Store ist dev-geeignet; f\u00fcr CI/parallel w\u00e4re sp\u00e4ter Persistenz (DB) sinnvoll.</p>"},{"location":"analysis/integration-tests-agent-mode.html#variante-b-headless-ui-e2e-playwright-gegen-integration-tests","title":"Variante B: Headless UI-E2E (Playwright) gegen <code>/integration-tests</code>","text":"<p>Idee: Playwright klickt UI, liest DOM-Ergebnisse, bewertet.</p> <p>Vorteile - Testet auch UI/State/Rendering.</p> <p>Nachteile - Fragiler, langsamer, h\u00f6herer Wartungsaufwand. - CI-Komplexit\u00e4t (Browser, Auth, Timings).</p>"},{"location":"analysis/integration-tests-agent-mode.html#variante-c-nur-cli-orchestrator-ohne-http","title":"Variante C: \u201eNur CLI-Orchestrator\u201c ohne HTTP","text":"<p>Idee: Orchestrator als Node-Script direkt aufrufen, Assertions im Script.</p> <p>Vorteile - Einfach in CI zu integrieren.</p> <p>Nachteile - Umgeht API/Auth-Realit\u00e4t teilweise (je nach Implementierung). - Weniger \u201erealistisch\u201c als HTTP-Pfade, wenn diese sich ver\u00e4ndern.</p>"},{"location":"analysis/integration-tests-agent-mode.html#entscheidung","title":"Entscheidung","text":"<p>Wir setzen Variante A um, weil sie die vorhandene Architektur erweitert (statt zu duplizieren), echte HTTP-Integration erm\u00f6glicht und einen Agent/CI-Loop ohne Copy/Paste erlaubt. Optional kann sp\u00e4ter Variante B erg\u00e4nzend UI-E2E abdecken.</p>"},{"location":"analysis/integration-tests-storage-agnostic.html","title":"Integration tests storage agnostic","text":""},{"location":"analysis/integration-tests-storage-agnostic.html#ziel","title":"Ziel","text":"<p>Die Integrationstest-Suite soll Use-Cases validieren \u2013 unabh\u00e4ngig davon, ob Shadow\u2011Twin Artefakte prim\u00e4r in MongoDB oder im Filesystem/Provider liegen. Das hei\u00dft: Die Tests d\u00fcrfen nicht implizit annehmen, dass es einen Dot\u2011Folder gibt oder dass Artefakte als <code>.md</code> Dateien im Parent liegen. Stattdessen m\u00fcssen sie \u00fcber die zentrale Shadow\u2011Twin\u2011Abstraktion (<code>ShadowTwinService</code>) pr\u00fcfen, ob Artefakte existieren/lesbar sind und ob der Job\u2011Contract (z.B. <code>result.savedItemId</code>) erf\u00fcllt ist.</p> <p>Zus\u00e4tzlich sollen die Tests deterministisch und wiederholbar sein: - \u201eclean\u201c muss wirklich clean sein (auch f\u00fcr Mongo). - \u201eexists\u201c/\u201eincomplete_frontmatter\u201c m\u00fcssen aktiv hergestellt werden, nicht durch \u201evorheriger Lauf war schon mal da\u201c.</p>"},{"location":"analysis/integration-tests-storage-agnostic.html#beobachtungen-aus-dem-aktuellen-stand","title":"Beobachtungen aus dem aktuellen Stand","text":"<ul> <li><code>prepareShadowTwinForTestCase()</code> l\u00f6scht aktuell nur Filesystem\u2011Artefakte (Dot\u2011Folder + Transcript im Parent) und nicht MongoDB\u2011Artefakte. Dadurch ist \u201eclean\u201c bei <code>primaryStore=mongo</code> faktisch nicht clean \u2192 Gates skippen unerwartet (Happy\u2011Path wird rot).</li> <li>Die Template\u2011Skip\u2011Logik in <code>src/lib/external-jobs/phase-template.ts</code> pr\u00fcft \u201echapters bereits vorhanden\u201c \u00fcber Provider\u2011Siblings im Filesystem. Bei <code>persistToFilesystem=false</code> existiert aber keine <code>.md</code> Datei \u2192 Template wird nicht geskippt, obwohl die Transformation in Mongo existiert.</li> <li>Validatoren waren teils Filesystem\u2011zentriert; daf\u00fcr wurde bereits ein Mongo\u2011Aware Pfad erg\u00e4nzt. F\u00fcr echte Storage\u2011Agnostik sollte die Shadow\u2011Twin\u2011Existenz/Lesbarkeit in allen F\u00e4llen via <code>ShadowTwinService</code> gepr\u00fcft werden.</li> </ul>"},{"location":"analysis/integration-tests-storage-agnostic.html#3-losungsvarianten","title":"3 L\u00f6sungsvarianten","text":""},{"location":"analysis/integration-tests-storage-agnostic.html#variante-a-nur-validatoren-generalisieren-klein-aber-nicht-deterministisch","title":"Variante A: \u201eNur Validatoren generalisieren\u201c (klein, aber nicht deterministisch)","text":"<p>Idee - Validatoren pr\u00fcfen Artefakte ausschlie\u00dflich via <code>ShadowTwinService</code>. - Keine File\u2011System\u2011Annahmen (kein <code>shadowTwinFolderId</code> Fail bei <code>persistToFilesystem=false</code>).</p> <p>Vorteile - Minimaler Eingriff. - Gute Aussagekraft f\u00fcr \u201eEndzustand ok\u201c (Artefakt existiert/lesbar, Contract erf\u00fcllt).</p> <p>Nachteile - Tests bleiben \u201eflaky\u201c, weil Precondition\u2011State (<code>clean/exists</code>) nicht deterministisch hergestellt wird. - Skip/Force\u2011Usecases sind schwer reproduzierbar, wenn bereits alte Artefakte existieren.</p>"},{"location":"analysis/integration-tests-storage-agnostic.html#variante-b-deterministische-precondition-servicechecks-empfohlen","title":"Variante B: \u201eDeterministische Precondition + Service\u2011Checks\u201c (empfohlen)","text":"<p>Idee - <code>prepareShadowTwinForTestCase()</code> wird storage\u2011agnostisch:   - <code>clean</code>: l\u00f6scht Filesystem + Mongo Artefakte f\u00fcr <code>sourceId</code>.   - <code>exists</code>: erzeugt definierte Artefakte (Transcript + Transformation) mit gew\u00fcnschtem Frontmatter.   - <code>incomplete_frontmatter</code>: erzeugt Transformation mit <code>chapters</code>, aber ohne <code>pages</code> (oder fehlendem Feld), um Repair zu testen. - Job\u2011Runtime: Template\u2011Skip/Repair darf nicht provider\u2011basiert sein \u2192 <code>phase-template.ts</code> muss f\u00fcr \u201eexisting chapters\u201c ebenfalls <code>ShadowTwinService.getMarkdown()</code> verwenden.</p> <p>Vorteile - Tests sind wiederholbar (gleiches Ergebnis bei wiederholten Runs). - Skip/Force\u2011Szenarien k\u00f6nnen zuverl\u00e4ssig validiert werden. - Direkte Validierung der neuen zentralen Shadow\u2011Twin\u2011Logik.</p> <p>Nachteile / Aufwand - Es wird eine Mongo\u2011Delete/Reset\u2011Operation ben\u00f6tigt (f\u00fcr Tests). Das kann als Repo\u2011Helper (<code>deleteShadowTwinBySourceId</code>) implementiert werden. - F\u00fcr Filesystem\u2011Precondition braucht es ggf. definierte Template\u2011Namen (oder eine \u201ebest transformation\u201c Auswahl ohne templateName).</p>"},{"location":"analysis/integration-tests-storage-agnostic.html#variante-c-isolierte-testfiles-statt-delete-robust-aber-schwergewichtig","title":"Variante C: \u201eIsolierte Testfiles statt Delete\u201c (robust, aber schwergewichtig)","text":"<p>Idee - Statt Cleanup zu implementieren, kopiert der Test Runner die PDF pro Run in einen neuen \u201eScratch\u201c\u2011Pfad/Name \u2192 neue <code>sourceId</code>, keine Kollisionen. - Skip/Exists wird durch sequenzielle Jobs in derselben Testcase\u2011Ausf\u00fchrung erzeugt (Warm\u2011up Run, dann eigentlicher Test).</p> <p>Vorteile - Kein Delete notwendig, keine Race Conditions mit parallelen Runs. - Sehr robust gegen \u201ealte Artefakte\u201c.</p> <p>Nachteile - H\u00f6herer Storage\u2011Overhead (kopierte PDFs, ggf. Cleanup sp\u00e4ter n\u00f6tig). - Setup\u2011Zeit h\u00f6her; bei gro\u00dfen PDFs kann das sp\u00fcrbar sein.</p>"},{"location":"analysis/integration-tests-storage-agnostic.html#konkrete-definition-storageagnostische-assertions","title":"Konkrete Definition \u201eStorage\u2011agnostische Assertions\u201c","text":"<p>Unabh\u00e4ngig vom Store sollten Use\u2011Case\u2011Tests prim\u00e4r pr\u00fcfen: - Job\u2011Status (<code>completed</code> / <code>failed</code>) gem. Erwartung. - Phase\u2011Semantik (Run vs Skip vs Force) anhand Job\u2011Step Details (nicht anhand Dateisystem\u2011Existenz). - <code>result.savedItemId</code> erf\u00fcllt Contract und referenziert ein Artefakt des erwarteten Kinds. - Das erwartete Artefakt ist lesbar \u00fcber <code>ShadowTwinService.getMarkdown()</code> (auch wenn kein Dot\u2011Folder existiert). - Optional: inhaltliche Probe (Frontmatter\u2011Keys wie <code>chapters</code>/<code>pages</code>, falls Szenario das verlangt).</p>"},{"location":"analysis/integration-tests-storage-agnostic.html#entscheidung","title":"Entscheidung","text":"<p>Variante B ist die passende Basis, weil sie die Suite gleichzeitig 1) storage\u2011agnostisch, 2) deterministisch, 3) und aussagekr\u00e4ftig f\u00fcr Skip/Force\u2011Szenarien macht.</p>"},{"location":"analysis/markdown-page-splitting.html","title":"Markdown Page Splitting for PDF Measures","text":""},{"location":"analysis/markdown-page-splitting.html#context","title":"Context","text":"<p>We need one document per PDF page (each page represents a single measure). The current PDF pipeline already inserts explicit page markers in the transcript markdown (<code>--- Seite N ---</code>). These markers are reliable enough for deterministic splitting without re-running OCR.</p>"},{"location":"analysis/markdown-page-splitting.html#options-considered","title":"Options Considered","text":"<ul> <li>Split transcript markdown into per-page files, then transform per file.   Low risk and minimal new logic, but requires a per-file transform mode to avoid combined output.</li> <li>Create one external job per page.   Accurate but creates high orchestration overhead.</li> <li>Re-OCR page images.   Expensive and unnecessary because transcript markers already exist.</li> </ul>"},{"location":"analysis/markdown-page-splitting.html#decision","title":"Decision","text":"<p>Implement a page splitter that turns transcript markdown into <code>page-XXX.md</code> files inside a folder named after the source file. Then extend batch transformation with a per-file mode so each page gets its own template output.</p>"},{"location":"analysis/markdown-page-splitting.html#risks-mitigations","title":"Risks &amp; Mitigations","text":"<ul> <li>Missing or malformed page markers \u2192 return a clear error and avoid partial output.</li> <li>Unsafe folder names \u2192 sanitize source file name to a filesystem-safe folder name.</li> <li>Output collisions \u2192 use deterministic <code>page-XXX</code> names and template-specific output names.</li> </ul>"},{"location":"analysis/markdown-page-splitting.html#validation-plan","title":"Validation Plan","text":"<ul> <li>Unit test for page splitting using real marker format.</li> <li>Manual test: split a PDF transcript and confirm 1 file per page.</li> <li>Batch test: per-file transform yields one output document per page.</li> </ul>"},{"location":"analysis/markdown-processing-pipeline.html","title":"Analyse: Markdown-Verarbeitung (Preview/Transformation/Ingestion)","text":""},{"location":"analysis/markdown-processing-pipeline.html#ausgangsfrage","title":"Ausgangsfrage","text":"<p>Markdown ist bereits Text. Daher ist eine Transkription/Extraction (wie bei Audio/PDF) fachlich meist unn\u00f6tig. Trotzdem sind Template-Transformation (Frontmatter/Struktur) und Ingestion (RAG/Vector Search) weiterhin relevant.</p> <p>Diese Notiz dokumentiert, wie der aktuelle Flow im UI aussieht und welche (minimalen) Wege f\u00fcr Integrationstests sinnvoll sind.</p>"},{"location":"analysis/markdown-processing-pipeline.html#beobachtungen-im-ui-filepreview","title":"Beobachtungen im UI (<code>FilePreview</code>)","text":"<ul> <li>Dateityp-Erkennung: <code>file-preview.tsx</code> klassifiziert <code>.md/.mdx/.txt</code> als <code>markdown</code> und behandelt viele \u201etextartige\u201c Extensions ebenfalls als editierbar.</li> <li>Transformation (Template): Der UI-Flow l\u00e4uft prim\u00e4r \u00fcber <code>TransformationDialog</code> + <code>BatchTransformService</code>.</li> <li>Der Dialog akzeptiert Markdown direkt (kein Transcript/Resolver n\u00f6tig).</li> <li>Bei PDFs versucht der Dialog zuerst ein Transcript-Markdown per Resolver zu finden; bei <code>.md</code> entf\u00e4llt das.</li> <li>Ingestion: In <code>job-report-tab.tsx</code> (\u201eVer\u00f6ffentlichen\u201c) wird die Route   <code>POST /api/chat/{libraryId}/ingest-markdown</code> aufgerufen.</li> <li>Damit wird ein vorhandenes Markdown (typischerweise Transformation) ingestiert.</li> </ul>"},{"location":"analysis/markdown-processing-pipeline.html#beobachtungen-im-external-job-orchestrator-server","title":"Beobachtungen im External-Job-Orchestrator (Server)","text":"<p>Die modulare External-Job-Pipeline (<code>src/lib/external-jobs/*</code>) ist historisch stark auf PDF/Shadow\u2011Twin-Artefakte zugeschnitten:</p> <ul> <li><code>preprocess-core.findPdfMarkdown()</code> nutzt in Teilen noch PDF-Annahmen (<code>${baseName}.pdf</code>) als Fallback.</li> <li>Template- und Ingest-Preprocessor suchen prim\u00e4r Transformationen im Shadow\u2011Twin-Kontext.</li> </ul> <p>Konsequenz: Ein \u201eMarkdown als Quelle\u201c\u2011Flow ist aktuell nicht der nat\u00fcrliche Pfad der External\u2011Jobs, sondern eher der UI\u2011Pfad \u201eText/Markdown \u2192 Template-Transform \u2192 Shadow\u2011Twin \u2192 Ingest\u201c.</p>"},{"location":"analysis/markdown-processing-pipeline.html#varianten-losungsoptionen","title":"Varianten (L\u00f6sungsoptionen)","text":""},{"location":"analysis/markdown-processing-pipeline.html#variante-a-ingest-only-fur-markdown","title":"Variante A: \u201eIngest-only\u201c f\u00fcr Markdown","text":"<ul> <li>Wann sinnvoll: Markdown-Dateien sind bereits final (Frontmatter vorhanden / keine Template-Struktur n\u00f6tig).</li> <li>Vorteile: Minimal, robust, wenig Abh\u00e4ngigkeiten.</li> <li>Risiko: Template-Transformation wird nicht abgedeckt; Qualit\u00e4ts-/Strukturregeln (Frontmatter) evtl. nicht erzwungen.</li> </ul>"},{"location":"analysis/markdown-processing-pipeline.html#variante-b-template-ingest-ohne-external-jobs-ui-nah","title":"Variante B: \u201eTemplate + Ingest\u201c ohne External-Jobs (UI-nah)","text":"<ul> <li>Idee: Serverseitig analog zum UI-Flow:</li> <li>Markdown lesen \u2192 Secretary Template-Transformer aufrufen \u2192 frontmatter-basiertes Markdown erzeugen</li> <li>Transformation im Shadow\u2011Twin speichern \u2192 Ingestion durchf\u00fchren</li> <li>Vorteile: Deckt den fachlich relevanten Pfad f\u00fcr Markdown ab, ohne die External-Job-Pipeline umzubauen.</li> <li>Constraints: F\u00fcr deterministische Runs braucht man Template-Content (z.B. aus MongoDB); reine \u201eStandard-Template-Name\u201c-Calls   sind serverseitig nicht \u00fcberall verf\u00fcgbar.</li> </ul>"},{"location":"analysis/markdown-processing-pipeline.html#variante-c-external-job-orchestrator-mediatypetextmarkdown-erweitern","title":"Variante C: External-Job-Orchestrator \u201emediaType=text/markdown\u201c erweitern","text":"<ul> <li>Idee: External-Jobs so erweitern, dass Markdown als Source (ohne Extract) sauber unterst\u00fctzt wird:</li> <li><code>findPdfMarkdown</code> generalisieren (kein PDF-Fallback)</li> <li>Job-Typ/Step-Naming f\u00fcr Text/Markdown definieren</li> <li>Template/Ingester direkt auf Source-Markdown anwenden</li> <li>Vorteile: Einheitliche Pipeline f\u00fcr alle Medien.</li> <li>Nachteil: Gr\u00f6\u00dferer Umbau, mehr Regression-Risiko.</li> </ul>"},{"location":"analysis/markdown-processing-pipeline.html#aktueller-stand-implementationsnotiz","title":"Aktueller Stand (Implementationsnotiz)","text":"<p>F\u00fcr Integrationstests wurde der Markdown-Testcase auf \u201eTemplate + Ingestion\u201c ausgerichtet (Variante B), ohne den External-Job-Orchestrator als Voraussetzung zu erzwingen.</p> <p>Wichtig: Diese Variante ist nur so gut wie die Verf\u00fcgbarkeit des verwendeten Templates in MongoDB (Template-Content wird serverseitig geladen). Die End-to-End-Integration mit dem realen Secretary Service ist ein echter Integrationstest und muss in der Umgebung ausgef\u00fchrt werden.</p>"},{"location":"analysis/markdown-search-scroll-issue.html","title":"Markdown search scroll issue","text":"<p># Markdown-Suche: Scroll springt zurueck</p>"},{"location":"analysis/markdown-search-scroll-issue.html#kontext","title":"Kontext","text":"<p>Beim Ausloesen der Schnellsuche in der Markdown-Preview scrollt die Ansicht kurz zur Fundstelle und springt dann wieder zur vorherigen Position zurueck. Das Verhalten tritt sowohl im normalen als auch im Vollbild-Modus auf. Das deutet auf ein nachtraegliches Re-Rendering oder ein Scroll-Reset im Container hin.</p>"},{"location":"analysis/markdown-search-scroll-issue.html#beobachtungen","title":"Beobachtungen","text":"<ul> <li>Die Suche markiert den Treffer per DOM-Manipulation (replaceChild + span highlight).</li> <li>Der Scroll erfolgt ueber <code>containerRef.scrollTo(...)</code>, waehrend der Treffer im <code>contentRef</code> gesucht wird.</li> <li>Ein Popover/Tooltip fuer die Suche aktualisiert State und kann Re-Renderings ausloesen.</li> </ul>"},{"location":"analysis/markdown-search-scroll-issue.html#moegliche-ursachen","title":"Moegliche Ursachen","text":"<ol> <li>Re-Rendering des Scroll-Containers: Ein State-Wechsel (Popover, Tab, Fullscreen) re-rendered den Container und setzt <code>scrollTop</code> zurueck.</li> <li>Race Conditions im DOM: DOM-Manipulation (replaceChild) und Scroll passieren zu frueh oder in falscher Reihenfolge.</li> <li>Scroll-Konflikt: Ein zweiter Effekt oder Handler (z. B. Tab-Reset) setzt den Scroll unmittelbar nach dem Suchen wieder zurueck.</li> </ol>"},{"location":"analysis/markdown-search-scroll-issue.html#varianten-zur-loesung","title":"Varianten zur Loesung","text":""},{"location":"analysis/markdown-search-scroll-issue.html#variante-a-stateful-isolation-scroll-persistenz","title":"Variante A: Stateful Isolation + Scroll-Persistenz","text":"<ul> <li>Suche komplett in eine isolierte Komponente auslagern.</li> <li>Scroll-Position im Container vor/ nach der Suche explizit speichern und wiederherstellen.</li> <li>Vorteil: minimalinvasiv, geringe Aenderungen.</li> <li>Risiko: kaschiert tieferliegende Ursache.</li> </ul>"},{"location":"analysis/markdown-search-scroll-issue.html#variante-b-render-stabilisierung-des-markdown-inhalts","title":"Variante B: Render-Stabilisierung des Markdown-Inhalts","text":"<ul> <li>Markdown-Content in eine stabile Subkomponente auslagern und per <code>React.memo</code> + <code>useRef</code> rendern, sodass DOM nicht neu gesetzt wird.</li> <li>Highlighting ueber CSS (z. B. <code>mark</code>-Overlay) statt <code>replaceChild</code>.</li> <li>Vorteil: verhindert Re-Render-induziertes Neuladen.</li> <li>Risiko: groesserer Umbau im Preview-Rendering.</li> </ul>"},{"location":"analysis/markdown-search-scroll-issue.html#variante-c-suche-als-reines-dom-overlay","title":"Variante C: Suche als reines DOM-Overlay","text":"<ul> <li>Keine DOM-Manipulation am Inhalt.</li> <li>Treffer via Range API markieren und scrollen, aber kein persistentes Aendern der Nodes.</li> <li>Vorteil: kein DOM-Reset, geringes Risiko fuer Bild-Reloads.</li> <li>Risiko: komplexeres Handling fuer Edge-Cases (mehrere Treffer, Entfernen der Markierung).</li> </ul>"},{"location":"analysis/markdown-search-scroll-issue.html#entscheidung","title":"Entscheidung","text":"<p>Variante A wird umgesetzt: Scroll-Position wird beim Suchen explizit stabilisiert und nach kurzer Verzoegerung erneut gesetzt, um spaete Reflows/State-Updates zu ueberbruecken. Das ist die minimalinvasive Aenderung und dient als pragmatischer Fix. Falls das Problem danach weiter besteht, folgt Variante B oder C.</p>"},{"location":"analysis/mongo-gates-vs-filesystem-gates.html","title":"Mongo gates vs filesystem gates","text":""},{"location":"analysis/mongo-gates-vs-filesystem-gates.html#problemstellung","title":"Problemstellung","text":"<p>Beim erneuten Starten eines Jobs f\u00fcr dieselbe Quelle (ohne \u201eerzwingen\u201c) werden <code>extract_pdf</code>, <code>transform_template</code> und <code>ingest_rag</code> trotzdem erneut ausgef\u00fchrt. Das ist unerw\u00fcnscht, wenn die Artefakte bereits existieren.</p>"},{"location":"analysis/mongo-gates-vs-filesystem-gates.html#beobachtung-kritisch","title":"Beobachtung (kritisch)","text":"<p>Die Gate-/Preprocess-Logik hatte bisher zwei zentrale Schw\u00e4chen:</p> <ol> <li>Gates &amp; Preprozessoren nutzten prim\u00e4r den <code>StorageProvider</code> (Filesystem/OneDrive/etc.), um Artefakte zu finden.</li> <li>Das funktioniert, wenn Shadow\u2011Twins im Filesystem liegen.</li> <li> <p>Es funktioniert nicht, wenn <code>primaryStore='mongo'</code> ist und <code>persistToFilesystem=false</code>, weil dann keine Artefakte im Provider sichtbar sind.</p> </li> <li> <p>Dadurch wurde \u201eArtefakt existiert\u201c f\u00e4lschlich als false bewertet:</p> </li> <li><code>gateExtractPdf()</code> fand kein Transcript im Storage \u2192 <code>extractGateExists=false</code></li> <li><code>preprocessorTransformTemplate()</code> fand keine Transformation \u2192 <code>needTemplate=true</code></li> <li><code>preprocessorIngest()</code> fand kein transformiertes Markdown \u2192 <code>needIngest=true</code></li> </ol> <p>Die Folge ist deterministisch: Jobs laufen erneut, obwohl MongoDB bereits den Shadow\u2011Twin enth\u00e4lt.</p>"},{"location":"analysis/mongo-gates-vs-filesystem-gates.html#losungsvarianten","title":"L\u00f6sungsvarianten","text":""},{"location":"analysis/mongo-gates-vs-filesystem-gates.html#variante-a-mongo-aware-gates-minimal-invasiv","title":"Variante A \u2013 Mongo-aware Gates (minimal-invasiv)","text":"<p>Wenn <code>primaryStore='mongo'</code>: - Gates pr\u00fcfen Existenz direkt im Shadow\u2011Twin\u2011Dokument. - Storage-Fallback nur, wenn <code>allowFilesystemFallback=true</code>.</p> <p>Pro: wenig Umbau, schnelle Entscheidung, keine Storage-Scans. Contra: Muss sauber zwischen Transcript vs. Transformation unterscheiden.</p>"},{"location":"analysis/mongo-gates-vs-filesystem-gates.html#variante-b-mongo-aware-preprozessoren-praziser-aber-mehr-umbau","title":"Variante B \u2013 Mongo-aware Preprozessoren (pr\u00e4ziser, aber mehr Umbau)","text":"<p>Preprozessoren laden gezielt: - Extract: Transcript aus Mongo - Template/Ingest: Transformation aus Mongo (TemplateName + Sprache)</p> <p>Pro: richtige Semantik pro Phase, Frontmatter-Analyse auf Transformation statt Transcript. Contra: Mehr Stellen anzupassen.</p>"},{"location":"analysis/mongo-gates-vs-filesystem-gates.html#variante-c-shadowtwinstate-zentralisieren-groerer-umbau","title":"Variante C \u2013 ShadowTwinState zentralisieren (gr\u00f6\u00dferer Umbau)","text":"<p><code>analyzeShadowTwin()</code> w\u00fcrde f\u00fcr Mongo-PrimaryStore ebenfalls Mongo konsultieren, so dass alle Konsumenten (UI/Jobs) konsistente States bekommen.</p> <p>Pro: Single Source of Truth. Contra: Signatur/Abh\u00e4ngigkeiten \u00e4ndern (libraryId/userEmail), h\u00f6heres Risiko.</p>"},{"location":"analysis/mongo-gates-vs-filesystem-gates.html#entscheidung","title":"Entscheidung","text":"<p>Wir implementieren Variante A + B:</p> <ul> <li><code>gateExtractPdf()</code> ist mongo-aware (Transcript-Existenz).</li> <li><code>findPdfMarkdown()</code> unterst\u00fctzt Mongo direkt und kann Transcript oder Transformation laden.</li> <li>Preprozessoren nutzen <code>findPdfMarkdown()</code> mit dem passenden <code>preferredKind</code>:</li> <li>Extract \u2192 <code>transcript</code></li> <li>Template/Ingest \u2192 <code>transformation</code> (mit <code>templateName</code>)</li> </ul> <p>Damit werden bestehende Artefakte in MongoDB als \u201eexistiert\u201c erkannt und die Phasen laufen ohne \u201eerzwingen\u201c nicht erneut.</p>"},{"location":"analysis/performance-analysis-loading.html","title":"Performance-Analyse: Ladeverhalten und Verzeichniswechsel","text":""},{"location":"analysis/performance-analysis-loading.html#problemstellung","title":"Problemstellung","text":"<p>Die Anwendung ist sehr tr\u00e4ge, besonders bei Verzeichniswechseln. Ziel: Unn\u00f6tige Operationen identifizieren und eliminieren.</p>"},{"location":"analysis/performance-analysis-loading.html#identifizierte-performance-probleme","title":"Identifizierte Performance-Probleme","text":""},{"location":"analysis/performance-analysis-loading.html#1-mehrfache-api-calls-beim-verzeichniswechsel","title":"1. Mehrfache API-Calls beim Verzeichniswechsel","text":"<p>Problem: Beim Navigieren zu einem Ordner werden mehrere API-Calls ausgef\u00fchrt:</p> <ol> <li><code>navigateToFolder</code> \u2192 <code>getPathItemsById(folderId)</code> - L\u00e4dt den gesamten Pfad</li> <li><code>navigateToFolder</code> \u2192 <code>getItemById(folderId)</code> - L\u00e4dt den Zielordner selbst</li> <li><code>loadItems</code> \u2192 <code>listItems(currentFolderId)</code> - L\u00e4dt den Ordnerinhalt</li> <li>FileTree \u2192 <code>listItemsById(folderId)</code> - Kann zus\u00e4tzlich Ordnerinhalt laden (bei Auto-Expand)</li> </ol> <p>L\u00f6sung: - <code>getPathItemsById</code> sollte bereits den Zielordner enthalten (oder wir kombinieren die Calls) - Cache-Check in <code>loadItems</code> sollte vor dem API-Call erfolgen - FileTree sollte nicht nochmal laden, wenn <code>loadItems</code> bereits l\u00e4dt</p>"},{"location":"analysis/performance-analysis-loading.html#2-shadow-twin-analyse-bei-jedem-ordnerwechsel","title":"2. Shadow-Twin-Analyse bei jedem Ordnerwechsel","text":"<p>Problem: <code>useShadowTwinAnalysis</code> analysiert ALLE Dateien im Ordner bei jedem Wechsel: - Bei 100 Dateien = 100 API-Calls - L\u00e4uft synchron, blockiert UI - Wird auch ausgef\u00fchrt, wenn sich nichts ge\u00e4ndert hat</p> <p>L\u00f6sung: - Analyse nur f\u00fcr neue/ge\u00e4nderte Dateien (bereits implementiert, aber pr\u00fcfen) - Debouncing bei schnellen Ordnerwechseln - Lazy Loading: Analyse erst nach kurzer Verz\u00f6gerung - Parallelisierung optimieren</p>"},{"location":"analysis/performance-analysis-loading.html#3-redundante-useeffect-ausfuhrungen","title":"3. Redundante useEffect-Ausf\u00fchrungen","text":"<p>Problem: Mehrere useEffects reagieren auf <code>currentFolderId</code>:</p> <ol> <li><code>library.tsx</code> - Initial Load Effect (Zeile 320-371)</li> <li><code>library.tsx</code> - Library Change Effect (Zeile 378-400)</li> <li><code>file-tree.tsx</code> - Auto-Expand Effect (Zeile 439-534)</li> <li><code>file-list.tsx</code> - Shadow-Twin Analysis (Zeile 767)</li> </ol> <p>L\u00f6sung: - Konsolidiere Logik in weniger useEffects - Verwende Refs f\u00fcr Werte, die nicht zu Re-Renders f\u00fchren sollen - Vermeide unn\u00f6tige Dependencies</p>"},{"location":"analysis/performance-analysis-loading.html#4-cache-updates-nicht-optimal","title":"4. Cache-Updates nicht optimal","text":"<p>Problem: - <code>loadItems</code> aktualisiert Cache nur wenn <code>currentFolderId !== 'root'</code> - <code>navigateToFolder</code> aktualisiert Cache separat - Cache wird nicht f\u00fcr Root-Items verwendet</p> <p>L\u00f6sung: - Einheitliche Cache-Strategie f\u00fcr alle Ordner (inkl. Root) - Cache-Update atomar mit State-Update kombinieren - Cache-Invalidierung nur bei Bedarf</p>"},{"location":"analysis/performance-analysis-loading.html#5-url-updates-fuhren-zu-re-renders","title":"5. URL-Updates f\u00fchren zu Re-Renders","text":"<p>Problem: - <code>navigateToFolder</code> ruft <code>router.replace</code> auf - <code>useSearchParams</code> wird neu evaluiert - Kann zu mehrfachen Re-Renders f\u00fchren</p> <p>L\u00f6sung: - URL-Update debouncen - <code>useSearchParams</code> nur dort verwenden, wo n\u00f6tig - Memoization f\u00fcr abgeleitete Werte</p>"},{"location":"analysis/performance-analysis-loading.html#6-filetree-auto-expand-ladt-unnotig","title":"6. FileTree Auto-Expand l\u00e4dt unn\u00f6tig","text":"<p>Problem: - FileTree l\u00e4dt Ordner-Inhalte beim Auto-Expand (Zeile 439-534) - L\u00e4dt auch Ordner, die bereits im Cache sind - Kann zu zus\u00e4tzlichen API-Calls f\u00fchren</p> <p>L\u00f6sung: - Cache-Check vor dem Laden - Verwende <code>folderCache</code> statt <code>listItemsById</code> - Lazy Loading: Nur sichtbare Ordner laden</p>"},{"location":"analysis/performance-analysis-loading.html#7-breadcrumb-pfad-berechnung","title":"7. Breadcrumb-Pfad-Berechnung","text":"<p>Problem: - <code>currentPathAtom</code> wird bei jedem <code>folderCache</code>-Update neu berechnet - Kann bei vielen Cache-Updates zu Performance-Problemen f\u00fchren</p> <p>L\u00f6sung: - Memoization f\u00fcr Pfad-Berechnung - Nur bei relevanten Cache-Updates neu berechnen</p>"},{"location":"analysis/performance-analysis-loading.html#empfohlene-optimierungen","title":"Empfohlene Optimierungen","text":""},{"location":"analysis/performance-analysis-loading.html#prioritat-1-hochste-impact","title":"Priorit\u00e4t 1 (H\u00f6chste Impact)","text":"<ol> <li>Shadow-Twin-Analyse optimieren:</li> <li>Debouncing (300ms)</li> <li>Lazy Loading (erst nach 500ms)</li> <li> <p>Nur neue/ge\u00e4nderte Dateien analysieren</p> </li> <li> <p>Cache-Strategie vereinheitlichen:</p> </li> <li>Root-Items auch cachen</li> <li>Cache-Check vor jedem API-Call</li> <li> <p>Atomare Cache-Updates</p> </li> <li> <p>Redundante API-Calls eliminieren:</p> </li> <li><code>getPathItemsById</code> sollte Zielordner enthalten</li> <li>FileTree sollte Cache verwenden statt API-Calls</li> </ol>"},{"location":"analysis/performance-analysis-loading.html#prioritat-2-mittlere-impact","title":"Priorit\u00e4t 2 (Mittlere Impact)","text":"<ol> <li>useEffect-Konsolidierung:</li> <li>Weniger useEffects mit mehr Logik</li> <li> <p>Refs f\u00fcr nicht-reaktive Werte</p> </li> <li> <p>URL-Update optimieren:</p> </li> <li>Debouncing f\u00fcr URL-Updates</li> <li>Memoization f\u00fcr <code>useSearchParams</code></li> </ol>"},{"location":"analysis/performance-analysis-loading.html#prioritat-3-niedrige-impact","title":"Priorit\u00e4t 3 (Niedrige Impact)","text":"<ol> <li>Breadcrumb-Optimierung:</li> <li> <p>Memoization f\u00fcr Pfad-Berechnung</p> </li> <li> <p>FileTree Lazy Loading:</p> </li> <li>Nur sichtbare Ordner laden</li> </ol>"},{"location":"analysis/performance-analysis-loading.html#messungen","title":"Messungen","text":""},{"location":"analysis/performance-analysis-loading.html#aktuelle-performance-geschatzt","title":"Aktuelle Performance (gesch\u00e4tzt)","text":"<ul> <li>Verzeichniswechsel: ~500-1000ms</li> <li>Navigation: ~100ms</li> <li>API-Calls: ~200-400ms</li> <li>Shadow-Twin-Analyse: ~200-500ms</li> <li>Re-Renders: ~100-200ms</li> </ul>"},{"location":"analysis/performance-analysis-loading.html#ziel-performance","title":"Ziel-Performance","text":"<ul> <li>Verzeichniswechsel: ~100-200ms</li> <li>Navigation: ~50ms</li> <li>API-Calls: ~50-100ms (mit Cache)</li> <li>Shadow-Twin-Analyse: ~50-100ms (lazy, debounced)</li> <li>Re-Renders: ~50ms</li> </ul>"},{"location":"analysis/performance-analysis-loading.html#implementierte-optimierungen","title":"Implementierte Optimierungen","text":""},{"location":"analysis/performance-analysis-loading.html#1-shadow-twin-analyse-optimiert-prioritat-1","title":"\u2705 1. Shadow-Twin-Analyse optimiert (Priorit\u00e4t 1)","text":"<p>\u00c4nderungen: - Lazy Loading: 500ms Delay bevor die Analyse startet - Debouncing: Verhindert unn\u00f6tige Analysen bei schnellen Ordnerwechseln - Cleanup: Timeout wird bei Unmount gecancelt</p> <p>Datei: <code>src/hooks/use-shadow-twin-analysis.ts</code></p> <p>Impact:  - Verhindert sofortige Analysen bei schnellen Ordnerwechseln - Reduziert API-Calls um ~50-80% bei schneller Navigation - Verbessert wahrgenommene Performance deutlich</p>"},{"location":"analysis/performance-analysis-loading.html#2-cache-strategie-vereinheitlicht-prioritat-1","title":"\u2705 2. Cache-Strategie vereinheitlicht (Priorit\u00e4t 1)","text":"<p>\u00c4nderungen: - Root-Items werden jetzt auch gecacht - Cache-Update f\u00fcr alle Ordner (inkl. Root) - Einheitliche Cache-Strategie</p> <p>Datei: <code>src/components/library/library.tsx</code></p> <p>Impact: - FileTree kann Root-Items aus Cache laden - Reduziert redundante API-Calls f\u00fcr Root-Items - Konsistente Cache-Verwendung</p>"},{"location":"analysis/performance-analysis-loading.html#3-filetree-auto-expand-optimiert-prioritat-2","title":"\u2705 3. FileTree Auto-Expand optimiert (Priorit\u00e4t 2)","text":"<p>\u00c4nderungen: - Cache-Check vor API-Call - Verwendet <code>folderCache</code> statt <code>listItemsById</code> wenn m\u00f6glich - Reduziert API-Calls beim Auto-Expand</p> <p>Datei: <code>src/components/library/file-tree.tsx</code></p> <p>Impact: - Eliminiert redundante API-Calls beim Auto-Expand - Schnellere Pfad-Erweiterung</p>"},{"location":"analysis/performance-analysis-loading.html#4-file-status-debouncing-implementiert-prioritat-2","title":"\u2705 4. File-Status Debouncing implementiert (Priorit\u00e4t 2)","text":"<p>\u00c4nderungen: - 200ms Debounce f\u00fcr file-status Requests in FileRow - Verhindert viele Requests beim schnellen Scrollen oder Rendern - Cleanup bei Unmount</p> <p>Datei: <code>src/components/library/file-list.tsx</code></p> <p>Impact: - Reduziert file-status Requests um ~70-90% bei schnellem Scrollen - Verbessert Netzwerk-Performance - Reduziert Server-Last</p>"},{"location":"analysis/performance-analysis-loading.html#5-request-deduplizierung-verbessert-prioritat-1","title":"\u2705 5. Request-Deduplizierung verbessert (Priorit\u00e4t 1)","text":"<p>\u00c4nderungen: - FileTree verwendet jetzt <code>listItems</code> statt <code>provider.listItemsById</code> - Alle FileTree-Calls gehen durch Deduplizierung - Cache-Check vor API-Calls in FileTree</p> <p>Dateien:  - <code>src/components/library/file-tree.tsx</code> - <code>src/lib/storage/request-deduplicator.ts</code></p> <p>Impact: - Eliminiert doppelte API-Calls f\u00fcr denselben Ordner - Konsistente Request-Deduplizierung \u00fcber alle Komponenten</p>"},{"location":"analysis/performance-analysis-loading.html#6-getpathitemsbyid-optimiert-prioritat-1","title":"\u2705 6. getPathItemsById optimiert (Priorit\u00e4t 1)","text":"<p>\u00c4nderungen: - Zielordner wird jetzt direkt in <code>getPathItemsById</code> zur\u00fcckgegeben - Eliminiert zus\u00e4tzlichen <code>getItemById</code>-Call in <code>useFolderNavigation</code> - Implementiert f\u00fcr alle Provider (filesystem-provider, storage-factory, storage-factory-mongodb, filesystem-client)</p> <p>Dateien: - <code>src/lib/storage/filesystem-provider.ts</code> - <code>src/lib/storage/storage-factory.ts</code> - <code>src/lib/storage/storage-factory-mongodb.ts</code> - <code>src/lib/storage/filesystem-client.ts</code> - <code>src/hooks/use-folder-navigation.ts</code></p> <p>Impact: - Reduziert API-Calls beim Verzeichniswechsel von 3 auf 2 - Schnellere Navigation - Konsistentes Verhalten \u00fcber alle Provider</p>"},{"location":"analysis/performance-analysis-loading.html#7-shadow-twin-analyse-timeout-korrigiert-prioritat-1","title":"\u2705 7. Shadow-Twin-Analyse Timeout korrigiert (Priorit\u00e4t 1)","text":"<p>\u00c4nderungen: - <code>itemsToAnalyze</code> wird jetzt innerhalb des Timeouts berechnet - Verwendet aktuelle Items statt stale Closure-Werte - Verhindert Analysen mit veralteten Item-Listen</p> <p>Datei: <code>src/hooks/use-shadow-twin-analysis.ts</code></p> <p>Impact: - Korrekte Analyse auch bei schnellen Ordnerwechseln - Verhindert Analysen mit falschen Items - Verbessert Datenqualit\u00e4t</p>"},{"location":"analysis/performance-analysis-loading.html#8-race-condition-bei-loaditems-behoben-prioritat-1","title":"\u2705 8. Race-Condition bei loadItems behoben (Priorit\u00e4t 1)","text":"<p>\u00c4nderungen: - <code>setLastLoadedFolder</code> wird jetzt optimistisch gesetzt, bevor der API-Call gemacht wird - Verhindert, dass <code>loadItems</code> zweimal aufgerufen wird - Bei Context-Change wird <code>lastLoadedFolder</code> zur\u00fcckgesetzt</p> <p>Datei: <code>src/components/library/library.tsx</code></p> <p>Impact: - Eliminiert doppelte Zielordner-Requests - Reduziert API-Calls um ~50% bei Navigation</p>"},{"location":"analysis/performance-analysis-loading.html#9-root-items-fur-pfadaufbau-optimiert-prioritat-1","title":"\u2705 9. Root-Items f\u00fcr Pfadaufbau optimiert (Priorit\u00e4t 1)","text":"<p>\u00c4nderungen: - <code>useFolderNavigation</code> baut den Pfad jetzt manuell auf - Verwendet <code>listItems</code> (dedupliziert) statt <code>getPathItemsById</code> - Pr\u00fcft Cache f\u00fcr Root-Items und Ordner im Pfad vor API-Calls</p> <p>Datei: <code>src/hooks/use-folder-navigation.ts</code></p> <p>Impact: - Eliminiert doppelte Root-Requests - Reduziert API-Calls um ~33% bei Navigation - Nutzt Cache effizienter</p>"},{"location":"analysis/performance-analysis-loading.html#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ol> <li>\u2705 Shadow-Twin-Analyse optimieren (Debouncing + Lazy Loading) - FERTIG</li> <li>\u2705 Cache-Strategie vereinheitlichen - FERTIG</li> <li>\u2705 Redundante API-Calls eliminieren: <code>getPathItemsById</code> gibt jetzt Zielordner zur\u00fcck - FERTIG</li> <li>\u2705 File-Status Debouncing implementiert - FERTIG</li> <li>\u2705 Request-Deduplizierung verbessert - FERTIG</li> <li>\u2705 Race-Condition bei loadItems behoben - FERTIG</li> <li>\u2705 Root-Items f\u00fcr Pfadaufbau optimiert - FERTIG</li> <li>\u23f3 Performance messen und validieren</li> <li>\u23f3 Metadaten-Cache implementieren (optional, niedrige Priorit\u00e4t)</li> </ol>"},{"location":"analysis/pipeline-sheet-autoopen-loop.html","title":"Pipeline sheet autoopen loop","text":""},{"location":"analysis/pipeline-sheet-autoopen-loop.html#problem","title":"Problem","text":"<p>Im Flow View \u00f6ffnet sich das Panel \u201eAufbereiten &amp; Publizieren\u201c automatisch, wenn keine Shadow\u2011Twin Artefakte vorhanden sind. Wenn der Nutzer den Dialog schlie\u00dft, geht er sofort wieder auf.</p>"},{"location":"analysis/pipeline-sheet-autoopen-loop.html#beobachtung-root-cause","title":"Beobachtung (Root Cause)","text":"<p>Die Auto\u2011Open\u2011Logik h\u00e4ngt aktuell an <code>shouldPromptPipeline</code>. Solange keine Artefakte existieren, bleibt dieses Flag <code>true</code>. Beim Schlie\u00dfen setzt die UI <code>pipeline=0</code> (oder vorher implizit \u201eclosed\u201c), der Effekt erkennt \u201enicht offen\u201c und \u00f6ffnet erneut.</p>"},{"location":"analysis/pipeline-sheet-autoopen-loop.html#losungskandidaten","title":"L\u00f6sungskandidaten","text":""},{"location":"analysis/pipeline-sheet-autoopen-loop.html#variante-a-url-param-als-zustandsmaschine","title":"Variante A (URL-Param als Zustandsmaschine)","text":"<ul> <li>Verwende drei Zust\u00e4nde \u00fcber <code>pipeline</code>:</li> <li><code>''</code> (nicht gesetzt) = Initialzustand \u2192 Auto\u2011Open darf greifen</li> <li><code>'1'</code> = offen</li> <li><code>'0'</code> = vom Nutzer geschlossen \u2192 Auto\u2011Open darf nicht mehr greifen</li> <li>Vorteil: Deep-Linking bleibt m\u00f6glich, Verhalten ist deterministisch.</li> <li>Nachteil: Minimal mehr Zustandslogik im URL\u2011Param.</li> </ul>"},{"location":"analysis/pipeline-sheet-autoopen-loop.html#variante-b-lokales-dismissed-flag","title":"Variante B (lokales \u201edismissed\u201c Flag)","text":"<ul> <li>Lokalen State/Ref <code>hasDismissedAutoOpen</code> setzen, wenn User schlie\u00dft.</li> <li>Vorteil: URL bleibt sauber.</li> <li>Nachteil: State geht bei Refresh verloren und ist schlechter debugbar.</li> </ul>"},{"location":"analysis/pipeline-sheet-autoopen-loop.html#variante-c-sessionstorage-persistenz","title":"Variante C (SessionStorage Persistenz)","text":"<ul> <li><code>dismissed</code> in <code>sessionStorage</code> speichern, solange Tab offen ist.</li> <li>Vorteil: wirkt \u201estabil\u201c \u00fcber Navigation innerhalb der App.</li> <li>Nachteil: mehr IO/Edge Cases; URL bleibt uneindeutig.</li> </ul>"},{"location":"analysis/pipeline-sheet-autoopen-loop.html#entscheidung","title":"Entscheidung","text":"<p>Wir w\u00e4hlen Variante A, weil sie minimal-invasiv ist, keinen zus\u00e4tzlichen Persistenz-State braucht und gut debuggbar bleibt.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html","title":"Shadow-Twin: Deterministische Architektur","text":"<p>Status: Analyse abgeschlossen, Refactoring erforderlich Erstellt: 2026-01-29 Bezug: Coverbild-Upload-Fehler wegen fehlendem templateName</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#1-grundprinzip-ein-shadow-twin-ist-deterministisch","title":"1. Grundprinzip: Ein Shadow-Twin ist deterministisch","text":"<p>Ein Shadow-Twin ist KEIN optionales Konstrukt. Es hat deterministische Parameter, ohne die es nicht funktionieren kann.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#artifactkey-die-pflichtparameter","title":"ArtifactKey - Die Pflichtparameter","text":"<pre><code>interface ArtifactKey {\n  sourceId: string;         // PFLICHT - ID der Quelldatei\n  kind: ArtifactKind;       // PFLICHT - 'transcript' | 'transformation' | 'canonical' | 'raw'\n  targetLanguage: string;   // PFLICHT - z.B. 'de', 'en'\n  templateName?: string;    // PFLICHT f\u00fcr 'transformation', undefined f\u00fcr andere\n}\n</code></pre>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#regel-templatename-ist-fur-transformationen-pflicht","title":"Regel: templateName ist f\u00fcr Transformationen PFLICHT","text":"kind templateName Beispiel-Dateiname <code>transcript</code> MUSS <code>undefined</code> sein <code>document.de.md</code> <code>transformation</code> MUSS gesetzt sein <code>document.klimamassnahme-detail-de.de.md</code> <code>canonical</code> MUSS <code>undefined</code> sein <code>document.canonical.de.md</code> <code>raw</code> MUSS <code>undefined</code> sein <code>document.raw.html</code> <p>Ein Shadow-Twin mit <code>kind='transformation'</code> ohne <code>templateName</code> ist UNG\u00dcLTIG und darf nicht existieren.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#2-identifizierte-fallback-losungen-problematisch","title":"2. Identifizierte Fallback-L\u00f6sungen (PROBLEMATISCH)","text":""},{"location":"analysis/shadow-twin-deterministic-architecture.html#21-mongoshadowtwinstore-wahle-beste-transformation","title":"2.1 MongoShadowTwinStore - \"W\u00e4hle beste Transformation\"","text":"<p>Datei: <code>src/lib/shadow-twin/store/mongo-shadow-twin-store.ts</code></p> <pre><code>// Zeile 39 und 60:\nif (key.kind === 'transformation' &amp;&amp; (!key.templateName || key.templateName.trim().length === 0)) {\n  // PROBLEMATISCH: Sucht \"irgendeine\" Transformation\n  const selected = selectShadowTwinArtifact(doc, 'transformation', key.targetLanguage)\n}\n</code></pre> <p>Problem: Nicht-deterministisches Verhalten. \"Beste\" = neueste, aber das kann sich \u00e4ndern.</p> <p>Empfehlung: Fehler werfen statt raten.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#22-shadowtwinservice-templatename-aus-frontmatterid","title":"2.2 ShadowTwinService - templateName aus Frontmatter/ID","text":"<p>Datei: <code>src/lib/shadow-twin/store/shadow-twin-service.ts</code></p> <pre><code>// Zeile 626-648:\nif (!templateName &amp;&amp; kind === 'transformation') {\n  // Versuche aus Frontmatter zu extrahieren\n  if (existing.frontmatter?.template_used) {\n    templateName = String(existing.frontmatter.template_used)\n  } else if (isMongoShadowTwinId(existing.id)) {\n    // Fallback: Aus der ID extrahieren\n    const parsed = parseMongoShadowTwinId(existing.id)\n    templateName = parsed?.templateName\n  }\n}\n</code></pre> <p>Problem: Das ist eine Rettungsaktion f\u00fcr fehlerhafte Aufrufe. Der Caller sollte templateName kennen.</p> <p>Empfehlung: Caller muss templateName liefern, sonst Fehler.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#23-artifact-resolver-template-agnostische-auflosung","title":"2.3 Artifact Resolver - Template-agnostische Aufl\u00f6sung","text":"<p>Datei: <code>src/lib/shadow-twin/artifact-resolver.ts</code></p> <pre><code>// Zeile 137-141:\n/**\n * Template-agnostische Aufl\u00f6sung:\n * wenn kind === 'transformation' und templateName fehlt, w\u00e4hlen wir die \"beste\"\n */\nfunction pickBestTransformation(items: StorageItem[]): StorageItem | null {\n  // Sortiert nach modifiedAt, nimmt neueste\n}\n</code></pre> <p>Problem: Nicht-deterministisch. Bei mehreren Templates wird \"irgendeine\" gew\u00e4hlt.</p> <p>Empfehlung: Explizit templateName erfordern oder alle Templates zur\u00fcckgeben.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#3-legitime-fallback-muster","title":"3. Legitime Fallback-Muster","text":"<p>Diese Fallbacks sind KORREKT und sollten beibehalten werden:</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#31-storage-fallback-mongodb-filesystem","title":"3.1 Storage-Fallback (MongoDB \u2192 Filesystem)","text":"<pre><code>// Primary: MongoDB\n// Fallback: Filesystem (f\u00fcr Migration/Kompatibilit\u00e4t)\nif (this.fallbackStore) {\n  const fallbackResult = await this.fallbackStore.getArtifactMarkdown(key)\n}\n</code></pre> <p>Legitim: Zwei verschiedene Storage-Backends, gleiche deterministische Keys.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#32-url-auflosung-azure-storage-api","title":"3.2 URL-Aufl\u00f6sung (Azure \u2192 Storage-API)","text":"<pre><code>// Bevorzugt: Azure Blob Storage URL\nif (fragment.url) return fragment.url\n// Fallback: Dateisystem-Referenz \u2192 Storage-API-URL\nif (fragment.fileId) return `/api/storage/filesystem?...`\n</code></pre> <p>Legitim: Abstrahiert Storage-Backend f\u00fcr UI.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#33-dateiname-parsing-defensive-programmierung","title":"3.3 Dateiname-Parsing (defensive Programmierung)","text":"<pre><code>// Fallback bei unbekanntem Pattern\nif (!targetLanguage &amp;&amp; fileName.endsWith('.md')) {\n  kind = 'transcript'\n}\n</code></pre> <p>Legitim: Legacy-Kompatibilit\u00e4t f\u00fcr existierende Dateien.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#4-woher-kommt-templatename","title":"4. Woher kommt templateName?","text":""},{"location":"analysis/shadow-twin-deterministic-architecture.html#41-bei-job-erstellung-external-jobs","title":"4.1 Bei Job-Erstellung (External Jobs)","text":"<pre><code>// src/app/api/external/jobs/[jobId]/start/route.ts\nconst templateEnabled = !!libraryConfig?.templateName\nconst templateName = libraryConfig?.templateName\n</code></pre> <p>templateName kommt aus Library-Konfiguration.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#42-bei-ui-anzeige-jobreporttab","title":"4.2 Bei UI-Anzeige (JobReportTab)","text":"<pre><code>// Aus Job-Metadaten:\nconst templateName = job?.cumulativeMeta?.template_used\n// Aus Frontmatter:\nconst templateName = frontmatterMeta?.template_used\n</code></pre> <p>templateName wird im Frontmatter als <code>template_used</code> gespeichert.</p>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#43-bei-shadow-twin-state","title":"4.3 Bei Shadow-Twin-State","text":"<pre><code>// Aus shadowTwinState.transformed\n// Die ID enth\u00e4lt das templateName:\n// mongo-shadow-twin:libraryId::sourceId::transformation::de::klimamassnahme-detail-de\n</code></pre>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#5-handlungsempfehlungen","title":"5. Handlungsempfehlungen","text":""},{"location":"analysis/shadow-twin-deterministic-architecture.html#51-sofort-fehler-statt-fallback-in-patchartifactfrontmatter","title":"5.1 SOFORT: Fehler statt Fallback in patchArtifactFrontmatter","text":"<pre><code>// VORHER (aktuell):\nif (!templateName &amp;&amp; kind === 'transformation') {\n  // Versuche zu erraten...\n}\n\n// NACHHER (empfohlen):\nif (kind === 'transformation' &amp;&amp; !templateName) {\n  throw new Error(\n    `templateName ist erforderlich f\u00fcr Transformation. ` +\n    `Caller muss templateName explizit \u00fcbergeben.`\n  )\n}\n</code></pre>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#52-mittelfristig-ui-code-anpassen","title":"5.2 MITTELFRISTIG: UI-Code anpassen","text":"<p>Der Caller (UI) muss templateName aus verf\u00fcgbaren Quellen holen:</p> <pre><code>// In saveCoverImage():\nconst templateName = \n  frontmatterMeta?.template_used ||\n  job?.cumulativeMeta?.template_used ||\n  shadowTwinState?.transformed?.metadata?.templateName // falls verf\u00fcgbar\n\nif (!templateName) {\n  toast.error('Template-Name nicht verf\u00fcgbar. Bitte Seite neu laden.')\n  return\n}\n</code></pre>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#53-langfristig-selectshadowtwinartifact-refactoren","title":"5.3 LANGFRISTIG: selectShadowTwinArtifact() refactoren","text":"<pre><code>// VORHER:\nfunction selectShadowTwinArtifact(doc, kind, language) {\n  // W\u00e4hlt \"beste\" wenn templateName fehlt\n}\n\n// NACHHER (Option A - Strict):\nfunction getArtifactStrict(doc, kind, language, templateName) {\n  if (kind === 'transformation' &amp;&amp; !templateName) {\n    throw new Error('templateName required for transformation')\n  }\n  // Exakter Match\n}\n\n// NACHHER (Option B - List all):\nfunction listTransformations(doc, language): ArtifactRecord[] {\n  // Gibt ALLE Transformationen zur\u00fcck, Caller w\u00e4hlt\n}\n</code></pre>"},{"location":"analysis/shadow-twin-deterministic-architecture.html#6-dokumentation-status","title":"6. Dokumentation-Status","text":"Dokument Status Kommentar <code>shadow-twin-architecture.mdc</code> \u2705 G\u00dcLTIG Storage-Abstraktion korrekt <code>shadow-twin-v2-only.md</code> \u2705 G\u00dcLTIG v2-only Runtime korrekt <code>shadow-twin-source-selection.md</code> \u2705 G\u00dcLTIG Purpose-basierte Quellenwahl korrekt <code>shadow-twin-mongo-target-structure.md</code> \u2705 G\u00dcLTIG MongoDB-Struktur korrekt <code>shadow-twin-mongo-migration-plan.md</code> \u26a0\ufe0f VERALTET Migration gr\u00f6\u00dftenteils abgeschlossen"},{"location":"analysis/shadow-twin-deterministic-architecture.html#7-checkliste-fur-entwickler","title":"7. Checkliste f\u00fcr Entwickler","text":"<p>Vor jeder \u00c4nderung im Shadow-Twin-Bereich:</p> <ul> <li>[ ] Ist <code>templateName</code> f\u00fcr Transformationen IMMER gesetzt?</li> <li>[ ] Werfe ich einen Fehler wenn <code>templateName</code> fehlt (statt zu raten)?</li> <li>[ ] Kommt <code>templateName</code> aus einer verl\u00e4sslichen Quelle (nicht aus ID extrahiert)?</li> <li>[ ] Gibt es \"w\u00e4hle beste/neueste\" Logik? \u2192 Refactoren!</li> <li>[ ] Ist der Code deterministisch? (Gleiche Eingabe \u2192 Gleiches Ergebnis)</li> </ul>"},{"location":"analysis/shadow-twin-migration-logging.html","title":"Shadow\u2011Twin Migration: Zentrales Logging","text":""},{"location":"analysis/shadow-twin-migration-logging.html#einordnung","title":"Einordnung","text":"<p>Der Dry\u2011Run liefert bereits einen Report, aber er geht nach dem Dialog verloren. Fuer Debugging und Nachvollziehbarkeit brauchen wir einen zentralen Verlauf der letzten Migrationen (Dry\u2011Run und echte Runs).</p>"},{"location":"analysis/shadow-twin-migration-logging.html#varianten","title":"Varianten","text":""},{"location":"analysis/shadow-twin-migration-logging.html#variante-a-mongodbcollection-shadow_twin_migrations-empfohlen","title":"Variante A: MongoDB\u2011Collection <code>shadow_twin_migrations</code> (empfohlen)","text":"<p>Beschreibung: Jeder Run wird als Dokument gespeichert (Start, Ende, Status, Report). Vorteile: Zentral, langlebig, leicht filterbar pro Library. Risiken: Zusaetzliche Collection, muss gepflegt werden.</p>"},{"location":"analysis/shadow-twin-migration-logging.html#variante-b-fileloggeronly","title":"Variante B: FileLogger\u2011Only","text":"<p>Beschreibung: Nur Logs in Datei/Console. Vorteile: Keine DB\u2011Aenderung. Risiken: Nicht strukturiert, schwer auszuwerten, nicht zentral abrufbar.</p>"},{"location":"analysis/shadow-twin-migration-logging.html#variante-c-events-im-jobsystem","title":"Variante C: Events im Job\u2011System","text":"<p>Beschreibung: Migration als Job modellieren und Events im Job\u2011Repo speichern. Vorteile: Einheitlicher Flow. Risiken: Mehr Aufwand, zusaetzliche Architektur.</p>"},{"location":"analysis/shadow-twin-migration-logging.html#entscheidung","title":"Entscheidung","text":"<p>Variante A. Sie ist minimalinvasiv, zentral und strukturiert.</p>"},{"location":"analysis/shadow-twin-migration-logging.html#scope-minimal","title":"Scope (Minimal)","text":"<ul> <li>Repository: <code>shadow_twin_migrations</code> mit Start/Finish.</li> <li>Migration\u2011Route schreibt Run\u2011Dokument.</li> <li>Optionaler API\u2011Read fuer \u201eletzte Runs\u201c.</li> </ul>"},{"location":"analysis/shadow-twin-migration-ui-dry-run.html","title":"UI\u2011Button: Shadow\u2011Twin Migration (Dry\u2011Run)","text":""},{"location":"analysis/shadow-twin-migration-ui-dry-run.html#ausgangslage","title":"Ausgangslage","text":"<p>Wir wollen den Dry\u2011Run der Migration aus dem Frontend testen. Das soll in der Library\u2011Config sichtbar sein, ohne die produktive Migration aus Versehen auszul\u00f6sen. Der Dry\u2011Run ist ein Request\u2011Flag und geh\u00f6rt nicht in die Library\u2011Config.</p>"},{"location":"analysis/shadow-twin-migration-ui-dry-run.html#ziele","title":"Ziele","text":"<ul> <li>Dry\u2011Run mit minimalen Parametern starten (folderId, recursive, limit).</li> <li>Ergebnis/Report im UI sichtbar machen (Counts, Fehler).</li> <li>Optionaler echter Lauf bewusst getrennt (separate Aktion).</li> </ul>"},{"location":"analysis/shadow-twin-migration-ui-dry-run.html#varianten","title":"Varianten","text":""},{"location":"analysis/shadow-twin-migration-ui-dry-run.html#variante-a-button-dialog-in-libraryform-empfohlen","title":"Variante A: Button + Dialog in Library\u2011Form (empfohlen)","text":"<p>Beschreibung: In <code>LibraryForm</code> ein kleiner Block \u201eMigration testen\u201c, der einen Dialog mit <code>folderId</code>, <code>recursive</code>, <code>limit</code>, <code>cleanup</code> \u00f6ffnet und den Dry\u2011Run ausf\u00fchrt. Vorteile: Schnell, keine neue Seite, klare N\u00e4he zur Konfiguration. Risiken: UI\u2011Form wird gr\u00f6\u00dfer; muss gut abgesichert werden (Default = dryRun).</p>"},{"location":"analysis/shadow-twin-migration-ui-dry-run.html#variante-b-dedizierte-debugseite","title":"Variante B: Dedizierte Debug\u2011Seite","text":"<p>Beschreibung: Neue Seite unter <code>/library/:id/debug</code> mit Formular &amp; Report. Vorteile: Sauber getrennt, skalierbar f\u00fcr weitere Debug\u2011Tools. Risiken: Mehr Routing/Access\u2011Logik, gr\u00f6\u00dferer Aufwand.</p>"},{"location":"analysis/shadow-twin-migration-ui-dry-run.html#variante-c-devonly-console-helper","title":"Variante C: Dev\u2011Only Console Helper","text":"<p>Beschreibung: Nur in Dev ein kleiner Button, der vordefiniert <code>dryRun=true</code> triggert (ohne Dialog). Vorteile: Minimaler Code, schnell. Risiken: Keine Parametrisierung, wenig Feedback, schwer nachvollziehbar.</p>"},{"location":"analysis/shadow-twin-migration-ui-dry-run.html#entscheidung","title":"Entscheidung","text":"<p>Wir w\u00e4hlen Variante A, weil sie schnell implementierbar ist, klare Parameter erlaubt und keine zus\u00e4tzlichen Routen braucht.</p>"},{"location":"analysis/shadow-twin-migration-ui-dry-run.html#offene-punkte","title":"Offene Punkte","text":"<ul> <li><code>folderId</code> muss manuell kopiert werden (z.\u202fB. aus URL oder Storage\u2011UI).</li> <li>Report\u2011Darstellung: zuerst Roh\u2011JSON, sp\u00e4ter strukturierter.</li> </ul>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html","title":"Shadow-Twin: MongoDB-Planung und Migration (Batch)","text":""},{"location":"analysis/shadow-twin-mongo-migration-plan.html#einordnung-und-ziel","title":"Einordnung und Ziel","text":"<p>Wir sehen aktuell klare Performance-Engp\u00e4sse beim Dateisystem-Scan und bei der Shadow\u2011Twin\u2011Aufl\u00f6sung. Die Idee, Shadow\u2011Twins prim\u00e4r in MongoDB zu speichern und das Filesystem optional zu machen, ist sinnvoll. Dadurch wird das \u00d6ffnen eines Ordners zu einem reinen Datenbankzugriff, der gut batchbar ist. Das reduziert Latenzen und entkoppelt UI\u2011Performance von Filesystem\u2011I/O.</p> <p>Wichtig ist, dass wir die neue Speicherung deterministisch und konsistent gestalten. Ein Dokument pro <code>sourceId</code> (Original\u2011File) ist in der Praxis am einfachsten. Es h\u00e4lt alle Varianten (Transcript/Transformation) und referenziert bin\u00e4re Artefakte \u00fcber Blob\u2011URLs. F\u00fcr Sharing bleibt ein optionaler Filesystem\u2011Write erhalten, der bewusst deaktivierbar ist.</p> <p>Die Migration soll als Batch gedacht werden: gezielte Libraries werden einmalig importiert. Danach wird das System in einen Dual\u2011Read\u2011Modus gebracht (Mongo bevorzugt, Filesystem fallback). So bleibt der Betrieb stabil, w\u00e4hrend wir schrittweise umstellen.</p>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#zielbild-zustand-nach-migration","title":"Zielbild (Zustand nach Migration)","text":"<ul> <li>Shadow\u2011Twin\u2011Artefakte prim\u00e4r in MongoDB gespeichert.</li> <li>Filesystem\u2011Speicherung optional pro Library (z.\u202fB. <code>shadowTwin.persistToFilesystem</code>).</li> <li>UI l\u00e4dt Shadow\u2011Twins eines Ordners als Batch aus MongoDB.</li> <li>Filesystem\u2011Scan ist optional und nur f\u00fcr Legacy/Sharing notwendig.</li> </ul>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#vorschlag-datenmodell-mongodb","title":"Vorschlag Datenmodell (MongoDB)","text":"<p>Ein Dokument pro Quelle (<code>sourceId</code>). Einbettung der Fragmente in einem Dokument reduziert Query\u2011Overhead.</p> <pre><code>{\n  \"_id\": \"&lt;ObjectId&gt;\",\n  \"libraryId\": \"ff73d3a2-...\",\n  \"sourceId\": \"fileId-original\",\n  \"sourceName\": \"document.pdf\",\n  \"parentId\": \"folderId\",\n  \"userEmail\": \"user@example.com\",\n  \"artifacts\": {\n    \"transcript\": {\n      \"de\": {\n        \"markdown\": \"&lt;md&gt;\",\n        \"createdAt\": \"2026-01-22T12:00:00Z\",\n        \"updatedAt\": \"2026-01-22T12:05:00Z\"\n      }\n    },\n    \"transformation\": {\n      \"templateName\": {\n        \"de\": {\n          \"markdown\": \"&lt;md&gt;\",\n          \"frontmatter\": { \"docType\": \"event\", \"title\": \"...\" },\n          \"createdAt\": \"2026-01-22T12:10:00Z\",\n          \"updatedAt\": \"2026-01-22T12:11:00Z\"\n        }\n      }\n    }\n  },\n  \"binaryFragments\": [\n    {\n      \"name\": \"page-001.png\",\n      \"kind\": \"image\",\n      \"url\": \"https://&lt;azure&gt;/.../page-001.png\",\n      \"hash\": \"abcdef123456\",\n      \"mimeType\": \"image/png\",\n      \"size\": 123456,\n      \"createdAt\": \"2026-01-22T12:12:00Z\"\n    }\n  ],\n  \"filesystemSync\": {\n    \"enabled\": false,\n    \"shadowTwinFolderId\": null,\n    \"lastSyncedAt\": null\n  },\n  \"createdAt\": \"2026-01-22T12:00:00Z\",\n  \"updatedAt\": \"2026-01-22T12:11:00Z\"\n}\n</code></pre> <p>Collection\u2011Namen: <code>shadow_twins__${libraryId}</code> (analog zu <code>vectors__${libraryId}</code>)</p> <p>Indizes (Minimum): - <code>{ libraryId: 1, parentId: 1 }</code> f\u00fcr Ordner\u2011Batch\u2011Loading - <code>{ libraryId: 1, sourceId: 1 }</code> unique - <code>{ libraryId: 1, \"artifacts.transformation.*.*.updatedAt\": -1 }</code> optional, falls \u201clatest transformation\u201d ben\u00f6tigt wird</p>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#batchmigration-theoretischer-ablauf","title":"Batch\u2011Migration (theoretischer Ablauf)","text":"<ol> <li>Scope bestimmen: Welche Libraries migriert werden (Batch\u2011Auswahl).</li> <li>Scan Quelle: F\u00fcr jede Library: Ordnerinhalt einmalig laden, Shadow\u2011Twin\u2011Ordner/Dateien aufl\u00f6sen.</li> <li>Parse Artefakte: Transcript/Transformation anhand der bekannten Namenskonventionen erkennen.</li> <li>Persistieren: Ein Dokument pro <code>sourceId</code> upserten.</li> <li>Binary\u2011Assets: Bilder in Azure, URLs in Mongo speichern (vorhandene Upload\u2011Logik nutzen).</li> <li>Dual\u2011Read aktivieren: UI/Resolver liest prim\u00e4r aus Mongo; Filesystem fallback.</li> <li>Write\u2011Pfad \u00e4ndern: Neue Shadow\u2011Twins zuerst in Mongo speichern; Filesystem optional.</li> <li>Validieren: Stichproben, Counts, Checksummen (z.\u202fB. Anzahl Artefakte je Quelle).</li> </ol>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#strategie-variante-a-libraryweit","title":"Strategie (Variante A: Library\u2011weit)","text":"<p>Diese Variante setzt auf einen klaren Library\u2011Modus, damit Verhalten deterministisch bleibt: - <code>shadowTwin.primaryStore = \"mongo\"</code> - <code>shadowTwin.persistToFilesystem = false</code> (Default)</p>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#featureflags-librarykonfiguration","title":"Feature\u2011Flags (Library\u2011Konfiguration)","text":"<p>Empfohlene Flags f\u00fcr eine kontrollierte Umstellung: - <code>shadowTwin.primaryStore: \"mongo\" | \"filesystem\"</code>   Legt fest, aus welcher Quelle prim\u00e4r gelesen wird. - <code>shadowTwin.persistToFilesystem: boolean</code>   Steuert, ob Shadow\u2011Twins zus\u00e4tzlich ins Filesystem geschrieben werden. - <code>shadowTwin.cleanupFilesystemOnMigrate: boolean</code>   L\u00f6scht Shadow\u2011Twins aus dem Filesystem, nachdem sie erfolgreich in MongoDB persistiert wurden. - <code>shadowTwin.allowFilesystemFallback: boolean</code>   Erlaubt Legacy\u2011Fallback, falls MongoDB\u2011Eintrag fehlt.</p>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#konkrete-feldnamen-srctypeslibraryts","title":"Konkrete Feldnamen (src/types/library.ts)","text":"<p>Die Feature\u2011Flags sind als Felder unter <code>Library.config.shadowTwin</code> vorgesehen: - <code>config.shadowTwin.mode?: \"legacy\" | \"v2\"</code> - <code>config.shadowTwin.primaryStore?: \"filesystem\" | \"mongo\"</code> - <code>config.shadowTwin.persistToFilesystem?: boolean</code> - <code>config.shadowTwin.cleanupFilesystemOnMigrate?: boolean</code> - <code>config.shadowTwin.allowFilesystemFallback?: boolean</code></p> <p>Default\u2011Logik (effektiv): - <code>primaryStore = \"filesystem\"</code> (wenn nicht gesetzt) - <code>persistToFilesystem = true</code> wenn <code>primaryStore = \"filesystem\"</code>, sonst <code>false</code> - <code>cleanupFilesystemOnMigrate = false</code> - <code>allowFilesystemFallback = true</code></p> <p>Ablauf (Migration): 1. MongoDB als prim\u00e4ren Store aktivieren. 2. Shadow\u2011Twins in MongoDB schreiben (inkl. Azure\u2011URLs f\u00fcr Binary Assets). 3. Filesystem\u2011Shadow\u2011Twins nach erfolgreicher Persistierung l\u00f6schen. 4. UI liest ab sofort aus Mongo (Filesystem nur fallback).</p> <p>Ablauf (Sharing): 1. <code>persistToFilesystem = true</code> setzen. 2. Batch\u2011Job schreibt alle Mongo\u2011Shadow\u2011Twins ins Filesystem (Original\u2011Layout). 3. Optional: bei <code>persistToFilesystem = false</code> wieder bereinigen.</p>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#tests-validierung-der-umstellung","title":"Tests (Validierung der Umstellung)","text":"<ol> <li>Zielzustand nach Migration </li> <li>Keine Shadow\u2011Twin\u2011Dateien im Filesystem  </li> <li>Mongo enth\u00e4lt vollst\u00e4ndige Artefakte  </li> <li> <p>UI l\u00e4dt Shadow\u2011Twins ohne Filesystem\u2011Scan</p> </li> <li> <p>Round\u2011trip Test (Sharing an/aus) </p> </li> <li><code>persistToFilesystem = true</code> \u21d2 Filesystem\u2011Artefakte vorhanden  </li> <li><code>persistToFilesystem = false</code> \u21d2 Filesystem wieder bereinigt  </li> <li> <p>Dateinamen und Markdown\u2011Inhalte stimmen deterministisch \u00fcberein</p> </li> <li> <p>Binary\u2011Assets </p> </li> <li>URLs entsprechen exakt der bestehenden Azure\u2011Logik  </li> <li>Keine doppelten Uploads bei wiederholter Migration</li> </ol>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#migrationscheckliste-prerun-run-postrun","title":"Migrations\u2011Checkliste (Pre\u2011Run / Run / Post\u2011Run)","text":"<p>Pre\u2011Run - Library\u2011Scope fixiert (IDs, Anzahl Quellen, Umfang) - Backup / Snapshot der betroffenen Shadow\u2011Twin\u2011Ordner - Feature\u2011Flags gesetzt (Planwerte dokumentiert) - Test\u2011Library f\u00fcr Dry\u2011Run definiert</p> <p>Run - Batch\u2011Import gestartet (Logging aktiv) - Azure\u2011Upload aktiv (Bild\u2011URLs werden ersetzt) - Mongo\u2011Upserts erfolgreich (Counts validieren) - Optional: Filesystem\u2011Cleanup nach erfolgreichem Upsert</p> <p>Post\u2011Run - Stichprobe: Artefakte aus Mongo lesen - UI\u2011Smoke\u2011Test: Ordner \u00f6ffnen, Icons sichtbar - Round\u2011trip (Sharing an/aus) f\u00fcr Stichprobe - Report archivieren (Counts, Fehler, Differenzen)</p>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#testprotokolltemplate-minimal","title":"Testprotokoll\u2011Template (Minimal)","text":"<p>Ziel: Round\u2011trip Validierung (Mongo \u2194 Filesystem)</p> <p>Setup - Library ID: - Datum: - Tester: - Flags: <code>primaryStore=</code>, <code>persistToFilesystem=</code>, <code>cleanupFilesystemOnMigrate=</code></p> <p>Durchlauf - Schritt 1: Migration gestartet (Zeit: ) - Schritt 2: Mongo\u2011Count gepr\u00fcft (Anzahl Artefakte: ) - Schritt 3: Filesystem\u2011Cleanup gepr\u00fcft (Anzahl Shadow\u2011Twins: ) - Schritt 4: Sharing aktiviert (persistToFilesystem=true) - Schritt 5: Round\u2011trip Vergleich (Dateiname/Frontmatter/Body/URLs)</p> <p>Ergebnis - Bestanden: Ja/Nein - Abweichungen (falls vorhanden): - Notizen:</p>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#roundtripcheckliste-vergleichskriterien","title":"Round\u2011trip\u2011Checkliste (Vergleichskriterien)","text":"<p>Damit der Test aussagekr\u00e4ftig ist, m\u00fcssen die Artefakte deterministisch gleich sein: - Dateiname exakt gleich (inkl. Template\u2011Name und Sprachsuffix) - Frontmatter\u2011Felder identisch (Key\u2011Order egal, Werte gleich) - Markdown\u2011Body identisch (Zeilenumbr\u00fcche normalisieren) - Asset\u2011URLs identisch (Azure\u2011Pfad + Hash) - Transkript/Transformation korrekt zugeordnet</p>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#risiken-und-gegenmanahmen","title":"Risiken und Gegenma\u00dfnahmen","text":"<ol> <li>Dateninkonsistenz (Mongo vs Filesystem) </li> <li>Risiko: Unterschiedliche St\u00e4nde nach Migration.  </li> <li> <p>Gegenma\u00dfnahme: Dual\u2011Read\u2011Phase + Vergleichslogik, Migrationsreport mit Differenzen.</p> </li> <li> <p>Gro\u00dfe Dokumente (Mongo 16MB Limit) </p> </li> <li>Risiko: Sehr gro\u00dfe Markdown\u2011Artefakte + viele Fragmente.  </li> <li> <p>Gegenma\u00dfnahme: Gro\u00dfe Markdown\u2011Bodies optional in Blob\u2011Storage, Mongo nur Referenzen.</p> </li> <li> <p>Fehlende Template\u2011Zuordnung </p> </li> <li>Risiko: Transformationen ohne Template\u2011Namen.  </li> <li> <p>Gegenma\u00dfnahme: Heuristik \u201eneueste Transformation\u201c + Flag <code>templateName: \"unknown\"</code>.</p> </li> <li> <p>Binary\u2011Assets im Filesystem </p> </li> <li>Risiko: Bilder sind noch nicht in Azure.  </li> <li> <p>Gegenma\u00dfnahme: Migration enth\u00e4lt Upload\u2011Schritt + URL\u2011Rewrite.</p> </li> <li> <p>Performance bei Batch\u2011Migration </p> </li> <li>Risiko: I/O\u2011Last auf Filesystem.  </li> <li> <p>Gegenma\u00dfnahme: Throttling, Chunk\u2011Batching, Lauf au\u00dferhalb UI\u2011Peak.</p> </li> <li> <p>Rollback\u2011Strategie </p> </li> <li>Risiko: Migration erzeugt fehlerhafte Mongo\u2011Daten.  </li> <li>Gegenma\u00dfnahme: Mongo\u2011Writes \u00fcber Version\u2011Feld; mit Flag deaktivierbar.</li> </ol>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#rollbackpfad-libraryweit","title":"Rollback\u2011Pfad (Library\u2011weit)","text":"<ol> <li><code>shadowTwin.primaryStore = \"filesystem\"</code></li> <li><code>shadowTwin.persistToFilesystem = true</code></li> <li>Batch\u2011Job \u201eRehydrate FS\u201c aus Mongo (oder Legacy\u2011FS als Quelle)</li> <li><code>allowFilesystemFallback = true</code> f\u00fcr Stabilit\u00e4t in \u00dcbergangszeit</li> </ol>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#konkrete-nachste-schritte-planung","title":"Konkrete n\u00e4chste Schritte (Planung)","text":"<ol> <li>Schema fixieren (finale Felder + Indexe).</li> <li>Library\u2011Flag definieren (<code>shadowTwin.persistToFilesystem</code> + <code>shadowTwin.primaryStore = \"mongo\"</code>).</li> <li>Batch\u2011Importer entwerfen (CLI oder API\u2011Route).</li> <li>Dual\u2011Read implementieren (Mongo zuerst, Filesystem fallback).</li> <li>Validation\u2011Report definieren (Counts, Sample\u2011Diffs).</li> </ol>"},{"location":"analysis/shadow-twin-mongo-migration-plan.html#entscheidungspunkte","title":"Entscheidungspunkte","text":"<ul> <li>Ein Dokument vs mehrere Dokumente: Hier empfohlen: ein Dokument pro <code>sourceId</code>.</li> <li>Binary\u2011Assets: URLs in Mongo, Inhalte in Azure (kein Filesystem\u2011Zugriff im UI).</li> <li>Rollback: Lesepfad kann per Feature\u2011Flag auf Filesystem zur\u00fcckgestellt werden.</li> </ul>"},{"location":"analysis/shadow-twin-mongo-target-structure.html","title":"Shadow-Twin MongoDB: Zielstruktur und Implementierungsstatus","text":""},{"location":"analysis/shadow-twin-mongo-target-structure.html#einordnung","title":"Einordnung","text":"<p>Dieses Dokument rekonstruiert das Zielbild f\u00fcr Shadow-Twin-Dokumente in MongoDB und zeigt, was bereits implementiert ist und was noch fehlt.</p>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#zielbild-aus-shadow-twin-mongo-migration-planmd","title":"Zielbild (aus shadow-twin-mongo-migration-plan.md)","text":""},{"location":"analysis/shadow-twin-mongo-target-structure.html#datenmodell","title":"Datenmodell","text":"<p>Ein Dokument pro Quelle (<code>sourceId</code>). Einbettung der Fragmente in einem Dokument reduziert Query-Overhead.</p> <pre><code>{\n  \"_id\": \"&lt;ObjectId&gt;\",\n  \"libraryId\": \"ff73d3a2-...\",\n  \"sourceId\": \"fileId-original\",\n  \"sourceName\": \"document.pdf\",\n  \"parentId\": \"folderId\",\n  \"userEmail\": \"user@example.com\",\n  \"artifacts\": {\n    \"transcript\": {\n      \"de\": {\n        \"markdown\": \"&lt;md&gt;\",\n        \"frontmatter\": {},\n        \"createdAt\": \"2026-01-22T12:00:00Z\",\n        \"updatedAt\": \"2026-01-22T12:05:00Z\"\n      }\n    },\n    \"transformation\": {\n      \"templateName\": {\n        \"de\": {\n          \"markdown\": \"&lt;md&gt;\",\n          \"frontmatter\": { \"docType\": \"event\", \"title\": \"...\" },\n          \"createdAt\": \"2026-01-22T12:10:00Z\",\n          \"updatedAt\": \"2026-01-22T12:11:00Z\"\n        }\n      }\n    }\n  },\n  \"binaryFragments\": [\n    {\n      \"name\": \"page-001.png\",\n      \"kind\": \"image\",\n      \"url\": \"https://&lt;azure&gt;/.../page-001.png\",\n      \"hash\": \"abcdef123456\",\n      \"mimeType\": \"image/png\",\n      \"size\": 123456,\n      \"createdAt\": \"2026-01-22T12:12:00Z\"\n    },\n    {\n      \"name\": \"preview_001.jpg\",\n      \"kind\": \"image\",\n      \"url\": \"https://&lt;azure&gt;/.../preview_001.jpg\",\n      \"hash\": \"fedcba654321\",\n      \"mimeType\": \"image/jpeg\",\n      \"size\": 45678,\n      \"createdAt\": \"2026-01-22T12:12:00Z\"\n    }\n  ],\n  \"filesystemSync\": {\n    \"enabled\": false,\n    \"shadowTwinFolderId\": null,\n    \"lastSyncedAt\": null\n  },\n  \"createdAt\": \"2026-01-22T12:00:00Z\",\n  \"updatedAt\": \"2026-01-22T12:11:00Z\"\n}\n</code></pre>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#wichtige-punkte-aus-dem-konzept","title":"Wichtige Punkte aus dem Konzept","text":"<ol> <li>Binary Fragments enthalten Azure-URLs: </li> <li>Jedes Fragment hat eine <code>url</code>-Eigenschaft mit der Azure Blob Storage URL</li> <li><code>hash</code> f\u00fcr Deduplizierung</li> <li> <p><code>mimeType</code>, <code>size</code>, <code>createdAt</code> f\u00fcr Metadaten</p> </li> <li> <p>Ein Dokument pro sourceId: </p> </li> <li>Alle Artefakte (transcript + transformation) werden in einem Dokument gespeichert</li> <li> <p>Binary Fragments werden einmalig pro Quelle gespeichert (nicht pro Artefakt)</p> </li> <li> <p>Filesystem optional: </p> </li> <li><code>filesystemSync.enabled: false</code> bedeutet, dass keine Filesystem-Kopien mehr existieren</li> <li>Bilder werden direkt aus Azure geladen</li> </ol>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#aktueller-implementierungsstatus","title":"Aktueller Implementierungsstatus","text":""},{"location":"analysis/shadow-twin-mongo-target-structure.html#was-bereits-implementiert-ist","title":"\u2705 Was bereits implementiert ist","text":"<ol> <li>Datenmodell-Struktur (<code>src/lib/repositories/shadow-twin-repo.ts</code>):</li> <li><code>ShadowTwinDocument</code> Interface entspricht dem Zielbild</li> <li><code>artifacts</code> Struktur korrekt (transcript/transformation)</li> <li> <p><code>binaryFragments</code> Array vorhanden</p> </li> <li> <p>Migration Writer (<code>src/lib/shadow-twin/shadow-twin-migration-writer.ts</code>):</p> </li> <li>Sammelt alle Dateien aus Shadow-Twin-Ordner</li> <li>Kategorisiert Dateien (markdown, image, audio, video, binary)</li> <li>Erstellt <code>binaryFragments</code> Array</li> </ol>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#was-fehlt","title":"\u274c Was fehlt","text":"<p>Kritisch: Azure-URLs in binaryFragments</p> <p>Die aktuelle Implementierung speichert nur <code>fileId</code> statt Azure-URLs:</p> <pre><code>// Aktuell (shadow-twin-migration-writer.ts, Zeile 163-170):\nbinaryFragments.push({\n  name: fileName,\n  kind: fileKind,\n  mimeType,\n  fileId: file.id,  // \u2190 Nur fileId, keine URL!\n  size: file.metadata.size,\n  createdAt: file.metadata.createdAt || new Date().toISOString(),\n})\n</code></pre> <p>Erwartet (aus Konzept): <pre><code>{\n  name: \"page-001.png\",\n  kind: \"image\",\n  url: \"https://&lt;azure&gt;/.../page-001.png\",  // \u2190 Azure-URL fehlt!\n  hash: \"abcdef123456\",  // \u2190 Hash fehlt!\n  mimeType: \"image/png\",\n  size: 123456,\n  createdAt: \"2026-01-22T12:12:00Z\"\n}\n</code></pre></p>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#was-implementiert-werden-muss","title":"Was implementiert werden muss","text":""},{"location":"analysis/shadow-twin-mongo-target-structure.html#1-bild-upload-wahrend-migration","title":"1. Bild-Upload w\u00e4hrend Migration","text":"<p>Die Migration sollte Bilder nach Azure hochladen, \u00e4hnlich wie <code>ImageProcessor.processMarkdownImages</code>:</p> <p>Referenz-Implementierung: - <code>src/lib/ingestion/image-processor.ts</code>: <code>uploadImageWithDeduplication()</code> - <code>src/lib/services/azure-storage-service.ts</code>: <code>uploadImageToScope()</code></p> <p>Ben\u00f6tigte Schritte:</p> <ol> <li>F\u00fcr jedes Bild im Shadow-Twin-Ordner:</li> <li>Datei aus Storage Provider laden (<code>provider.getBinary(fileId)</code>)</li> <li>Hash berechnen (<code>calculateImageHash(buffer)</code>)</li> <li>Nach Azure hochladen (<code>azureStorage.uploadImageToScope()</code>)</li> <li> <p>Azure-URL erhalten</p> </li> <li> <p>Scope bestimmen:</p> </li> <li><code>books</code> f\u00fcr normale Dokumente</li> <li><code>sessions</code> f\u00fcr Event-Dokumente mit Slides</li> <li> <p>Kann aus <code>artifactKey.templateName</code> oder Frontmatter abgeleitet werden</p> </li> <li> <p>Binary Fragments mit URLs speichern: <pre><code>binaryFragments.push({\n  name: fileName,\n  kind: fileKind,\n  url: azureUrl,  // \u2190 Azure-URL\n  hash: hash,     // \u2190 Hash f\u00fcr Deduplizierung\n  mimeType,\n  size: file.metadata.size,\n  createdAt: file.metadata.createdAt || new Date().toISOString(),\n})\n</code></pre></p> </li> </ol>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#2-deduplizierung","title":"2. Deduplizierung","text":"<ul> <li>Bilder mit gleichem Hash sollten nicht mehrfach hochgeladen werden</li> <li><code>ImageProcessor</code> hat bereits Deduplizierungs-Logik (Hash-Check vor Upload)</li> </ul>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#3-markdown-url-rewrite","title":"3. Markdown-URL-Rewrite","text":"<ul> <li>Nach Upload sollten relative Bild-Referenzen im Markdown durch Azure-URLs ersetzt werden</li> <li>\u00c4hnlich wie <code>ImageProcessor.processMarkdownImages()</code> macht</li> </ul>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#vergleich-aktuell-vs-ziel","title":"Vergleich: Aktuell vs. Ziel","text":""},{"location":"analysis/shadow-twin-mongo-target-structure.html#aktuelles-mongodb-dokument-ist","title":"Aktuelles MongoDB-Dokument (IST)","text":"<pre><code>{\n  \"binaryFragments\": [\n    {\n      \"name\": \"img-0.jpeg\",\n      \"kind\": \"image\",\n      \"mimeType\": \"image/jpeg\",\n      \"fileId\": \"cGRmLy4wMU9LVDIwMjRfTGl2aXF1ZV9Tw7hyZW5zZW4gQmVkZGluZ19Cb3hzcHJpbmdiZXR0X0VLX05ldHRvXzI1MDcwNF92MDAwMDNOZXcucGRmL2ltZy0wLmpwZWc=\",\n      \"size\": 635675,\n      \"createdAt\": \"2026-01-24T15:47:13.022Z\"\n    }\n  ]\n}\n</code></pre>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#ziel-dokument-soll","title":"Ziel-Dokument (SOLL)","text":"<pre><code>{\n  \"binaryFragments\": [\n    {\n      \"name\": \"img-0.jpeg\",\n      \"kind\": \"image\",\n      \"url\": \"https://&lt;storage-account&gt;.blob.core.windows.net/&lt;container&gt;/&lt;libraryId&gt;/books/&lt;fileId&gt;/&lt;hash&gt;.jpeg\",\n      \"hash\": \"a1b2c3d4e5f6...\",\n      \"mimeType\": \"image/jpeg\",\n      \"size\": 635675,\n      \"createdAt\": \"2026-01-24T15:47:13.022Z\"\n    }\n  ]\n}\n</code></pre>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ol> <li>Migration Writer erweitern:</li> <li>Azure-Upload f\u00fcr alle Bilder w\u00e4hrend Migration</li> <li>Hash-Berechnung</li> <li> <p>URL-Generierung</p> </li> <li> <p>Markdown-URL-Rewrite:</p> </li> <li>Relative Pfade (<code>img-0.jpeg</code>) durch Azure-URLs ersetzen</li> <li> <p>Vor dem Speichern in MongoDB</p> </li> <li> <p>Deduplizierung:</p> </li> <li>Hash-Check vor Upload</li> <li> <p>Wiederverwendung existierender Azure-URLs</p> </li> <li> <p>Scope-Bestimmung:</p> </li> <li>Logik zur Bestimmung von <code>books</code> vs. <code>sessions</code></li> <li>Basierend auf Template oder Frontmatter</li> </ol>"},{"location":"analysis/shadow-twin-mongo-target-structure.html#code-referenzen","title":"Code-Referenzen","text":"<ul> <li>Azure Upload: <code>src/lib/services/azure-storage-service.ts</code></li> <li>Image Processing: <code>src/lib/ingestion/image-processor.ts</code></li> <li>Hash-Berechnung: <code>src/lib/ingestion/image-processor.ts</code> (calculateImageHash)</li> <li>Migration Writer: <code>src/lib/shadow-twin/shadow-twin-migration-writer.ts</code></li> </ul>"},{"location":"analysis/shadow-twin-settings-ui.html","title":"Shadow\u2011Twin Settings UI (Library\u2011Config)","text":""},{"location":"analysis/shadow-twin-settings-ui.html#ziel","title":"Ziel","text":"<p>Im Frontend sollen die neuen Shadow\u2011Twin\u2011Flags (<code>primaryStore</code>, <code>persistToFilesystem</code>, <code>cleanupFilesystemOnMigrate</code>, <code>allowFilesystemFallback</code>) direkt in der Library\u2011Config gesetzt werden koennen. Das erspart manuelle DB\u2011Edits und macht Tests reproduzierbar.</p>"},{"location":"analysis/shadow-twin-settings-ui.html#varianten","title":"Varianten","text":""},{"location":"analysis/shadow-twin-settings-ui.html#variante-a-einstellungen-in-libraryform-empfohlen","title":"Variante A: Einstellungen in <code>LibraryForm</code> (empfohlen)","text":"<p>Beschreibung: Neue Sektion im bestehenden Formular unterhalb des Shadow\u2011Twin\u2011Modus. Vorteile: Schnell implementiert, keine neue Route, konsistent zum restlichen Settings\u2011Flow. Risiken: Formular wird groesser, mehr State im Component.</p>"},{"location":"analysis/shadow-twin-settings-ui.html#variante-b-separate-advanced-shadowtwin-settings-seite","title":"Variante B: Separate \u201eAdvanced Shadow\u2011Twin Settings\u201c Seite","text":"<p>Beschreibung: Neue Route (z.\u202fB. <code>/settings/shadow-twin</code>) nur fuer erweiterte Flags. Vorteile: Klar getrennt, weniger UI\u2011Rauschen im Standard\u2011Formular. Risiken: Mehr Routing/Permissions, hoehere Implementierungskosten.</p>"},{"location":"analysis/shadow-twin-settings-ui.html#variante-c-devonly-toggle-via-environment","title":"Variante C: Dev\u2011Only Toggle via Environment","text":"<p>Beschreibung: Flags nur via ENV/Config setzen, UI zeigt Read\u2011Only Werte. Vorteile: Wenig UI\u2011Aenderung, geringer Wartungsaufwand. Risiken: Unpraktisch fuer Tests, weniger transparent.</p>"},{"location":"analysis/shadow-twin-settings-ui.html#entscheidung","title":"Entscheidung","text":"<p>Variante A. Sie ist die schnellste und staerkt den Test\u2011Workflow direkt in der Library\u2011Config.</p>"},{"location":"analysis/shadow-twin-settings-ui.html#scope-minimal","title":"Scope (Minimal)","text":"<ul> <li>Dropdown fuer <code>primaryStore</code>.</li> <li>Switches fuer <code>persistToFilesystem</code>, <code>cleanupFilesystemOnMigrate</code>, <code>allowFilesystemFallback</code>.</li> <li>Persistierung in <code>Library.config.shadowTwin</code>.</li> </ul>"},{"location":"analysis/shadow-twin-source-selection.html","title":"Shadow-Twin Quellenwahl - Deterministische Architektur","text":""},{"location":"analysis/shadow-twin-source-selection.html#problem-bug-vom-27012026","title":"Problem (Bug vom 27.01.2026)","text":"<p>Bei Re-Transformation eines PDFs mit 32 Seiten wurde nur eine kurze Summary (761 Zeichen) generiert, obwohl das vollst\u00e4ndige Transkript vorhanden war.</p>"},{"location":"analysis/shadow-twin-source-selection.html#ursachen-zwei-bugs","title":"Ursachen (zwei Bugs)","text":"<p>Bug 1: Template-Phase wurde \u00fcbersprungen trotz <code>force</code> Policy</p> <p>Die Start-Route ignorierte die <code>policies.metadata = 'force'</code> Policy:</p> <pre><code>// VORHER (falsch):\nconst runTemplate = templateEnabled &amp;&amp; needTemplate\n// needTemplate kam aus Preprocessor, force wurde ignoriert!\n</code></pre> <p>Bug 2: Falsche Quellenwahl bei Template-Ausf\u00fchrung</p> <p>Die Funktion <code>loadShadowTwinMarkdown()</code> bevorzugte immer die transformierte Datei (<code>shadowTwinState.transformed.id</code>), unabh\u00e4ngig vom Kontext:</p> <pre><code>Shadow-Twin-State:\n\u251c\u2500\u2500 transformed.id = \"...::transformation::de::pdfanalyse\"  \u2190 761 Zeichen (Summary)\n\u2514\u2500\u2500 transcriptFiles[0].id = \"...::transcript::de::\"         \u2190 ~50.000 Zeichen (32 Seiten)\n</code></pre> <p>Bei Template-Ausf\u00fchrung mit <code>policy=force</code>: 1. <code>loadShadowTwinMarkdown()</code> lud die alte Transformation (761 Zeichen) 2. Template transformierte die Summary \u2192 Ergebnis war wieder nur Summary 3. Garbage In, Garbage Out</p>"},{"location":"analysis/shadow-twin-source-selection.html#losung-deterministische-quellenwahl-mit-explizitem-purpose-parameter","title":"L\u00f6sung: Deterministische Quellenwahl mit explizitem <code>purpose</code> Parameter","text":"<p>Die Funktion <code>loadShadowTwinMarkdown()</code> erfordert jetzt einen required <code>purpose</code> Parameter:</p> <pre><code>type ShadowTwinLoadPurpose =\n  | 'forTemplateTransformation'  // L\u00e4dt TRANSKRIPT (Phase 1 Ergebnis)\n  | 'forIngestOrPassthrough'     // L\u00e4dt TRANSFORMATION (Phase 2 Ergebnis)\n</code></pre>"},{"location":"analysis/shadow-twin-source-selection.html#architekturprinzip","title":"Architekturprinzip","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DETERMINISTISCHE QUELLENWAHL                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  Template wird AUSGEF\u00dcHRT        Template wird \u00dcBERSPRUNGEN                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500              \u2502\n\u2502  Quelle: TRANSKRIPT              Quelle: TRANSFORMATION                     \u2502\n\u2502  (Phase 1 Ergebnis)              (Phase 2 Ergebnis)                         \u2502\n\u2502                                                                             \u2502\n\u2502  Der Transformer darf NIEMALS    Bestehendes Ergebnis wird an               \u2502\n\u2502  seine eigenen Daten als         n\u00e4chste Phase weitergegeben                \u2502\n\u2502  Quelle verwenden!                                                          \u2502\n\u2502                                                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  Ingest-Phase                                                               \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                               \u2502\n\u2502  Quelle: TRANSFORMATION (Fallback: Transkript)                              \u2502\n\u2502  Ingest braucht das transformierte Markdown mit Metadaten                   \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"analysis/shadow-twin-source-selection.html#verwendung","title":"Verwendung","text":"<pre><code>// Template-Phase wird AUSGEF\u00dcHRT \u2192 braucht Transkript\nconst source = await loadShadowTwinMarkdown(ctx, provider, 'forTemplateTransformation')\n\n// Ingest-Phase oder Template \u00fcbersprungen \u2192 braucht transformierte Datei\nconst source = await loadShadowTwinMarkdown(ctx, provider, 'forIngestOrPassthrough')\n</code></pre>"},{"location":"analysis/shadow-twin-source-selection.html#aufrufer-ubersicht","title":"Aufrufer-\u00dcbersicht","text":"Datei Kontext Purpose <code>start/route.ts</code> Ingest-only-Pfad <code>'forIngestOrPassthrough'</code> <code>start/route.ts</code> Template-only-Pfad <code>'forTemplateTransformation'</code> <code>start/route.ts</code> Ingest nach Template <code>'forIngestOrPassthrough'</code> <code>phase-ingest.ts</code> Ingest-Phase <code>'forIngestOrPassthrough'</code>"},{"location":"analysis/shadow-twin-source-selection.html#losung-bug-1-template-policy-berucksichtigung","title":"L\u00f6sung Bug 1: Template-Policy-Ber\u00fccksichtigung","text":"<p>Die Start-Route ber\u00fccksichtigt jetzt die <code>policies.metadata</code> Policy:</p> <pre><code>// NACHHER (korrekt):\nconst templateDirective: 'ignore' | 'do' | 'force' = \n  policies.metadata === 'force' ? 'force' :\n  policies.metadata === 'ignore' || policies.metadata === 'skip' ? 'ignore' :\n  templateEnabled ? 'do' : 'ignore'\n\nconst runTemplate = templateEnabled &amp;&amp; (\n  templateDirective === 'force' ? true :\n  templateDirective === 'ignore' ? false :\n  needTemplate // 'do' \u2192 basierend auf Preprocessor\n)\n</code></pre> Policy Verhalten <code>'force'</code> Template wird IMMER ausgef\u00fchrt (auch wenn needTemplate=false) <code>'ignore'</code>/<code>'skip'</code> Template wird NIE ausgef\u00fchrt <code>'auto'</code>/<code>'do'</code> Basierend auf Preprocessor (needTemplate)"},{"location":"analysis/shadow-twin-source-selection.html#betroffene-dateien","title":"Betroffene Dateien","text":"<ul> <li><code>src/lib/external-jobs/phase-shadow-twin-loader.ts</code> - Deterministische Quellenwahl</li> <li><code>src/app/api/external/jobs/[jobId]/start/route.ts</code> - Policy-Ber\u00fccksichtigung + Aufrufer</li> <li><code>src/lib/external-jobs/phase-ingest.ts</code> - Aufrufer angepasst</li> </ul>"},{"location":"analysis/shadow-twin-source-selection.html#ruckgabewert","title":"R\u00fcckgabewert","text":"<p>Der R\u00fcckgabewert enth\u00e4lt jetzt auch <code>loadedArtifactKind</code> f\u00fcr Debugging:</p> <pre><code>interface ShadowTwinMarkdownResult {\n  markdown: string\n  meta: Record&lt;string, unknown&gt;\n  fileId: string\n  fileName: string\n  loadedArtifactKind: 'transcript' | 'transformation'  // NEU\n}\n</code></pre>"},{"location":"analysis/shadow-twin-storage-abstraction.html","title":"Shadow twin storage abstraction","text":""},{"location":"analysis/shadow-twin-storage-abstraction.html#ausgangsfrage","title":"Ausgangsfrage","text":"<p>Warum behandeln so viele Code-Stellen Shadow\u2011Twins explizit als \u201eMongoDB vs Filesystem\u201c-Fallunterscheidung, statt eine zentrale Library/Klasse zu haben, die intern entscheidet, wie gelesen/geschrieben wird?</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#kritische-analyse-warum-es-aktuell-zersplittert-ist","title":"Kritische Analyse (warum es aktuell \u201czersplittert\u201d ist)","text":""},{"location":"analysis/shadow-twin-storage-abstraction.html#1-historische-kopplung-provider-first","title":"1) Historische Kopplung: \u201cProvider-first\u201d","text":"<p>Der bestehende Codepfad (Jobs, Preprocess, Resolver) ist stark auf den <code>StorageProvider</code> ausgerichtet: - <code>resolveArtifact(provider, ...)</code> findet Artefakte \u00fcber Filesystem/OneDrive/Drive \u2013 nicht \u00fcber MongoDB. - <code>analyzeShadowTwin()</code> und viele \u201cexistiert schon?\u201d-Checks leiten sich aus Provider-Listen/Reads ab.</p> <p>Sobald <code>primaryStore='mongo'</code> und <code>persistToFilesystem=false</code> gilt, sind diese Artefakte absichtlich nicht mehr im Provider sichtbar. Damit liefert der Provider-Pfad \u201cnicht gefunden\u201d, obwohl MongoDB den Shadow\u2011Twin hat. Das zwingt heute zu Spezialf\u00e4llen (Mongo-first, provider-fallback).</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#2-hybrid-konfigurationen-sind-fachlich-erlaubt","title":"2) Hybrid-Konfigurationen sind fachlich erlaubt","text":"<p>Eure Library-Config erlaubt Mischbetrieb: - <code>primaryStore</code>: <code>'mongo' | 'filesystem'</code> - <code>allowFilesystemFallback</code>: boolean - <code>persistToFilesystem</code>: boolean</p> <p>Das hei\u00dft: In manchen Situationen muss man mehrere Stores ber\u00fccksichtigen. Wenn diese Logik nicht zentral gekapselt ist, taucht sie \u00fcberall als \u201cif/else\u201d auf.</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#3-unterschiedliche-entscheidungen-brauchen-unterschiedliche-artefakte","title":"3) Unterschiedliche Entscheidungen brauchen unterschiedliche Artefakte","text":"<p>Nicht jede Phase fragt dasselbe: - Extract: \u201cExistiert Transcript (oder Transformation als Superset)?\u201d - Template/Ingest: \u201cExistiert Transformation f\u00fcr <code>templateName</code> + Sprache und ist Frontmatter valide?\u201d - Completion/Contract: \u201cIst ein referenzierbarer <code>savedItemId</code> f\u00fcr den erwarteten Artefakt-Typ vorhanden?\u201d</p> <p>Wenn es keinen zentralen \u201cShadowTwinStore/Service\u201d gibt, implementieren diese Stellen ihre eigene Interpretation \u2013 und dadurch entsteht Inkonsistenz.</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#zielbild-was-du-beschreibst","title":"Zielbild (was du beschreibst)","text":"<p>Ein zentrales Objekt/Service, das von au\u00dfen wie eine einheitliche Shadow\u2011Twin API wirkt: - <code>getArtifact(...)</code> - <code>upsertArtifact(...)</code> - <code>exists(...)</code> - <code>getBinaryFragments(...)</code> - <code>resolveSavedItemIdForContract(...)</code></p> <p>Und intern (einmal) entscheidet: - MongoDB vs Provider - Fallbacks - Konfiguration (<code>primaryStore</code>, <code>allowFilesystemFallback</code>, <code>persistToFilesystem</code>)</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#drei-losungsvarianten","title":"Drei L\u00f6sungsvarianten","text":""},{"location":"analysis/shadow-twin-storage-abstraction.html#variante-a-thin-facade-funktional-minimal-invasiv","title":"Variante A \u2014 \u201cThin Facade\u201d (funktional, minimal-invasiv)","text":"<p>Eine zentrale Datei <code>shadow-twin-service.ts</code> (oder \u00e4hnlich) mit Funktionen wie: - <code>shadowTwinExists({ library, source, kind, lang, templateName })</code> - <code>getShadowTwinMarkdown({ ... })</code> - <code>upsertShadowTwinMarkdown({ ... })</code></p> <p>Intern: - Wenn <code>primaryStore==='mongo'</code> \u2192 Mongo zuerst - Wenn <code>allowFilesystemFallback</code> \u2192 Provider-Fallback</p> <p>Pro - Schnell umzusetzen, geringe Refactor-Kosten - Reduziert Duplikation sofort</p> <p>Contra - Keine klare Objekt-/Interface-Struktur, Gefahr \u201cGod module\u201d - Auf Dauer schwer zu testen, wenn zu viel Logik hinein wandert</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#variante-b-repositorystore-interface-empfohlen-sauber-testbar","title":"Variante B \u2014 \u201cRepository/Store Interface\u201d (empfohlen, sauber testbar)","text":"<p>Definiere ein Interface:</p> <ul> <li><code>ShadowTwinStore</code> mit Methoden:</li> <li><code>getArtifactMarkdown(key): Promise&lt;{ id, name, markdown } | null&gt;</code></li> <li><code>existsArtifact(key): Promise&lt;boolean&gt;</code></li> <li><code>upsertArtifact(key, markdown, binaryFragments?): Promise&lt;{ id }&gt;</code></li> <li><code>getBinaryFragments(sourceId): Promise&lt;...&gt;</code></li> </ul> <p>Implementationen: - <code>MongoShadowTwinStore</code> - <code>ProviderShadowTwinStore</code> (filesystem/drive \u00fcber <code>StorageProvider</code>)</p> <p>Orchestrator: - <code>ShadowTwinService</code> entscheidet nach Config und koordiniert Fallbacks:   - <code>primaryStore</code> first   - optionaler <code>fallbackStore</code></p> <p>Pro - Single Source of Truth f\u00fcr Store-Wahl - Sehr gut unit-testbar (Mock Store) - Saubere Erweiterbarkeit (z.B. sp\u00e4ter Redis Cache, oder \u201chybrid store\u201d)</p> <p>Contra - Refactor-Aufwand moderat (mehr Signaturen, Dependency Injection)</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#variante-c-domain-object-shadowtwin-oo-ansatz-wie-ein-objekt","title":"Variante C \u2014 \u201cDomain Object: ShadowTwin\u201d (OO-Ansatz, \u201cwie ein Objekt\u201d)","text":"<p>Ein <code>ShadowTwin</code>-Objekt, das pro Source geladen wird, z.B.: - <code>const st = await ShadowTwin.load({ userEmail, library, source })</code> - <code>await st.getTranscript(lang)</code> - <code>await st.getTransformation({ lang, templateName })</code> - <code>await st.saveTransformation(...)</code></p> <p>Intern h\u00e4lt es: - Store-Strategy - Cache des geladenen Dokuments - Hilfsfunktionen wie \u201cTransformation impliziert Extract\u201d</p> <p>Pro - Passt gut zu deinem mentalen Modell (\u201cShadowTwin als Objekt\u201d) - Weniger Parameter-Weiterreichen pro Call</p> <p>Contra - In Next.js/Server-Kontext muss man sehr sauber sein (keine Cross-Request-Mutation, kein global state) - Gefahr von \u201czu viel Magie\u201d, wenn Load/Cache/Side-effects nicht klar sind</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#empfehlung-technisch-pragmatisch","title":"Empfehlung (technisch pragmatisch)","text":"<p>Ich w\u00fcrde Variante B w\u00e4hlen (Interface + Service): - Minimal genug, um inkrementell zu refactoren - Strukturiert genug, um das \u201cif/else \u00fcberall\u201d dauerhaft zu eliminieren</p> <p>Variante C kann sp\u00e4ter als d\u00fcnner Wrapper um Variante B entstehen (z.B. <code>ShadowTwin</code> nutzt intern <code>ShadowTwinService</code>), wenn ihr wirklich das Objektmodell wollt.</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#inkrementeller-refactor-plan-ohne-big-bang","title":"Inkrementeller Refactor-Plan (ohne Big Bang)","text":"<p>1) Zentralen <code>ShadowTwinService</code> einf\u00fchren, aber zun\u00e4chst nur f\u00fcr Lesen/Existenz:    - <code>existsTranscriptOrTransformation(...)</code>    - <code>getTransformationMarkdown(...)</code></p> <p>2) Kritische Hotspots migrieren:    - Gates: <code>gateExtractPdf</code>, <code>gateTransformTemplate</code> (falls n\u00f6tig)    - Preprocessor: <code>findPdfMarkdown</code> (ersetzt direkte Mongo/Provider-Calls)    - Completion: Contract-Aufl\u00f6sung (<code>savedItemId</code>) zentralisieren</p> <p>3) Write-Pfade migrieren:    - <code>persistShadowTwinToMongo</code>, <code>saveMarkdown</code> \u2192 \u00fcber Service/Store</p> <p>4) <code>analyzeShadowTwin()</code> so umbauen, dass es den Service nutzt (dann wird UI/Jobs konsistent).</p>"},{"location":"analysis/shadow-twin-storage-abstraction.html#warum-wir-es-jetzt-noch-nicht-komplett-so-gemacht-haben","title":"Warum wir es jetzt noch nicht komplett so gemacht haben","text":"<p>Der \u201cFix\u201d war akut: ohne Mongo-aware Checks liefen Jobs unn\u00f6tig neu oder fielen am Contract. In so einer Situation ist eine punktuelle Anpassung risiko\u00e4rmer als ein gro\u00dffl\u00e4chiger Architektur-Umbau.</p> <p>Das \u00e4ndert nichts daran, dass die zentrale Kapselung mittelfristig der bessere Zustand ist.</p>"},{"location":"analysis/shadow-twin-v2-only.html","title":"Shadow-Twin (v2-only)","text":""},{"location":"analysis/shadow-twin-v2-only.html#shadow-twin-v2-only-runtime","title":"Shadow-Twin (v2-only runtime)","text":"<p>Status: active Last verified: 2026-01-04  </p>"},{"location":"analysis/shadow-twin-v2-only.html#scope","title":"Scope","text":"<p>This document describes how Shadow-Twin works in the current runtime (v2-only). It does not describe migration/repair of old data (Phase B, deferred).</p>"},{"location":"analysis/shadow-twin-v2-only.html#summary-what-is-true-today","title":"Summary (what is true today)","text":"<ul> <li>The application runtime is v2-only for Shadow-Twin artifact resolve/write.</li> <li>Transcript + Transformation artifacts use deterministic names.</li> <li>The UI must not guess filenames. It uses the backend resolver (bulk).</li> <li>Legacy/V1 repair paths were removed from the runtime path.</li> </ul>"},{"location":"analysis/shadow-twin-v2-only.html#glossary","title":"Glossary","text":"<ul> <li>Artifact: a generated file related to a source file (Markdown, images).</li> <li>Transcript: extracted text (usually without frontmatter).</li> <li>Transformation: template-based Markdown with frontmatter/metadata.</li> <li>Dot-folder: hidden folder <code>.{originalName}</code> that groups multiple related artifacts.</li> </ul>"},{"location":"analysis/shadow-twin-v2-only.html#v2-only-enforcement","title":"v2-only enforcement","text":"<p>We treat any \u201clegacy/v1 Shadow-Twin logic\u201d as unsupported in runtime.</p> <ul> <li>Config may still contain <code>shadowTwin.mode = legacy|v2</code> for historical libraries.</li> <li>The runtime does not execute legacy heuristics or legacy adoption/cleanup.</li> <li>UI/Settings provides a safe action: set the config flag to v2 (no migration).</li> </ul>"},{"location":"analysis/shadow-twin-v2-only.html#artifact-locations-storage","title":"Artifact locations (storage)","text":"<p>Artifacts can live either: 1) inside a dot-folder <code>.{originalName}/</code> (recommended when multiple assets exist), or 2) as siblings next to the source file (common for \u201conly Markdown\u201d cases).</p> <p>The resolver checks dot-folder first (if present), then siblings.</p>"},{"location":"analysis/shadow-twin-v2-only.html#naming-v2","title":"Naming (v2)","text":"<p>Transcript: - <code>{baseName}.{language}.md</code> - Example: <code>document.de.md</code></p> <p>Transformation: - <code>{baseName}.{templateName}.{language}.md</code> - Example: <code>document.pdfanalyse.de.md</code></p>"},{"location":"analysis/shadow-twin-v2-only.html#central-entry-points-code","title":"Central entry points (code)","text":"<p>Resolve: - <code>src/lib/shadow-twin/artifact-resolver.ts</code> (<code>resolveArtifact</code>) - <code>src/app/api/library/[libraryId]/artifacts/batch-resolve/route.ts</code></p> <p>Write: - <code>src/lib/shadow-twin/artifact-writer.ts</code> (<code>writeArtifact</code>) - Used by external jobs and creation flows</p>"},{"location":"analysis/shadow-twin-v2-only.html#known-fixed-issue-processingstatus-in-extract-only","title":"Known fixed issue: processingStatus in extract-only","text":"<p>Observed issue: <code>shadowTwinState.processingStatus</code> could end up missing for extract-only jobs. Current behavior: after transcript is saved, extract-only recomputes the Shadow-Twin state and writes <code>processingStatus = 'ready'</code>, plus a final idempotent fallback at job end.</p> <p>Implementation reference: - <code>src/lib/external-jobs/extract-only.ts</code></p>"},{"location":"analysis/storage.html","title":"Storage","text":""},{"location":"analysis/storage.html#storage-current-runtime","title":"Storage (current runtime)","text":"<p>Status: active Last verified: 2026-01-04  </p>"},{"location":"analysis/storage.html#scope","title":"Scope","text":"<p>This document explains how storage providers behave in this project and which errors are common.</p>"},{"location":"analysis/storage.html#glossary","title":"Glossary","text":"<ul> <li>Provider: a backend adapter (filesystem, OneDrive, ...)</li> <li>itemId: provider-specific identifier for a file/folder</li> <li>parentId: folder itemId that contains the item</li> </ul>"},{"location":"analysis/storage.html#providers","title":"Providers","text":"<p>This codebase supports multiple providers (examples): - local filesystem - OneDrive (Microsoft Graph)</p> <p>Provider types live under: - <code>src/lib/storage/*</code></p>"},{"location":"analysis/storage.html#common-issue-fileidundefined-requests-filesystem","title":"Common issue: <code>fileId=undefined</code> requests (filesystem)","text":"<p>Symptom: - after upload, a list request is made with <code>fileId=undefined</code>, leading to ENOENT/404.</p> <p>Root cause (typical): - caller calls <code>refreshItems()</code> without a folder id, so the URL contains <code>undefined</code>.</p> <p>Fix strategy: - fix the caller to always pass a folder id (or default to <code>root</code>) - optionally harden server parsing to treat <code>\"undefined\"|\"null\"|\"\"</code> as <code>root</code> (safety net)</p>"},{"location":"analysis/storage.html#related-reference-docs","title":"Related reference docs","text":"<ul> <li><code>docs/reference/modules/storage.md</code></li> </ul>"},{"location":"analysis/template-only-job-completion.html","title":"Template only job completion","text":"<p># Template\u2011Only Job Completion: savedItemId fehlt</p>"},{"location":"analysis/template-only-job-completion.html#kontext","title":"Kontext","text":"<p>Im Template\u2011Only Pfad der Start\u2011Route wird der Job als completed markiert, obwohl kein <code>result.savedItemId</code> gesetzt wird. Das verletzt den globalen Contract und f\u00fchrt zu Fehlern wie: \"Template\u2011Job ist completed, aber result.savedItemId (Transformation) fehlt oder ist ung\u00fcltig.\"</p>"},{"location":"analysis/template-only-job-completion.html#beobachtung","title":"Beobachtung","text":"<p><code>runTemplatePhase(...)</code> liefert ein <code>TemplatePhaseResult</code> mit optionalem <code>savedItemId</code>. Dieser Wert wird im Template\u2011Only Pfad aktuell nicht an <code>setJobCompleted(...)</code> \u00fcbergeben.</p>"},{"location":"analysis/template-only-job-completion.html#ziel","title":"Ziel","text":"<p>Den Contract einhalten, indem <code>savedItemId</code> aus der Template\u2011Phase (falls vorhanden) an den Completion\u2011Schritt \u00fcbergeben wird. Dadurch wird der Job nur dann als completed markiert, wenn die Transformation auch referenzierbar ist.</p>"},{"location":"analysis/template-only-job-completion.html#varianten","title":"Varianten","text":"<p>1) Minimaler Fix (bevorzugt) <code>setJobCompleted(...)</code> im Template\u2011Only Pfad bekommt <code>result: { savedItemId: templateResult.savedItemId }</code>.    Vorteil: minimal, keine Nebenwirkungen, Contract wird erfuellt.</p> <p>2) Validierung vor Completion    Wenn <code>savedItemId</code> fehlt, Job als <code>failed</code> markieren und klare Fehlermeldung setzen.    Vorteil: klare Diagnose, kein \"silent complete\".    Nachteil: mehr UI\u2011Folgen (Fehlerzustand).</p> <p>3) Deterministische Aufloesung im Start\u2011Pfad    Wenn <code>savedItemId</code> fehlt, starte einen Resolver (wie in <code>complete.ts</code>).    Vorteil: selbstheilend.    Nachteil: zusaetzliche Storage\u2011Calls im Start\u2011Pfad.</p>"},{"location":"analysis/template-only-job-completion.html#entscheidung","title":"Entscheidung","text":"<p>Variante 1 wird umgesetzt, da sie den geringsten Eingriff darstellt und den Contract direkt erfuellt.</p>"},{"location":"analysis/testimonial-transformation-concept.html","title":"Testimonial Transformation: Konzeptproblem","text":""},{"location":"analysis/testimonial-transformation-concept.html#problemstellung","title":"Problemstellung","text":"<p>Bei der Erstellung eines Testimonials mit reinem Text-Eingabe (kein Audio, kein LLM) werden aktuell zwei Artefakte erstellt:</p> <ol> <li>Transcript (<code>source.de.md</code>): Roher Text ohne Frontmatter</li> <li>Transformation (<code>source.event-testimonial-creation-de.de.md</code>): Template-formatierter Text mit Frontmatter</li> </ol>"},{"location":"analysis/testimonial-transformation-concept.html#frage-warum-gibt-es-ein-transformation-artefakt","title":"Frage: Warum gibt es ein Transformation-Artefakt?","text":"<p>Laut Shadow-Twin-Architektur: - Transcript: Authentisches Abbild der Quelle (UC-A), Autor = Quelle - Transformation: User-autored, Template-basierte Interpretation (UC-B)</p>"},{"location":"analysis/testimonial-transformation-concept.html#aktuelle-situation-bei-testimonials","title":"Aktuelle Situation bei Testimonials","text":""},{"location":"analysis/testimonial-transformation-concept.html#was-passiert-aktuell","title":"Was passiert aktuell:","text":"<ol> <li>User gibt Text ein \u2192 <code>source.txt</code></li> <li>Transcript wird erstellt \u2192 <code>source.de.md</code> (gleicher Text, ohne Frontmatter)</li> <li>Transformation wird erstellt \u2192 <code>source.event-testimonial-creation-de.de.md</code>:</li> <li>Frontmatter wird aus Metadaten generiert</li> <li>Template-Body wird gerendert (Platzhalter ersetzt)</li> <li>ABER: Kein LLM wird verwendet, keine echte \"Transformation\"</li> </ol>"},{"location":"analysis/testimonial-transformation-concept.html#was-das-template-erwartet","title":"Was das Template erwartet:","text":"<p>Das Template <code>event-testimonial-creation-de.md</code> hat einen <code>systemprompt</code>: <pre><code>Role:\n- You extract structured testimonial information from user input.\n</code></pre></p> <p>Das deutet darauf hin, dass eigentlich ein LLM verwendet werden sollte, um strukturierte Informationen zu extrahieren.</p>"},{"location":"analysis/testimonial-transformation-concept.html#mogliche-interpretationen","title":"M\u00f6gliche Interpretationen","text":""},{"location":"analysis/testimonial-transformation-concept.html#variante-a-transformation-template-formatierung-auch-ohne-llm","title":"Variante A: Transformation = Template-Formatierung (auch ohne LLM)","text":"<p>Argumentation: - Transformation bedeutet nicht zwingend LLM-Transformation - Template-Formatierung (Frontmatter + Body-Rendering) ist auch eine \"Transformation\" - Erm\u00f6glicht konsistente Struktur f\u00fcr UI-Anzeige</p> <p>Pro: - Konsistent mit Shadow-Twin-Architektur - Transformation-Artefakt enth\u00e4lt strukturierte Metadaten (f\u00fcr Suche/Filterung) - UI kann Transformation-Artefakt f\u00fcr Anzeige verwenden</p> <p>Contra: - Keine echte \"Transformation\" im Sinne von LLM-Interpretation - Verwirrend, wenn kein LLM verwendet wird</p>"},{"location":"analysis/testimonial-transformation-concept.html#variante-b-transformation-nur-bei-llm-transformation","title":"Variante B: Transformation nur bei LLM-Transformation","text":"<p>Argumentation: - Transformation sollte nur erstellt werden, wenn tats\u00e4chlich eine LLM-Transformation stattfindet - Bei reinem Text-Eingabe: Nur Transcript erstellen - Frontmatter k\u00f6nnte direkt im Transcript stehen (aber das widerspricht der Architektur)</p> <p>Pro: - Klarere Semantik: Transformation = echte Transformation - Weniger Artefakte bei einfachen F\u00e4llen</p> <p>Contra: - Widerspricht Shadow-Twin-Architektur (Transcript = ohne Frontmatter) - UI braucht strukturierte Metadaten (Frontmatter) - Inkonsistent mit anderen Medien (PDF, Audio)</p>"},{"location":"analysis/testimonial-transformation-concept.html#variante-c-hybrid-ansatz","title":"Variante C: Hybrid-Ansatz","text":"<p>Argumentation: - Bei reinem Text-Eingabe: Nur Transcript erstellen - Transformation wird sp\u00e4ter erstellt, wenn:   - LLM-Transformation gew\u00fcnscht ist   - Oder wenn User explizit \"Finalisieren\" klickt (dann LLM-Transformation)</p> <p>Pro: - Klare Trennung: Transcript = Quelle, Transformation = Interpretation - Transformation wird nur erstellt, wenn tats\u00e4chlich transformiert wird</p> <p>Contra: - Komplexer: Zwei Phasen (Erstellung + Finalisierung) - UI braucht sofort strukturierte Metadaten</p>"},{"location":"analysis/testimonial-transformation-concept.html#empfehlung","title":"Empfehlung","text":"<p>Variante A scheint am konsistentesten: - Transformation = Template-basierte Formatierung (mit oder ohne LLM) - Erm\u00f6glicht konsistente Struktur f\u00fcr alle Testimonials - UI kann immer Transformation-Artefakt f\u00fcr Anzeige verwenden</p> <p>Aber: Das Template sollte klarstellen, ob LLM verwendet wird oder nicht.</p>"},{"location":"analysis/testimonial-transformation-concept.html#offene-fragen","title":"Offene Fragen","text":"<ol> <li>Soll das Template <code>event-testimonial-creation-de.md</code> einen LLM verwenden?</li> <li>Aktuell: Nein (nur Platzhalter-Ersetzung)</li> <li> <p>Template erwartet aber LLM (<code>systemprompt</code>)</p> </li> <li> <p>Soll bei reinem Text-Eingabe nur Transcript erstellt werden?</p> </li> <li>Aktuell: Beide Artefakte werden erstellt</li> <li> <p>Alternative: Nur Transcript, Transformation sp\u00e4ter</p> </li> <li> <p>Was ist der Zweck des Transformation-Artefakts bei Testimonials?</p> </li> <li>Strukturierte Metadaten f\u00fcr Suche/Filterung?</li> <li>UI-Anzeige?</li> <li>Oder tats\u00e4chlich transformierter Inhalt?</li> </ol>"},{"location":"analysis/testimonial-transformation-concept.html#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ol> <li>Kl\u00e4ren, ob LLM-Transformation f\u00fcr Testimonials gew\u00fcnscht ist</li> <li>Entscheiden, ob Transformation-Artefakt auch ohne LLM erstellt werden soll</li> <li>Dokumentation aktualisieren, um Konzept zu kl\u00e4ren</li> </ol>"},{"location":"analysis/trace-timeline-postprocessing-elimination.html","title":"Trace timeline postprocessing elimination","text":""},{"location":"analysis/trace-timeline-postprocessing-elimination.html#ziel","title":"Ziel","text":"<p>Die Trace-Timeline soll die tats\u00e4chlichen Phasenzeiten von <code>extract_pdf</code>, <code>transform_template</code> und <code>ingest_rag</code> abbilden. Insbesondere soll das Persistieren (MongoDB/Blob/Filesystem) nicht als eigenst\u00e4ndige (Root\u2011)Phase <code>postprocessing</code> erscheinen, sondern zeitlich der Phase zugeschrieben werden, die den Persistenzschritt logisch verursacht. Zus\u00e4tzlich soll verhindert werden, dass der <code>job</code>\u2011Span durch transiente Fehler (z.\u202fB. <code>ECONNRESET</code>) fr\u00fchzeitig endet und sp\u00e4tere erfolgreiche Callbacks die Timeline nicht mehr \u201eheilen\u201c k\u00f6nnen.</p>"},{"location":"analysis/trace-timeline-postprocessing-elimination.html#beobachtungen-aus-dem-trace-sample","title":"Beobachtungen (aus dem Trace-Sample)","text":"<ul> <li>Doppelte <code>postprocessing</code>-Root-Spans (gleiches <code>spanId</code>, unterschiedliche Zeitfenster) erzeugen Mehrdeutigkeit und k\u00f6nnen sogar mit Template \u00fcberlappen. Das ist instrumentationsseitig schwer zu interpretieren und macht Phasenzeiten unzuverl\u00e4ssig.</li> <li><code>extract_pdf</code> wird als <code>completed</code> markiert bevor die Persistenz (Markdown/Assets) passiert. Damit wird Persistenzzeit aus der Extract-Phase herausgeschnitten und landet in einem \u201eNeben-Span\u201c.</li> <li>Wird ein Job einmal \u00fcber <code>setStatus(..., 'failed')</code> markiert, beendet das Repository den <code>job</code>\u2011Span nur einmalig (<code>endedAt</code> wird nicht \u00fcberschrieben). Ein nachfolgend erfolgreicher Callback kann den <code>job</code>\u2011Span daher nicht mehr verl\u00e4ngern \u2192 Timeline bleibt falsch.</li> </ul>"},{"location":"analysis/trace-timeline-postprocessing-elimination.html#losungsvarianten","title":"L\u00f6sungsvarianten","text":""},{"location":"analysis/trace-timeline-postprocessing-elimination.html#variante-a-strikt-harte-finalitat","title":"Variante A \u2013 Strikt (harte Finalit\u00e4t)","text":"<p>Sobald ein Fehler auftritt, wird der Job als <code>failed</code> markiert und alle sp\u00e4teren Callbacks werden ignoriert.</p> <ul> <li>Pro: Timeline &amp; Status sind konsistent (kein \u201efailed aber l\u00e4uft weiter\u201c).</li> <li>Contra: Bei realen Retry-Szenarien (transiente Netzfehler, tempor\u00e4re 400/invalid_payload-Mapping) kann ein eigentlich erfolgreicher Job dauerhaft fehlschlagen.</li> </ul>"},{"location":"analysis/trace-timeline-postprocessing-elimination.html#variante-b-robust-transiente-fehler-sind-nicht-final","title":"Variante B \u2013 Robust (transiente Fehler sind nicht final)","text":"<p>Transiente Fehler (Netzwerk: <code>ECONNRESET</code>, <code>ETIMEDOUT</code>, etc.) werden als Warnung/Trace-Event erfasst, markieren den Job aber nicht als <code>failed</code>. Sp\u00e4tere erfolgreiche Callbacks k\u00f6nnen den Job normal abschlie\u00dfen.</p> <ul> <li>Pro: Verhindert \u201eJob endet zu fr\u00fch\u201c und verbessert die Diagnosef\u00e4higkeit.</li> <li>Contra: Erfordert eine pragmatische Heuristik zur Erkennung transienter Fehler; in Grenzf\u00e4llen bleibt Interpretation n\u00f6tig.</li> </ul>"},{"location":"analysis/trace-timeline-postprocessing-elimination.html#variante-c-strukturell-neues-statusmodell","title":"Variante C \u2013 Strukturell (neues Statusmodell)","text":"<p>Ein zus\u00e4tzlicher Zustand wie <code>recovering</code> / <code>running-with-errors</code> oder ein eigener Retry\u2011State wird eingef\u00fchrt; Finalit\u00e4t wird erst nach definierter Retry-Policy gesetzt.</p> <ul> <li>Pro: Semantisch sauber.</li> <li>Contra: Gr\u00f6\u00dferer Umbau (API/UI/Tests), mehr Migrations- und Wartungsaufwand.</li> </ul>"},{"location":"analysis/trace-timeline-postprocessing-elimination.html#entscheidung-minimal-invasiv","title":"Entscheidung (minimal-invasiv)","text":"<p>Wir implementieren Variante B plus Instrumentierungs\u2011Bereinigung:</p> <ul> <li>Kein eigener <code>postprocessing</code>-Root\u2011Span f\u00fcr Persistenz. Persistenz-Events werden im korrekten Phase\u2011Span geloggt.</li> <li><code>extract_*</code> wird erst dann als <code>completed</code> markiert, wenn die lokale Persistenz (inkl. optionaler Bildverarbeitung) abgeschlossen ist.</li> <li>Transiente Fehler werden als <code>transient_error</code> geloggt, ohne den Job final auf <code>failed</code> zu setzen, damit sp\u00e4tere erfolgreiche Callbacks die Timeline korrekt beenden k\u00f6nnen.</li> </ul>"},{"location":"analysis/unified-pipeline-architecture.html","title":"Architektur: Einheitliche Pipeline f\u00fcr alle Formate","text":""},{"location":"analysis/unified-pipeline-architecture.html#ausgangslage","title":"Ausgangslage","text":"<p>Bisherige External-Job-Pipeline ist PDF-zentriert: - <code>findPdfMarkdown()</code> nutzt PDF-Annahmen (<code>${baseName}.pdf</code> als Fallback) - Step-Naming (<code>extract_pdf</code>) ist hardcoded - Template/Ingest-Preprocessor suchen prim\u00e4r Transformationen im Shadow-Twin-Kontext</p> <p>Problem: Jeder neue Dateityp (Audio, Markdown, Website, CSV, \u2026) erfordert ad-hoc Entscheidungen \u00fcber Phasen, Artefakt-Konventionen und Validierungsregeln.</p>"},{"location":"analysis/unified-pipeline-architecture.html#zielbild-variante-c","title":"Zielbild (Variante C)","text":""},{"location":"analysis/unified-pipeline-architecture.html#leitidee-canonical-markdown-als-gemeinsame-reprasentation","title":"Leitidee: Canonical Markdown als gemeinsame Repr\u00e4sentation","text":"<p>Jede Quelle wird zuerst in Canonical Markdown normalisiert, danach laufen f\u00fcr alle Quellen dieselben Phasen:</p> <pre><code>Source (PDF/Audio/MD/TXT/HTML/CSV/...)\n  \u2193\n[Normalize] \u2192 Canonical Markdown + Frontmatter + Raw Origin Ref\n  \u2193\n[Template] \u2192 Structured Markdown (Frontmatter validiert/erweitert)\n  \u2193\n[Ingest] \u2192 Vectors + Meta in MongoDB Vector Search\n</code></pre>"},{"location":"analysis/unified-pipeline-architecture.html#canonical-markdown-definition","title":"Canonical Markdown Definition","text":"<p>Minimum-Anforderungen (basierend auf User-Requirements):</p> <ul> <li>Text-only Normalisierung: Keine Asset-Downloads im Normalize-Schritt (Bilder bleiben Links/Refs)</li> <li>Frontmatter verpflichtend: Jedes Canonical Markdown muss Frontmatter enthalten:</li> <li><code>source</code>: Quelle (Dateiname, URL, etc.)</li> <li><code>title</code>: Titel (aus Quelle extrahiert oder generiert)</li> <li><code>date</code>: Datum/Crawl-Zeit</li> <li><code>type</code>: Format-Typ (<code>pdf</code>, <code>audio</code>, <code>markdown</code>, <code>txt</code>, <code>website</code>, <code>csv</code>, etc.)</li> <li><code>originRef</code>: Referenz auf Original-Rohdaten-Artefakt (lossless)</li> <li>Lossless Origin: Original-Rohdaten werden zus\u00e4tzlich als Artefakt gespeichert/verlinkt</li> </ul>"},{"location":"analysis/unified-pipeline-architecture.html#artefakt-typen-shadow-twin","title":"Artefakt-Typen (Shadow-Twin)","text":"<p>Wir unterscheiden drei Artefakt-Typen pro Quelle:</p> <ol> <li><code>canonical</code> (neu): Normalisiertes Markdown mit Frontmatter (Output von Normalize-Schritt)</li> <li><code>raw</code> (neu): Original-Rohdaten (HTML, CSV, TXT, etc.) als lossless Backup</li> <li><code>transformation</code> (bestehend): Template-transformiertes Markdown (Output von Template-Schritt)</li> <li><code>transcript</code> (bestehend): F\u00fcr Audio/PDF \u2013 Transcript-Markdown (wird zu <code>canonical</code> f\u00fcr Textquellen)</li> </ol> <p>Naming-Konvention: - <code>canonical</code>: <code>{sourceName}.canonical.{lang}.md</code> - <code>raw</code>: <code>{sourceName}.raw.{ext}</code> (z.B. <code>.html</code>, <code>.csv</code>, <code>.txt</code>) - <code>transformation</code>: <code>{sourceName}.{template}.{lang}.md</code> (wie bisher)</p>"},{"location":"analysis/unified-pipeline-architecture.html#source-adapter-interface","title":"Source Adapter Interface","text":"<p>Jede Quelle implementiert einen Source Adapter:</p> <pre><code>interface SourceAdapter {\n  /**\n   * Normalisiert die Quelle zu Canonical Markdown.\n   * \n   * @param source Source-Daten (StorageItem, URL, etc.)\n   * @returns Canonical Markdown + Meta + Raw Origin Referenz\n   */\n  normalize(source: SourceInput): Promise&lt;CanonicalMarkdownResult&gt;\n}\n\ninterface CanonicalMarkdownResult {\n  /** Normalisiertes Markdown mit Frontmatter */\n  canonicalMarkdown: string\n  /** Frontmatter-Metadaten */\n  canonicalMeta: Record&lt;string, unknown&gt;\n  /** Referenz auf gespeichertes Raw-Origin-Artefakt */\n  rawOriginRef?: { fileId: string; fileName: string }\n}\n</code></pre>"},{"location":"analysis/unified-pipeline-architecture.html#step-naming-external-jobs","title":"Step-Naming (External-Jobs)","text":"<p>Dynamisches Step-Naming basierend auf <code>job.job_type</code>:</p> <ul> <li><code>job_type: 'pdf'</code> \u2192 <code>extract_pdf</code></li> <li><code>job_type: 'audio'</code> \u2192 <code>extract_audio</code></li> <li><code>job_type: 'video'</code> \u2192 <code>extract_video</code></li> <li><code>job_type: 'text'</code> \u2192 <code>normalize_text</code> (neu, f\u00fcr Markdown/TXT)</li> <li><code>job_type: 'website'</code> \u2192 <code>normalize_website</code> (neu)</li> <li><code>job_type: 'csv'</code> \u2192 <code>normalize_csv</code> (neu)</li> </ul> <p>Template/Ingest Steps bleiben einheitlich (<code>template</code>, <code>ingest</code>).</p>"},{"location":"analysis/unified-pipeline-architecture.html#normalize-adapter-format-spezifisch","title":"Normalize-Adapter (Format-spezifisch)","text":""},{"location":"analysis/unified-pipeline-architecture.html#markdown-normalize_text","title":"Markdown (<code>normalize_text</code>)","text":"<ul> <li>Input: Markdown-Datei (<code>.md</code>, <code>.mdx</code>)</li> <li>Normalize:</li> <li>Trim Whitespace</li> <li>Frontmatter erzwingen (falls fehlt: generiere aus Dateiname/Datum)</li> <li>Body normalisieren (einheitliche Zeilenumbr\u00fcche)</li> <li>Raw Origin: Original-Markdown-Datei als <code>raw</code> Artefakt</li> </ul>"},{"location":"analysis/unified-pipeline-architecture.html#txt-normalize_text","title":"TXT (<code>normalize_text</code>)","text":"<ul> <li>Input: Plain-Text-Datei (<code>.txt</code>, <code>.log</code>)</li> <li>Normalize:</li> <li>Wrap Text in Markdown-Body</li> <li>Frontmatter generieren (Titel aus Dateiname, Datum, Typ)</li> <li>Raw Origin: Original-TXT-Datei als <code>raw</code> Artefakt</li> </ul>"},{"location":"analysis/unified-pipeline-architecture.html#website-normalize_website","title":"Website (<code>normalize_website</code>)","text":"<ul> <li>Input: URL oder HTML-Datei</li> <li>Normalize:</li> <li>Fetch HTML (falls URL)</li> <li>Boilerplate-Reduktion (Readability-Algorithmus)</li> <li>HTML \u2192 Markdown (z.B. via <code>turndown</code> oder Secretary Service)</li> <li>Frontmatter mit URL, <code>fetchedAt</code>, <code>title</code> (aus <code>&lt;title&gt;</code> oder Meta)</li> <li>Raw Origin: Original-HTML als <code>raw</code> Artefakt</li> <li>Bilder: Zun\u00e4chst nur Links/Refs; Asset-Download sp\u00e4ter als Add-on</li> </ul>"},{"location":"analysis/unified-pipeline-architecture.html#csv-normalize_csv","title":"CSV (<code>normalize_csv</code>)","text":"<ul> <li>Input: CSV/TSV-Datei</li> <li>Normalize:</li> <li>Parse CSV \u2192 Markdown-Tabellen</li> <li>Frontmatter mit Spalten-Info, Zeilenanzahl, Delimiter</li> <li>Raw Origin: Original-CSV-Datei als <code>raw</code> Artefakt</li> </ul>"},{"location":"analysis/unified-pipeline-architecture.html#preprocess-core-generalisierung","title":"Preprocess-Core Generalisierung","text":"<p>Aktuell: <code>findPdfMarkdown()</code> ist PDF-zentriert.</p> <p>Ziel: Generalisieren zu <code>findSourceMarkdown()</code>:</p> <pre><code>async function findSourceMarkdown(\n  provider: StorageProvider,\n  parentId: string,\n  sourceItemId: string,\n  sourceName: string,\n  lang: string,\n  library: Library,\n  options: FindSourceMarkdownOptions,\n  userEmail: string\n): Promise&lt;FoundMarkdown&gt; {\n  // 1) Shadow-Twin-Service-Pr\u00fcfung (wie bisher, aber ohne PDF-Annahmen)\n  // 2) Fallback: Provider-basierte Suche (ohne `${baseName}.pdf` Fallback)\n  // 3) Artefakt-Typ bestimmen (canonical/transformation/transcript) aus options.preferredKind\n}\n</code></pre>"},{"location":"analysis/unified-pipeline-architecture.html#validierungsregeln-einheitlich","title":"Validierungsregeln (einheitlich)","text":"<p>Globale Contracts (f\u00fcr alle Formate):</p> <ol> <li>Canonical Markdown non-empty: <code>canonicalMarkdown.trim().length &gt; 0</code></li> <li>Frontmatter required: <code>canonicalMeta</code> muss mindestens <code>source</code>, <code>title</code>, <code>date</code>, <code>type</code> enthalten</li> <li>Raw Origin exists: Wenn <code>rawOriginRef</code> gesetzt, muss das Artefakt existieren</li> <li>Template Output: Transformation erzeugt Markdown mit Frontmatter</li> <li>Ingest Vectors: <code>chunksUpserted &gt; 0</code> und Meta/Chunks in Vector Search</li> </ol> <p>Format-spezifische Validierung (optional):</p> <ul> <li>Markdown: Frontmatter-Syntax validieren</li> <li>Website: URL erreichbar, HTML parseable</li> <li>CSV: Delimiter erkannt, Spalten konsistent</li> </ul>"},{"location":"analysis/unified-pipeline-architecture.html#integrationstest-strategie","title":"Integrationstest-Strategie","text":"<p>Testcases pro Format:</p> <ul> <li>Jedes Format hat mindestens einen Happy-Path Testcase:</li> <li><code>{format}_normalize.happy_path</code>: Normalize \u2192 Canonical Markdown</li> <li><code>{format}_template.happy_path</code>: Template \u2192 Transformation</li> <li><code>{format}_ingest.happy_path</code>: Ingest \u2192 Vectors</li> </ul> <p>Alle Testcases pr\u00fcfen dieselben globalen Contracts (siehe oben).</p> <p>Format-spezifische Checks (optional): - Markdown: Frontmatter-Syntax - Website: URL-Erreichbarkeit, HTML\u2192MD Konvertierung - CSV: Tabellen-Struktur</p>"},{"location":"analysis/unified-pipeline-architecture.html#implementations-roadmap","title":"Implementations-Roadmap","text":"<ol> <li>\u2705 Docs-Update: Zielbild dokumentiert (dieses Dokument)</li> <li>\ud83d\udea7 Canonical Source Adapter Interface: Neue Abstraktion (<code>src/lib/external-jobs/sources/*</code>)</li> <li>\ud83d\udea7 Normalize f\u00fcr Markdown/TXT: Implementierung</li> <li>\ud83d\udea7 Normalize f\u00fcr Website: Implementierung</li> <li>\ud83d\udea7 Preprocess-Core Generalisierung: <code>findPdfMarkdown</code> \u2192 <code>findSourceMarkdown</code></li> <li>\ud83d\udea7 Integrationstests vereinheitlichen: Alle Formate testen dieselben Contracts</li> </ol>"},{"location":"analysis/unified-pipeline-architecture.html#trade-offs","title":"Trade-offs","text":"<p>Vorteile: - Einheitliche Pipeline f\u00fcr alle Formate - Keine ad-hoc Entscheidungen pro Format - Testbarkeit: Alle Formate testen dieselben Contracts - Erweiterbarkeit: Neues Format = neuer Normalize-Adapter</p> <p>Nachteile: - Gr\u00f6\u00dferer Umbau (mehr Regression-Risiko) - Normalize-Schritt f\u00fcr \"triviale\" Quellen (Markdown) kann Overhead sein - Raw-Origin-Speicherung erh\u00f6ht Storage-Anforderungen</p> <p>Mitigation: - Inkrementelle Implementierung (erst Markdown/TXT, dann Website) - Unit-Tests f\u00fcr jeden Normalize-Adapter - Integrationstests f\u00fcr Regression-Schutz</p>"},{"location":"analysis/unified-pipeline-architecture.html#referenzen","title":"Referenzen","text":"<ul> <li><code>docs/guides/integration-tests.md</code>: Integrationstest-Guide</li> <li><code>docs/analysis/markdown-processing-pipeline.md</code>: Markdown-spezifische Analyse</li> </ul>"},{"location":"analysis/wizard-and-jobs.html","title":"Wizard & External Jobs","text":""},{"location":"analysis/wizard-and-jobs.html#wizard-external-jobs-current-runtime","title":"Wizard &amp; External Jobs (current runtime)","text":"<p>Status: active Last verified: 2026-01-04  </p>"},{"location":"analysis/wizard-and-jobs.html#scope","title":"Scope","text":"<p>This document explains the current PDF wizard and external-jobs pipeline behavior. It focuses on the runtime contracts that must hold (so the UI does not need \u201cfixups\u201d).</p>"},{"location":"analysis/wizard-and-jobs.html#glossary","title":"Glossary","text":"<ul> <li>External Job: a server-side job document orchestrated by worker + routes.</li> <li>Start route: <code>POST /api/external/jobs/[jobId]/start</code></li> <li>Callback route: <code>POST /api/external/jobs/[jobId]</code> (webhook receiver)</li> <li>Extract-only: job runs extraction/transcript creation only.</li> <li>Template-only: job runs template transformation only (metadata/frontmatter).</li> <li>Publish (Wizard): human confirms and we write final frontmatter + ingestion.</li> </ul>"},{"location":"analysis/wizard-and-jobs.html#why-this-exists-key-principle","title":"Why this exists (key principle)","text":"<p>The UI must stay simple. It must not repair/guess results. So we enforce correctness centrally in server code and test it end-to-end.</p>"},{"location":"analysis/wizard-and-jobs.html#pipeline-overview-pdf","title":"Pipeline overview (PDF)","text":"<p>High level: - Worker triggers the start route. - Start route decides which phases to run via gates + policies. - Secretary Service does OCR/template and calls back. - Callback route orchestrates the remaining phases and stores artifacts.</p> <p>Canonical architecture reference: - <code>docs/architecture/pdf-transformation-phases.md</code></p>"},{"location":"analysis/wizard-and-jobs.html#contracts-must-always-hold","title":"Contracts (must always hold)","text":""},{"location":"analysis/wizard-and-jobs.html#contract-1-completed-resultsaveditemid-exists","title":"Contract 1: completed =&gt; result.savedItemId exists","text":"<p>If a job is <code>completed</code>, it must already have a persisted <code>result.savedItemId</code>. Otherwise polling clients can see <code>completed</code> with empty <code>result</code> (race condition).</p>"},{"location":"analysis/wizard-and-jobs.html#contract-2-saveditemid-points-to-the-correct-artifact-kind","title":"Contract 2: savedItemId points to the correct artifact kind","text":"<p>Stronger rule: - Template enabled =&gt; <code>savedItemId</code> must point to the transformation artifact (with frontmatter). - Extract-only =&gt; <code>savedItemId</code> must point to the transcript artifact.</p> <p>This is critical because transcript files typically do not have frontmatter. If <code>savedItemId</code> points to a transcript in a template job, the wizard preview and metadata will appear empty.</p> <p>Enforcement location: - <code>src/lib/external-jobs/complete.ts</code> (central contract enforcement)</p>"},{"location":"analysis/wizard-and-jobs.html#pdfanalyse-publish-contract-no-extra-final-markdown","title":"PDFAnalyse \u201cpublish contract\u201d (no extra final markdown)","text":"<p>Goal: - The canonical published document is the transformation markdown inside the Shadow-Twin:   - <code>.{PDF-Name}/{PDF-Stem}.pdfanalyse.{lang}.md</code></p> <p>Publish behavior: - Wizard overwrites that transformation file\u2019s frontmatter (body stays from transformation). - Wizard triggers ingestion (RAG) for that same file. - The wizard must not create an additional \u201cfinal\u201d markdown outside the Shadow-Twin.</p>"},{"location":"analysis/wizard-and-jobs.html#testing-strategy-how-we-catch-regressions","title":"Testing strategy (how we catch regressions)","text":"<ul> <li>Integration test validators assert:</li> <li>completed jobs have <code>result.savedItemId</code></li> <li><code>savedItemId</code> matches expected artifact kind for the job type</li> <li>template name matches when template jobs are configured</li> </ul> <p>Key files: - <code>src/lib/integration-tests/validators.ts</code> - <code>src/lib/integration-tests/test-cases.ts</code> - <code>src/lib/integration-tests/orchestrator.ts</code></p>"},{"location":"architecture/artifact-pipeline-v3-design.html","title":"Artifact pipeline v3 design","text":""},{"location":"architecture/artifact-pipeline-v3-design.html#ziel","title":"Ziel","text":"<p>Dieses Dokument beschreibt das technische Design der Artefakt\u2011zentrierten Pipeline (Variante 3), die:</p> <ul> <li>Secretary-only f\u00fcr Extraction/Transformation nutzt</li> <li>den bestehenden External-Jobs-Orchestrator (Strangler) wiederverwendet</li> <li>\u00fcber Artefakte + Gates/Policies idempotent und resumable ist</li> </ul> <p>V0 Fokus: PDF Mistral OCR inkl. Pages/Images (File\u2011Liste Single\u2011File).</p>"},{"location":"architecture/artifact-pipeline-v3-design.html#begriffe","title":"Begriffe","text":"<ul> <li>SourceRef: Referenz auf eine einzelne Quelle (Datei/URL) inkl. Identit\u00e4t (<code>itemId</code>, <code>parentId</code>, Name, MIME).</li> <li>SourceBundle: Sammlung mehrerer Quellen (Event) mit eigener stabiler Identit\u00e4t (<code>bundleId</code>).</li> <li>Artefakt: abgeleitete Datei im Shadow\u2011Twin (Extract/Transcript, Transformation, Assets/Refs).</li> <li>Template: Zielschema f\u00fcr Bericht (Markdown + Frontmatter), quelle\u2011agnostisch.</li> <li>Gates: pr\u00fcfen Artefakt-Existenz, um Phasen zu skippen.</li> <li>Policies: \u00fcberschreiben Gates (<code>force</code>) oder deaktivieren Phasen (<code>ignore</code>).</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#artefaktmodell-naming-storage","title":"Artefaktmodell (Naming + Storage)","text":""},{"location":"architecture/artifact-pipeline-v3-design.html#naming-kanonisch","title":"Naming (kanonisch)","text":"<ul> <li>Extract/Transcript: <code>{base}.{lang}.md</code></li> <li>Transformation: <code>{base}.{template}.{lang}.md</code></li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#storage","title":"Storage","text":"<ul> <li>Artefakte liegen im Shadow\u2011Twin. Zielbild: Dot\u2011Folder ist kanonisch (Write-Pfad). Siblings sind eine Legacy-Altlast und sollen nur noch im Read-Only Modus funktionieren (Resolver-Fallback).   Ein sp\u00e4terer Repair/Migration-Run verschiebt Sibling-Artefakte in den Dot\u2011Folder und eliminiert sie.</li> <li>Gro\u00dfe Bin\u00e4rdaten (Pages/Images ZIP) werden als URLs/Refs gehandhabt; optionaler Download/Spiegelung im Storage ist eine separate Optimierung.</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#phasenmodell","title":"Phasenmodell","text":""},{"location":"architecture/artifact-pipeline-v3-design.html#user-journey-story-creator","title":"User journey (Story Creator)","text":"<p>The UI entry point for single-file processing is the Story Creator (library page + dedicated route). It frames the pipeline in user terms:</p> <ol> <li>Text erzeugen (OCR/Extract or Transkription)</li> <li>Transformieren (template-based LLM structuring)</li> <li>Ver\u00f6ffentlichen (RAG ingestion/index)</li> </ol> <p>Internally this maps 1:1 to the technical phases below.</p>"},{"location":"architecture/artifact-pipeline-v3-design.html#phaseextract","title":"PhaseExtract","text":"<p>Input: <code>SourceRef</code>, <code>targetLanguage</code>, format-spezifische Optionen (z.B. <code>extractionMethod=mistral_ocr</code>).\\n Output: Extract/Transcript Artefakt + Asset\u2011Refs.</p>"},{"location":"architecture/artifact-pipeline-v3-design.html#phasetransformtemplate","title":"PhaseTransformTemplate","text":"<p>Input: ExtractedText/Korpus, <code>templateName</code>.\\n Output: Transformation Artefakt <code>{base}.{template}.{lang}.md</code> inkl. Frontmatter.</p>"},{"location":"architecture/artifact-pipeline-v3-design.html#phaseingestrag","title":"PhaseIngestRag","text":"<p>Input: Transformation Artefakt (bevorzugt), fallback auf Extract nur wenn kein Transform existiert.\\n Output: Mongo Vector Search (Meta + Chunks).</p>"},{"location":"architecture/artifact-pipeline-v3-design.html#gates-policies","title":"Gates &amp; Policies","text":""},{"location":"architecture/artifact-pipeline-v3-design.html#gateregeln-prinzip","title":"Gate\u2011Regeln (Prinzip)","text":"<ul> <li>Template\u2011Phase skip, wenn Transformation\u2011Artefakt existiert (und nicht <code>force</code>).</li> <li>Ingest\u2011Phase skip, wenn Ingest bereits existiert (und nicht <code>force</code>).</li> <li>Extract\u2011Phase skip, wenn Extract/Transcript oder Transformation bereits existiert (und nicht <code>force</code>).</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#policies","title":"Policies","text":"<ul> <li><code>ignore</code>: Phase nie ausf\u00fchren</li> <li><code>do</code>: ausf\u00fchren, wenn Gate nicht greift</li> <li><code>force</code>: ausf\u00fchren, auch wenn Gate greift</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#orchestrierung-strangler","title":"Orchestrierung (Strangler)","text":""},{"location":"architecture/artifact-pipeline-v3-design.html#komponenten","title":"Komponenten","text":"<ul> <li>Worker: External Jobs Worker</li> <li>Start: <code>/api/external/jobs/{jobId}/start</code></li> <li>Callback: <code>/api/external/jobs/{jobId}</code></li> <li>Phasenmodule: <code>phase-template</code>, <code>phase-ingest</code> (Extract startet Secretary und wird \u00fcber Callback finalisiert)</li> <li>UI Updates: SSE <code>/api/external/jobs/stream</code></li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#zustandsautomat-job","title":"Zustandsautomat (Job)","text":"<pre><code>stateDiagram-v2\n  [*] --&gt; queued\n  queued --&gt; running\n  running --&gt; completed\n  running --&gt; failed</code></pre>"},{"location":"architecture/artifact-pipeline-v3-design.html#datenfluss-high-level","title":"Datenfluss (High Level)","text":"<pre><code>flowchart TD\n  entry[UIEntryPoint] --&gt; createJob[CreateExternalJob]\n  createJob --&gt; worker[ExternalJobsWorker]\n  worker --&gt; startRoute[StartRoute]\n  startRoute --&gt; gateCheck[GateCheck]\n  gateCheck --&gt;|need_extract| secretary[SecretaryService]\n  secretary --&gt; callback[CallbackRoute]\n  callback --&gt; saveExtract[SaveExtractArtifact]\n  saveExtract --&gt; template[TemplatePhase]\n  template --&gt; saveTransform[SaveTransformArtifact]\n  saveTransform --&gt; ingest[IngestPhase]\n  ingest --&gt; mongo[MongoVectorSearch]\n  callback --&gt; sse[SSE_job_update]\n  sse --&gt; ui[UIProgressAndResult]</code></pre>"},{"location":"architecture/artifact-pipeline-v3-design.html#v0-pdf-mistral-ocr-pagesimages-design-notes","title":"V0 (PDF Mistral OCR + Pages/Images) \u2013 Design Notes","text":""},{"location":"architecture/artifact-pipeline-v3-design.html#input","title":"Input","text":"<ul> <li><code>extractionMethod=mistral_ocr</code></li> <li><code>includePageImages=true</code>, <code>includeOcrImages=true</code></li> <li><code>templateName</code> (Name-only)</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#output-contracts","title":"Output Contracts","text":"<ul> <li>Extract Artefakt <code>{base}.{lang}.md</code> enth\u00e4lt den OCR\u2011Markdown/Text (frontmatter optional).</li> <li>Transformation Artefakt <code>{base}.{template}.{lang}.md</code> enth\u00e4lt Frontmatter inkl. <code>template</code>, <code>target_language</code>, <code>source_file(_id)</code>, <code>pages</code>, <code>chapters</code> (oder begr\u00fcndeter Fallback).</li> <li>Asset\u2011Refs: <code>pages_archive_url</code>/<code>images_archive_url</code> (oder \u00e4quivalente Felder).</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#entrypoints-mapping","title":"Entry\u2011Points (Mapping)","text":""},{"location":"architecture/artifact-pipeline-v3-design.html#fileliste-archivpro","title":"File\u2011Liste (Archiv\u2011Pro)","text":"<ul> <li>Startet exakt 1 Job pro Datei.</li> <li>Ergebnis: Artefakt wird selektiert/\u00f6ffnbar nach <code>completed</code>.</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#batchverzeichnis-archivpro","title":"Batch/Verzeichnis (Archiv\u2011Pro)","text":"<ul> <li>Erzeugt N Jobs (optional mit <code>batchId/batchName</code>).</li> <li>Monitoring \u00fcber Job Monitor Panel + SSE.</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#wizard-wizarduser","title":"Wizard (Wizard\u2011User)","text":"<ul> <li>Startet Job und subscribed SSE.</li> <li>Preview/Save basiert auf Transformation\u2011Artefakt.</li> </ul>"},{"location":"architecture/artifact-pipeline-v3-design.html#automation","title":"Automation","text":"<ul> <li>Job erstellen + Polling/Webhook, result refs konsumieren.</li> </ul>"},{"location":"architecture/dependency-graph.html","title":"Dependency Graph","text":"<p>Visual representation of module dependencies in the Common Knowledge Scout application.</p>"},{"location":"architecture/dependency-graph.html#mermaid-dependency-graph","title":"Mermaid Dependency Graph","text":"<pre><code>graph TB\n    subgraph \"Layer 1: Core Infrastructure\"\n        MW[middleware.ts]\n        LAYOUT[app/layout.tsx]\n        INST[instrumentation.ts]\n        ENV[lib/env.ts]\n        AUTH[lib/auth.ts]\n        DB[lib/mongodb-service.ts]\n    end\n\n    subgraph \"Layer 2: Storage Layer\"\n        STYPES[lib/storage/types.ts]\n        SFACTORY[lib/storage/storage-factory.ts]\n        FSPROVIDER[lib/storage/filesystem-provider.ts]\n        ODPROVIDER[lib/storage/onedrive-provider.ts]\n        SERVERPROV[lib/storage/server-provider.ts]\n        SCONTEXT[contexts/storage-context.tsx]\n        USEPROV[hooks/use-storage-provider.tsx]\n    end\n\n    subgraph \"Layer 3: Library System\"\n        LTYPES[types/library.ts]\n        LATOMS[atoms/library-atom.ts]\n        LSERVICE[lib/services/library-service.ts]\n        LIBCOMP[components/library/library.tsx]\n    end\n\n    subgraph \"Layer 4: Chat System\"\n        CTYPES[types/chat.ts]\n        CCONST[lib/chat/constants.ts]\n        CORCH[lib/chat/orchestrator.ts]\n        CLOADER[lib/chat/loader.ts]\n        CSTREAM[app/api/chat/.../stream/route.ts]\n    end\n\n    subgraph \"Layer 5: API Routes &amp; Components\"\n        APIROUTES[app/api/**/*.ts]\n        COMPONENTS[components/**/*.tsx]\n    end\n\n    %% Core Infrastructure (no dependencies)\n\n    %% Storage Layer dependencies\n    SFACTORY --&gt; STYPES\n    SFACTORY --&gt; FSPROVIDER\n    SFACTORY --&gt; ODPROVIDER\n    FSPROVIDER --&gt; STYPES\n    ODPROVIDER --&gt; STYPES\n    ODPROVIDER --&gt; LTYPES\n    SERVERPROV --&gt; SFACTORY\n    SERVERPROV --&gt; LSERVICE\n    SERVERPROV --&gt; ENV\n    SCONTEXT --&gt; SFACTORY\n    SCONTEXT --&gt; LATOMS\n    USEPROV --&gt; LATOMS\n    USEPROV --&gt; SFACTORY\n\n    %% Library System dependencies\n    LATOMS --&gt; LTYPES\n    LATOMS --&gt; STYPES\n    LSERVICE --&gt; DB\n    LSERVICE --&gt; LTYPES\n    LIBCOMP --&gt; SCONTEXT\n    LIBCOMP --&gt; LATOMS\n\n    %% Chat System dependencies\n    CORCH --&gt; CLOADER\n    CORCH --&gt; CCONST\n    CORCH --&gt; CTYPES\n    CLOADER --&gt; LSERVICE\n    CLOADER --&gt; DB\n    CSTREAM --&gt; CORCH\n    CSTREAM --&gt; CLOADER\n    CSTREAM --&gt; CCONST\n\n    %% API Routes dependencies\n    APIROUTES --&gt; LSERVICE\n    APIROUTES --&gt; SFACTORY\n    APIROUTES --&gt; DB\n    APIROUTES --&gt; CORCH\n\n    %% Components dependencies\n    COMPONENTS --&gt; SCONTEXT\n    COMPONENTS --&gt; LATOMS\n    COMPONENTS --&gt; LIBCOMP</code></pre>"},{"location":"architecture/dependency-graph.html#dependency-layers","title":"Dependency Layers","text":""},{"location":"architecture/dependency-graph.html#layer-1-core-infrastructure","title":"Layer 1: Core Infrastructure","text":"<ul> <li>No internal dependencies</li> <li>Provides foundational services (auth, database, env)</li> <li>Used by all other layers</li> </ul>"},{"location":"architecture/dependency-graph.html#layer-2-storage-layer","title":"Layer 2: Storage Layer","text":"<ul> <li>Depends on: Layer 1 (env, auth, db)</li> <li>Provides: Storage abstraction</li> <li>Used by: Layer 3 (Library System), Layer 5 (API Routes)</li> </ul>"},{"location":"architecture/dependency-graph.html#layer-3-library-system","title":"Layer 3: Library System","text":"<ul> <li>Depends on: Layer 2 (Storage Layer)</li> <li>Provides: Library management and UI</li> <li>Used by: Layer 4 (Chat System), Layer 5 (Components)</li> </ul>"},{"location":"architecture/dependency-graph.html#layer-4-chat-system","title":"Layer 4: Chat System","text":"<ul> <li>Depends on: Layer 3 (Library System), Layer 2 (Storage)</li> <li>Provides: RAG-based chat functionality</li> <li>Used by: Layer 5 (API Routes, Components)</li> </ul>"},{"location":"architecture/dependency-graph.html#layer-5-api-routes-components","title":"Layer 5: API Routes &amp; Components","text":"<ul> <li>Depends on: All previous layers</li> <li>Provides: User-facing interfaces</li> <li>No dependencies from other modules</li> </ul>"},{"location":"architecture/dependency-graph.html#key-dependencies","title":"Key Dependencies","text":""},{"location":"architecture/dependency-graph.html#most-imported-modules","title":"Most Imported Modules","text":"<ol> <li><code>@/lib/storage/storage-factory.ts</code> - Used by contexts, API routes, components</li> <li><code>@/lib/storage/types.ts</code> - Used by all storage-related files</li> <li><code>@/lib/services/library-service.ts</code> - Used by API routes, storage, chat</li> <li><code>@/types/library.ts</code> - Used throughout the application</li> <li><code>@/lib/mongodb-service.ts</code> - Used by services and repositories</li> </ol>"},{"location":"architecture/dependency-graph.html#critical-paths","title":"Critical Paths","text":"<ul> <li>Storage Access: <code>components</code> \u2192 <code>contexts/storage-context</code> \u2192 <code>storage-factory</code> \u2192 <code>providers</code></li> <li>Chat Flow: <code>api/chat/stream</code> \u2192 <code>chat/orchestrator</code> \u2192 <code>chat/loader</code> \u2192 <code>library-service</code> \u2192 <code>mongodb-service</code></li> <li>Library Management: <code>components/library</code> \u2192 <code>atoms/library-atom</code> \u2192 <code>services/library-service</code> \u2192 <code>mongodb-service</code></li> </ul>"},{"location":"architecture/dependency-graph.html#circular-dependencies","title":"Circular Dependencies","text":""},{"location":"architecture/dependency-graph.html#potential-issues-to-verify","title":"Potential Issues (To Verify)","text":"<ol> <li>Storage Factory \u2194 Providers: Factory creates providers, providers may reference factory</li> <li>Library Service \u2194 Storage Factory: Service uses storage, storage may reference library types</li> <li>Chat Orchestrator \u2194 Chat Loader: Orchestrator uses loader, loader may use orchestrator utilities</li> </ol>"},{"location":"architecture/dependency-graph.html#notes","title":"Notes","text":"<ul> <li>Dependencies flow downward (Layer 1 \u2192 Layer 5)</li> <li>Each layer can only depend on layers below it</li> <li>Type definitions (types/) have no runtime dependencies</li> <li>Components depend on hooks, contexts, and library code</li> <li>API routes depend on services, storage, and chat systems</li> </ul>"},{"location":"architecture/finalize-wizard-requirements.html","title":"Finalize-Wizard: Anforderungen","text":""},{"location":"architecture/finalize-wizard-requirements.html#wichtige-anforderungen","title":"Wichtige Anforderungen","text":""},{"location":"architecture/finalize-wizard-requirements.html#1-index-swap-nicht-datei-ersetzung","title":"1. Index-Swap (nicht Datei-Ersetzung)","text":"<p>Was passiert: - \u2705 Der urspr\u00fcngliche Event wird im MongoDB-Index ersetzt (nicht die Datei im Storage) - \u2705 Final-Datei wird mit demselben <code>slug</code> ingestiert - \u2705 Original-Datei bleibt im Storage erhalten - \u2705 Original wird aus Index gel\u00f6scht (nur Vektoren/Metadaten)</p> <p>Zweck: - Explorer/Gallery zeigt Final-Version (gleicher \"Platz\") - Original bleibt f\u00fcr Nachvollziehbarkeit erhalten</p>"},{"location":"architecture/finalize-wizard-requirements.html#2-status-anderung","title":"2. Status-\u00c4nderung","text":"<p>Status-\u00dcberg\u00e4nge: - <code>eventStatus: 'open'</code> \u2192 <code>'closed'</code> (beim Finalisieren) - <code>eventStatus: 'finalDraft'</code> \u2192 <code>'finalPublished'</code> (beim Publizieren)</p> <p>Zweck: - Klare Unterscheidung zwischen offenem Event und finalisiertem Event - UI kann Status anzeigen (z.B. \"Event abgeschlossen\")</p>"},{"location":"architecture/finalize-wizard-requirements.html#3-wiederholte-finalisierungen","title":"3. Wiederholte Finalisierungen","text":"<p>Problem: - Bei wiederholten Finalisierungen w\u00fcrden vorherige Final-Dateien als Quellen verwendet werden - Das f\u00fchrt zu Duplikaten und falschen Zusammenf\u00fchrungen</p> <p>L\u00f6sung: - \u2705 Nur urspr\u00fcnglicher Event wird als Haupt-Quelle verwendet - \u2705 Nur Testimonials werden als zus\u00e4tzliche Quellen verwendet - \u2705 <code>finals/</code> Ordner wird ignoriert (Namenskonvention) - \u2705 Bei Index-Swap wird immer derselbe Eintrag \u00fcberschrieben (gleicher <code>slug</code>)</p> <p>Namenskonvention: <pre><code>events/&lt;eventSlug&gt;/\n  event.md                    \u2190 Haupt-Quelle (wird verwendet)\n  testimonials/               \u2190 Zus\u00e4tzliche Quellen (werden verwendet)\n    &lt;testimonialId&gt;/\n      ...\n  finals/                     \u2190 WIRD IGNORIERT (nicht als Quelle verwendet)\n    run-&lt;timestamp&gt;/\n      event-final.md\n</code></pre></p>"},{"location":"architecture/finalize-wizard-requirements.html#4-determinismus-durch-defaults","title":"4. Determinismus durch Defaults","text":"<p>Wizard-Verhalten: 1. \u2705 Automatisch alle Testimonials finden (aus <code>testimonials/</code> Ordner) 2. \u2705 Automatisch alle ausw\u00e4hlen (Default) 3. \u2705 Automatisch Transformation generieren (wenn Template LLM verwendet) 4. \u2705 User kann optional anpassen (aber muss nicht)</p> <p>Zweck: - Einfachheit f\u00fcr Standard-Fall (ein Klick \u2192 fertig) - Flexibilit\u00e4t f\u00fcr Spezial-F\u00e4lle (User kann anpassen)</p>"},{"location":"architecture/finalize-wizard-requirements.html#technische-umsetzung","title":"Technische Umsetzung","text":""},{"location":"architecture/finalize-wizard-requirements.html#discovery-logik","title":"Discovery-Logik","text":"<pre><code>async function discoverFolderArtifacts(\n  provider: StorageProvider,\n  folderId: string\n): Promise&lt;FolderArtifact[]&gt; {\n  const items = await provider.listItemsById(folderId)\n\n  // 1. Finde Haupt-Artefakt (Event-Markdown)\n  // IGNORIERE: Dateien in `finals/` Unterordnern\n  const mainArtifact = items.find(\n    it =&gt; it.type === 'file' &amp;&amp; \n    it.metadata?.name?.endsWith('.md') &amp;&amp;\n    !it.metadata?.name?.includes('final') &amp;&amp;\n    !it.parentId?.includes('finals')\n  )\n\n  // 2. Finde Testimonials (aus testimonials/ Ordner)\n  const testimonialsFolder = items.find(\n    it =&gt; it.type === 'folder' &amp;&amp; it.metadata?.name === 'testimonials'\n  )\n\n  // 3. IGNORIERE: finals/ Ordner komplett\n  // (wird nicht als Quelle verwendet)\n\n  return artifacts\n}\n</code></pre>"},{"location":"architecture/finalize-wizard-requirements.html#index-swap-logik","title":"Index-Swap-Logik","text":"<pre><code>async function publishFinal(\n  finalFileId: string,\n  originalFileId: string,\n  slug: string\n) {\n  // 1. Final ingestieren (mit gleichem slug)\n  await IngestionService.upsertMarkdown(\n    userEmail,\n    libraryId,\n    finalFileId,\n    fileName,\n    markdown,\n    { \n      docType: 'event',\n      slug, // Gleicher slug wie Original\n      eventStatus: 'closed' // Status \u00e4ndern\n    }\n  )\n\n  // 2. Original aus Index l\u00f6schen (nur Vektoren, nicht Datei)\n  await deleteVectorsByFileId(libraryKey, originalFileId)\n\n  // WICHTIG: Bei wiederholten Publizierungen wird derselbe Eintrag \u00fcberschrieben\n  // (gleicher slug = Update statt Duplikat)\n}\n</code></pre>"},{"location":"architecture/finalize-wizard-requirements.html#status-management","title":"Status-Management","text":"<p>Frontmatter im Final: <pre><code>---\neventStatus: closed  # Beim Finalisieren\noriginalFileId: &lt;eventFileId&gt;  # Referenz auf Original\nslug: &lt;originalSlug&gt;  # Gleicher slug wie Original\n---\n</code></pre></p> <p>Nach Publizieren: - Index-Eintrag hat <code>eventStatus: 'closed'</code> - Original-Datei bleibt mit <code>eventStatus: 'open'</code> (im Storage)</p>"},{"location":"architecture/finalize-wizard-requirements.html#migration","title":"Migration","text":""},{"location":"architecture/finalize-wizard-requirements.html#bestehende-final-dateien","title":"Bestehende Final-Dateien","text":"<ul> <li>Werden nicht als Quellen verwendet (werden ignoriert)</li> <li>K\u00f6nnen als \"Resume\" ge\u00f6ffnet werden (direkt publizieren)</li> <li>Werden beim n\u00e4chsten Finalisieren \u00fcberschrieben (gleicher slug)</li> </ul>"},{"location":"architecture/finalize-wizard-requirements.html#neue-final-dateien","title":"Neue Final-Dateien","text":"<ul> <li>Werden in <code>finals/run-&lt;timestamp&gt;/</code> gespeichert</li> <li>Werden beim n\u00e4chsten Finalisieren ignoriert</li> <li>Nur eine Final-Datei wird im Index sein (mit <code>slug</code>)</li> </ul>"},{"location":"architecture/finalize-wizard-requirements.html#vorteile","title":"Vorteile","text":"<ol> <li>\u2705 Deterministisch: Immer gleiche Quellen (Event + Testimonials)</li> <li>\u2705 Keine Duplikate: Vorherige Final-Dateien werden ignoriert</li> <li>\u2705 Einfach: User muss nichts wissen (Defaults)</li> <li>\u2705 Flexibel: User kann optional anpassen</li> <li>\u2705 Konsistent: Gleicher slug = Update statt Duplikat</li> </ol>"},{"location":"architecture/generic-finalize-wizard.html","title":"Generischer Finalize/Publish-Wizard","text":""},{"location":"architecture/generic-finalize-wizard.html#ziel","title":"Ziel","text":"<p>Ein generischer Wizard, der Inhalte eines Verzeichnisses zusammenf\u00fchrt, transformiert und publiziert. Nicht Event-spezifisch, sondern f\u00fcr beliebige Verzeichnisse mit Artefakten.</p>"},{"location":"architecture/generic-finalize-wizard.html#konzept","title":"Konzept","text":""},{"location":"architecture/generic-finalize-wizard.html#grundidee","title":"Grundidee","text":"<p>Ein Verzeichnis enth\u00e4lt: - Haupt-Artefakt (z.B. Event-Markdown) - Zus\u00e4tzliche Artefakte (z.B. Testimonial-Transcripte) - Alle werden chronologisch zusammengef\u00fchrt und mit einem Template transformiert</p>"},{"location":"architecture/generic-finalize-wizard.html#unterschied-zu-creation-wizard","title":"Unterschied zu Creation-Wizard","text":"Aspekt Creation-Wizard Finalize-Wizard Input Externe Quelle (Text/URL/PDF) Verzeichnis mit Artefakten Ziel Neues Artefakt erstellen Bestehende Artefakte zusammenf\u00fchren Transformation Template-basiert Template-basiert (gleiche Logik) Publish Optional (am Ende) Immer (letzter Schritt)"},{"location":"architecture/generic-finalize-wizard.html#wizard-flow","title":"Wizard-Flow","text":""},{"location":"architecture/generic-finalize-wizard.html#schritt-1-welcome","title":"Schritt 1: Welcome","text":"<ul> <li>Willkommensnachricht</li> <li>Erkl\u00e4rt, was zusammengef\u00fchrt wird</li> </ul>"},{"location":"architecture/generic-finalize-wizard.html#schritt-2-quellen-auswahlen","title":"Schritt 2: Quellen ausw\u00e4hlen","text":"<ul> <li>Zeigt alle Artefakte im Verzeichnis</li> <li>User kann ausw\u00e4hlen, welche verwendet werden sollen</li> <li>Chronologische Sortierung (nach <code>createdAt</code> oder Dateiname)</li> </ul>"},{"location":"architecture/generic-finalize-wizard.html#schritt-3-transformation-generieren","title":"Schritt 3: Transformation generieren","text":"<ul> <li>L\u00e4dt Template</li> <li>Sammelt alle ausgew\u00e4hlten Artefakte</li> <li>Sendet an Secretary Service f\u00fcr Transformation</li> <li>Erzeugt finales Markdown mit Frontmatter</li> </ul>"},{"location":"architecture/generic-finalize-wizard.html#schritt-4-reviewedit","title":"Schritt 4: Review/Edit","text":"<ul> <li>Zeigt generiertes Markdown</li> <li>User kann Frontmatter-Felder bearbeiten</li> <li>User kann Body bearbeiten</li> </ul>"},{"location":"architecture/generic-finalize-wizard.html#schritt-5-preview","title":"Schritt 5: Preview","text":"<ul> <li>Zeigt Vorschau der finalen Seite</li> <li>Verwendet <code>detailViewType</code> aus Template</li> </ul>"},{"location":"architecture/generic-finalize-wizard.html#schritt-6-publish","title":"Schritt 6: Publish","text":"<ul> <li>Speichert finales Artefakt</li> <li>F\u00fchrt Index-Swap durch (falls Original vorhanden)</li> <li>Ingestion ins RAG-System</li> </ul>"},{"location":"architecture/generic-finalize-wizard.html#technische-umsetzung","title":"Technische Umsetzung","text":""},{"location":"architecture/generic-finalize-wizard.html#generische-verzeichnis-discovery","title":"Generische Verzeichnis-Discovery","text":"<pre><code>interface FolderArtifact {\n  fileId: string\n  fileName: string\n  createdAt: string\n  type: 'main' | 'testimonial' | 'other'\n  content: string // Markdown-Body\n  metadata: Record&lt;string, unknown&gt; // Frontmatter\n}\n\nasync function discoverFolderArtifacts(\n  provider: StorageProvider,\n  folderId: string\n): Promise&lt;FolderArtifact[]&gt; {\n  // 1. Finde Haupt-Artefakt (z.B. Event-Markdown)\n  // 2. Finde zus\u00e4tzliche Artefakte (z.B. Testimonial-Transcripte)\n  // 3. Sortiere chronologisch\n  // 4. Parse Frontmatter + Body\n}\n</code></pre>"},{"location":"architecture/generic-finalize-wizard.html#template-transformation","title":"Template-Transformation","text":"<ul> <li>Verwendet bestehende <code>runTemplatePhase</code> Logik</li> <li>Input: Array von Artefakten (Haupt + zus\u00e4tzliche)</li> <li>Output: Finales Markdown mit Frontmatter</li> </ul>"},{"location":"architecture/generic-finalize-wizard.html#publish-logik","title":"Publish-Logik","text":"<ul> <li>Verwendet bestehende Shadow-Twin-Logik</li> <li>Index-Swap: Final ingestieren, Original aus Index entfernen</li> <li>Job-Worker f\u00fcr asynchrone Verarbeitung</li> </ul>"},{"location":"architecture/generic-finalize-wizard.html#migration-von-event-spezifischer-logik","title":"Migration von Event-spezifischer Logik","text":""},{"location":"architecture/generic-finalize-wizard.html#aktuelle-event-spezifische-endpunkte","title":"Aktuelle Event-spezifische Endpunkte","text":"<ol> <li><code>/api/library/[libraryId]/events/finalize</code> \u2192 Wird zu generischem Wizard</li> <li><code>/api/library/[libraryId]/events/publish-final</code> \u2192 Wird zu generischem Publish-Step</li> </ol>"},{"location":"architecture/generic-finalize-wizard.html#neue-generische-struktur","title":"Neue generische Struktur","text":"<pre><code>/api/wizard/finalize\n  - POST: Startet Wizard-Session\n  - GET: L\u00e4dt Wizard-Status\n\n/api/wizard/finalize/[sessionId]/transform\n  - POST: Startet Transformation (Secretary Service)\n\n/api/wizard/finalize/[sessionId]/publish\n  - POST: Publiziert finales Artefakt (Index-Swap)\n</code></pre>"},{"location":"architecture/generic-finalize-wizard.html#template-struktur","title":"Template-Struktur","text":""},{"location":"architecture/generic-finalize-wizard.html#beispiel-event-finalize-demd","title":"Beispiel: <code>event-finalize-de.md</code>","text":"<pre><code>---\ntitle: {{title|Titel des finalen Events}}\nteaser: {{teaser|Kurz\u00fcberblick}}\n\ncreation:\n  supportedSources:\n    - id: folder\n      type: folder\n      label: \"Verzeichnis mit Artefakten\"\n  flow:\n    steps:\n      - id: Welcome\n        preset: welcome\n      - id: Select\n        preset: selectRelatedArtifacts  # Generisch!\n      - id: Generate\n        preset: generateDraft\n      - id: Review\n        preset: editDraft\n      - id: Preview\n        preset: previewDetail\n      - id: Publish\n        preset: publish  # Immer am Ende\n---\n</code></pre>"},{"location":"architecture/generic-finalize-wizard.html#vorteile-der-generischen-losung","title":"Vorteile der generischen L\u00f6sung","text":"<ol> <li>Wiederverwendbar: Funktioniert f\u00fcr Events, Dialogr\u00e4ume, etc.</li> <li>Konsistent: Gleiche Logik wie Creation-Wizard</li> <li>Erweiterbar: Neue Artefakt-Typen einfach hinzuf\u00fcgbar</li> <li>Testbar: Einheitliche Test-Strategie</li> </ol>"},{"location":"architecture/generic-finalize-wizard.html#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ol> <li>\u2705 Generische <code>discoverFolderArtifacts</code> Funktion erstellen</li> <li>\u2705 <code>selectRelatedArtifacts</code> Step erstellen (generisch)</li> <li>\u2705 Transformation-Logik anpassen (mehrere Artefakte als Input)</li> <li>\u2705 Publish-Step integrieren (wie Creation-Wizard)</li> <li>\u2705 Event-spezifische Endpunkte entfernen</li> <li>\u2705 Template <code>event-publish-final-de.md</code> entfernen</li> </ol>"},{"location":"architecture/module-hierarchy.html","title":"Module Hierarchy","text":"<p>Visual representation of the Common Knowledge Scout module organization and dependencies.</p>"},{"location":"architecture/module-hierarchy.html#module-tree","title":"Module Tree","text":"<pre><code>Common Knowledge Scout\n\u2502\n\u251c\u2500\u2500 Core Infrastructure (Layer 1)\n\u2502   \u251c\u2500\u2500 middleware.ts\n\u2502   \u2502   \u2514\u2500\u2500 Authentication &amp; Routing\n\u2502   \u251c\u2500\u2500 app/layout.tsx\n\u2502   \u2502   \u2514\u2500\u2500 Root Layout &amp; Providers\n\u2502   \u251c\u2500\u2500 instrumentation.ts\n\u2502   \u2502   \u2514\u2500\u2500 External Jobs Worker Startup\n\u2502   \u2514\u2500\u2500 lib/\n\u2502       \u251c\u2500\u2500 env.ts\n\u2502       \u2502   \u2514\u2500\u2500 Environment Variables\n\u2502       \u251c\u2500\u2500 auth.ts\n\u2502       \u2502   \u2514\u2500\u2500 Authentication Helpers\n\u2502       \u2514\u2500\u2500 mongodb-service.ts\n\u2502           \u2514\u2500\u2500 Database Connection\n\u2502\n\u251c\u2500\u2500 Storage Layer (Layer 2)\n\u2502   \u251c\u2500\u2500 lib/storage/\n\u2502   \u2502   \u251c\u2500\u2500 types.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Type Definitions\n\u2502   \u2502   \u251c\u2500\u2500 storage-factory.ts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 LocalStorageProvider\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 StorageFactory\n\u2502   \u2502   \u251c\u2500\u2500 filesystem-provider.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 FileSystemProvider\n\u2502   \u2502   \u251c\u2500\u2500 onedrive-provider.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 OneDriveProvider\n\u2502   \u2502   \u251c\u2500\u2500 onedrive-provider-server.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 OneDriveServerProvider\n\u2502   \u2502   \u251c\u2500\u2500 filesystem-client.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 FilesystemClient\n\u2502   \u2502   \u251c\u2500\u2500 server-provider.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Server Provider Helper\n\u2502   \u2502   \u251c\u2500\u2500 storage-factory-mongodb.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 MongoDBStorageFactory\n\u2502   \u2502   \u251c\u2500\u2500 storage-service.ts\n\u2502   \u2502   \u251c\u2500\u2500 shadow-twin.ts\n\u2502   \u2502   \u2514\u2500\u2500 supported-types.ts\n\u2502   \u251c\u2500\u2500 contexts/storage-context.tsx\n\u2502   \u2502   \u2514\u2500\u2500 StorageContextProvider\n\u2502   \u2514\u2500\u2500 hooks/use-storage-provider.tsx\n\u2502       \u2514\u2500\u2500 useStorageProvider Hook\n\u2502\n\u251c\u2500\u2500 Library System (Layer 3)\n\u2502   \u251c\u2500\u2500 types/library.ts\n\u2502   \u2502   \u2514\u2500\u2500 Library Type Definitions\n\u2502   \u251c\u2500\u2500 atoms/library-atom.ts\n\u2502   \u2502   \u2514\u2500\u2500 Library State Atoms\n\u2502   \u251c\u2500\u2500 lib/services/library-service.ts\n\u2502   \u2502   \u2514\u2500\u2500 LibraryService\n\u2502   \u2514\u2500\u2500 components/library/\n\u2502       \u251c\u2500\u2500 library.tsx\n\u2502       \u2502   \u2514\u2500\u2500 Main Library Component\n\u2502       \u251c\u2500\u2500 library-header.tsx\n\u2502       \u251c\u2500\u2500 library-switcher.tsx\n\u2502       \u251c\u2500\u2500 file-tree.tsx\n\u2502       \u251c\u2500\u2500 file-list.tsx\n\u2502       \u251c\u2500\u2500 file-preview.tsx\n\u2502       \u2514\u2500\u2500 ... (other library components)\n\u2502\n\u251c\u2500\u2500 Chat System (Layer 4)\n\u2502   \u251c\u2500\u2500 types/chat.ts\n\u2502   \u2502   \u2514\u2500\u2500 Chat Type Definitions\n\u2502   \u251c\u2500\u2500 lib/chat/\n\u2502   \u2502   \u251c\u2500\u2500 constants.ts\n\u2502   \u2502   \u251c\u2500\u2500 orchestrator.ts\n\u2502   \u2502   \u251c\u2500\u2500 loader.ts\n\u2502   \u2502   \u251c\u2500\u2500 config.ts\n\u2502   \u2502   \u251c\u2500\u2500 common/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prompt.ts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 filters.ts\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 llm.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 question-analyzer.ts\n\u2502   \u2502   \u2514\u2500\u2500 retrievers/\n\u2502   \u2502       \u251c\u2500\u2500 chunks.ts\n\u2502   \u2502       \u2514\u2500\u2500 summaries-mongo.ts\n\u2502   \u251c\u2500\u2500 app/api/chat/[libraryId]/\n\u2502   \u2502   \u2514\u2500\u2500 stream/route.ts\n\u2502   \u2514\u2500\u2500 components/library/chat/\n\u2502       \u2514\u2500\u2500 ... (chat components)\n\u2502\n\u2514\u2500\u2500 API Routes &amp; Components (Layer 5)\n    \u251c\u2500\u2500 app/api/\n    \u2502   \u251c\u2500\u2500 storage/\n    \u2502   \u251c\u2500\u2500 chat/\n    \u2502   \u251c\u2500\u2500 libraries/\n    \u2502   \u251c\u2500\u2500 external/jobs/\n    \u2502   \u2514\u2500\u2500 ... (other API routes)\n    \u2514\u2500\u2500 components/\n        \u251c\u2500\u2500 ui/ (Shadcn UI components)\n        \u251c\u2500\u2500 shared/\n        \u2514\u2500\u2500 ... (other components)\n</code></pre>"},{"location":"architecture/module-hierarchy.html#dependency-flow","title":"Dependency Flow","text":"<pre><code>Layer 1 (Core Infrastructure)\n    \u2193\nLayer 2 (Storage Layer)\n    \u2193\nLayer 3 (Library System)\n    \u2193\nLayer 4 (Chat System)\n    \u2193\nLayer 5 (API Routes &amp; Components)\n</code></pre>"},{"location":"architecture/module-hierarchy.html#module-descriptions","title":"Module Descriptions","text":""},{"location":"architecture/module-hierarchy.html#core-infrastructure","title":"Core Infrastructure","text":"<p>Foundation layer providing authentication, database, and environment configuration. No internal dependencies.</p>"},{"location":"architecture/module-hierarchy.html#storage-layer","title":"Storage Layer","text":"<p>Abstracts file storage operations across multiple backends (local filesystem, OneDrive). Depends on Core Infrastructure.</p>"},{"location":"architecture/module-hierarchy.html#library-system","title":"Library System","text":"<p>Manages library data and provides UI components for file browsing and management. Depends on Storage Layer.</p>"},{"location":"architecture/module-hierarchy.html#chat-system","title":"Chat System","text":"<p>Provides RAG-based chat functionality for knowledge exploration. Depends on Library System and Storage Layer.</p>"},{"location":"architecture/module-hierarchy.html#api-routes-components","title":"API Routes &amp; Components","text":"<p>User-facing API endpoints and React components. Depends on all previous layers.</p>"},{"location":"architecture/module-hierarchy.html#key-principles","title":"Key Principles","text":"<ol> <li>Layered Architecture: Each layer depends only on layers below it</li> <li>Dependency Injection: Higher layers receive dependencies from lower layers</li> <li>Type Safety: TypeScript interfaces ensure contract compliance</li> <li>Separation of Concerns: Each module has a single, well-defined responsibility</li> </ol>"},{"location":"architecture/mongodb-vector-search.html","title":"MongoDB Vector Search","text":""},{"location":"architecture/mongodb-vector-search.html#mongodb-vector-search-architecture","title":"MongoDB Vector Search (architecture)","text":"<p>Status: active Last verified: 2026-01-06  </p>"},{"location":"architecture/mongodb-vector-search.html#scope","title":"Scope","text":"<p>This document describes the data model and index shape for MongoDB Atlas Vector Search in this repo. Operational \u201cwhat to debug\u201d notes live in <code>docs/analysis/ingestion.md</code>.</p>"},{"location":"architecture/mongodb-vector-search.html#glossary","title":"Glossary","text":"<ul> <li>Vector collection: MongoDB collection <code>vectors__${libraryId}</code> (one per library)</li> <li>Vector search index: Atlas search index <code>vector_search_idx</code></li> <li>meta: metadata-only document (no embedding)</li> <li>chunk: text chunk + embedding</li> <li>chapterSummary: chapter summary + embedding</li> </ul> <p>This project uses MongoDB Atlas Vector Search for semantic search and RAG. Embeddings and metadata live in MongoDB. No separate vector database is required.</p>"},{"location":"architecture/mongodb-vector-search.html#collection-layout","title":"Collection layout","text":"<ul> <li>One collection per library: <code>vectors__${libraryId}</code></li> <li>Multiple document kinds live in the same collection (distinguished by <code>kind</code>)</li> <li><code>meta</code>: full metadata (no embedding)</li> <li><code>chunk</code>: text chunk + embedding</li> <li><code>chapterSummary</code>: chapter summary + embedding</li> </ul>"},{"location":"architecture/mongodb-vector-search.html#why-we-keep-meta-without-embeddings","title":"Why we keep <code>meta</code> without embeddings","text":"<ul> <li>The gallery and facet aggregation need full metadata.</li> <li>Storing meta without embeddings saves space and keeps writes cheaper.</li> </ul>"},{"location":"architecture/mongodb-vector-search.html#vector-search-index","title":"Vector search index","text":"<ul> <li>Index name: <code>vector_search_idx</code></li> <li>Created lazily (first access) via Mongo admin commands</li> </ul> <p>Example (simplified): <pre><code>{\n  \"name\": \"vector_search_idx\",\n  \"definition\": {\n    \"mappings\": {\n      \"dynamic\": true,\n      \"fields\": {\n        \"embedding\": {\n          \"type\": \"knnVector\",\n          \"dimensions\": 1024,\n          \"similarity\": \"cosine\"\n        }\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"architecture/mongodb-vector-search.html#token-indexes-for-filtering-important","title":"Token indexes for filtering (important)","text":"<p>Atlas Vector Search requires fields used in <code>$vectorSearch.filter</code> to be indexed in a compatible way. In practice, this means:</p> <ul> <li>fields filtered via <code>$in</code> must be indexed as token (not plain string)</li> <li>this includes arrays (e.g. <code>authors</code>, <code>tags</code>) and also \u201csingle string facets\u201d if the code always uses <code>$in</code></li> </ul> <p>If you see errors like:</p> <p><code>Path 'authors' needs to be indexed as token</code></p> <p>the fix is to ensure the search index mapping contains token entries for those fields.</p>"},{"location":"architecture/mongodb-vector-search.html#recommended-mapping-additions-example","title":"Recommended mapping additions (example)","text":"<pre><code>{\n  \"mappings\": {\n    \"dynamic\": true,\n    \"fields\": {\n      \"embedding\": { \"type\": \"knnVector\", \"dimensions\": 1024, \"similarity\": \"cosine\" },\n      \"kind\": { \"type\": \"token\" },\n      \"libraryId\": { \"type\": \"token\" },\n      \"user\": { \"type\": \"token\" },\n      \"fileId\": { \"type\": \"token\" },\n      \"authors\": { \"type\": \"token\" },\n      \"speakers\": { \"type\": \"token\" },\n      \"tags\": { \"type\": \"token\" },\n      \"topics\": { \"type\": \"token\" }\n    }\n  }\n}\n</code></pre> <p>Notes: - The exact list depends on which facet fields you use in filters. - When in doubt: index every filterable facet as token to avoid runtime failures.</p>"},{"location":"architecture/mongodb-vector-search.html#query-patterns","title":"Query patterns","text":"<p>Vector search query (simplified): <pre><code>const pipeline = [\n  {\n    $vectorSearch: {\n      index: 'vector_search_idx',\n      path: 'embedding',\n      queryVector,\n      numCandidates: Math.max(topK * 10, 100),\n      limit: topK,\n      filter: {\n        kind: { $in: ['chunk', 'chapterSummary'] },\n        libraryId: { $eq: libraryId },\n        user: { $eq: userEmail },\n      }\n    }\n  },\n  { $project: { _id: 1, score: { $meta: 'vectorSearchScore' } } }\n]\n</code></pre></p> <p>Direct Mongo query (no vector search), e.g. for neighbor chunks: <pre><code>const chunks = await collection.find({\n  kind: 'chunk',\n  libraryId,\n  user: userEmail,\n  fileId: { $in: fileIds },\n}).sort({ fileId: 1, chunkIndex: 1 }).toArray()\n</code></pre></p>"},{"location":"architecture/mongodb-vector-search.html#facet-duplication","title":"Facet duplication","text":"<p>Facet fields are copied into <code>chunk</code> and <code>chapterSummary</code> documents so filtering can happen directly inside <code>$vectorSearch</code>.</p>"},{"location":"architecture/mongodb-vector-search.html#code-references","title":"Code references","text":"<ul> <li>Repository: <code>src/lib/repositories/vector-repo.ts</code></li> <li>Ingestion: <code>src/lib/chat/ingestion-service.ts</code></li> <li>Retrievers:</li> <li><code>src/lib/chat/retrievers/chunks.ts</code></li> <li><code>src/lib/chat/retrievers/chunk-summary.ts</code></li> </ul>"},{"location":"architecture/mongodb-vector-search.html#related-docs","title":"Related docs","text":"<ul> <li>Runtime/operations notes: <code>docs/analysis/ingestion.md</code></li> </ul>"},{"location":"architecture/pdf-transformation-phases.html","title":"PDF Transformation Phases","text":"<p>Status: active Last verified: 2026-01-06  </p>"},{"location":"architecture/pdf-transformation-phases.html#scope","title":"Scope","text":"<p>This document describes the current PDF processing pipeline (Extract \u2192 Template \u2192 Ingestion) and how it maps to the external-jobs runtime. It also documents the artifact contracts (Shadow\u2011Twin) that downstream UI and ingestion rely on.</p>"},{"location":"architecture/pdf-transformation-phases.html#glossary","title":"Glossary","text":"<ul> <li>Transcript: extracted Markdown without frontmatter (Phase 1 output)</li> <li>Transformation: template-based Markdown with frontmatter/metadata (Phase 2 output)</li> <li>Ingestion: RAG upsert into MongoDB Atlas Vector Search (Phase 3)</li> <li>Shadow\u2011Twin: derived artifacts stored next to the source file (often in a dot-folder)</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#overview","title":"Overview","text":"<p>PDF transformation consists of three sequential phases that convert a PDF file into a searchable, structured document ready for RAG (Retrieval Augmented Generation). Each phase builds upon the previous one, creating intermediate artifacts that can be reused or skipped based on policies.</p> <p>In the current implementation (IST), these three phases are not executed via three separate HTTP endpoints, but through a combination of:</p> <ul> <li>Worker: <code>src/lib/external-jobs-worker.ts</code> \u2013 polls jobs and calls the start route</li> <li>Start route: <code>src/app/api/external/jobs/[jobId]/start/route.ts</code> \u2013 initializes the job and starts Phase 1 (Extract) or an ingest-only path</li> <li>Secretary Service (external) \u2013 performs PDF/OCR/template transformation and sends webhooks back</li> <li>Callback route: <code>src/app/api/external/jobs/[jobId]/route.ts</code> \u2013 processes webhooks and orchestrates Phase 1\u20133 (Extract, Template, Ingestion)</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#runtime-orchestration-high-level","title":"Runtime Orchestration (high level)","text":"<pre><code>Worker (jobs queue)\n  \u2193 POST /api/external/jobs/{jobId}/start\nStart route\n  - loads PDF from storage\n  - decides Extract/Template/Ingest-only via gates + policies\n  - calls Secretary Service (PDF/OCR)\n  \u2193 Webhook: POST /api/external/jobs/{jobId}\nSecretary Service (external)\n  - extracts text/images\n  - sends extracted_text, pages_archive_url, mistral_ocr_raw_url, ...\n  \u2193\nCallback route\n  - processes extract result (Phase 1)\n  - runs or skips template phase (Phase 2)\n  - runs or skips ingestion (Phase 3)\n</code></pre>"},{"location":"architecture/pdf-transformation-phases.html#phase-1-extract-extraction","title":"Phase 1: Extract (Extraction)","text":""},{"location":"architecture/pdf-transformation-phases.html#purpose","title":"Purpose","text":"<p>Extract text and images from PDF files using OCR or native text extraction.</p>"},{"location":"architecture/pdf-transformation-phases.html#what-happens","title":"What Happens","text":"<ol> <li>PDF Processing:</li> <li>PDF file is sent to Secretary Service</li> <li>Text extraction via native PDF parsing or OCR (Mistral OCR)</li> <li> <p>Image extraction (if enabled)</p> </li> <li> <p>Image Processing:</p> </li> <li>Mistral OCR images: Extracted via <code>mistral_ocr_images_url</code> (ZIP archive) - separate from <code>mistral_ocr_raw</code></li> <li>PDF page images: Extracted as ZIP archive (<code>pages_archive_url</code> or <code>pages_archive_data</code>)</li> <li>Images saved to Shadow-Twin directory (if present)</li> <li> <p>Note: Asynchronous webhook sends <code>mistral_ocr_raw_url</code> and <code>mistral_ocr_raw_metadata</code> only. Full <code>mistral_ocr_raw</code> data must be downloaded via <code>GET /api/pdf/jobs/{job_id}/mistral-ocr-raw</code></p> </li> <li> <p>Markdown Creation:</p> </li> <li>Extracted text saved as Markdown without frontmatter</li> <li>File name (v2): <code>{baseName}.{language}.md</code> (transcript, language suffix)</li> </ol>"},{"location":"architecture/pdf-transformation-phases.html#input","title":"Input","text":"<ul> <li>PDF file (<code>document.pdf</code>)</li> <li>Extraction method (<code>native</code> or <code>mistral_ocr</code>)</li> <li>Target language (for OCR)</li> <li>Image extraction flags (<code>includeOcrImages</code>, <code>includePageImages</code>)</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#output","title":"Output","text":"<ul> <li>Transcript File: <code>document.de.md</code> (Markdown without frontmatter; language suffix)</li> <li>Images: Saved to <code>.document.pdf/</code> directory (if images extracted)</li> <li>Shadow-Twin Directory: Created automatically if images are present</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#code-references-ist","title":"Code References (IST)","text":"<ul> <li>Worker &amp; routes</li> <li><code>src/lib/external-jobs-worker.ts</code>: Background worker that polls jobs from the queue and triggers the start route (<code>POST /api/external/jobs/[jobId]/start</code>)</li> <li><code>src/app/api/external/jobs/[jobId]/start/route.ts</code>: Start route; loads the PDF from storage, sets watchdog/steps, calls Secretary Service (standard or Mistral OCR endpoint) and can run an ingest-only flow</li> <li><code>src/app/api/external/jobs/[jobId]/route.ts</code>: Callback route; processes webhooks from Secretary Service (including <code>extracted_text</code>, <code>pages_archive_url</code>, <code>mistral_ocr_raw_url</code>) and decides whether to run Extract-only, Extract+Template+Ingest or a skip path</li> <li>Extract-Phase (Core-Module)</li> <li><code>src/lib/external-jobs/extract-only.ts</code>: Extract-only processing logic (Transcript speichern, Bilder verarbeiten, Job abschlie\u00dfen)</li> <li><code>src/lib/external-jobs/images.ts</code>: Image extraction and processing (pages-Archive, images-Archive, Mistral OCR)</li> <li><code>src/lib/external-jobs/storage.ts</code>: Markdown storage in the shadow twin or parent folder</li> <li><code>src/lib/processing/gates.ts</code> (<code>gateExtractPdf</code>): Gate that checks whether a shadow twin (transcript or transformed) already exists and allows Extract to be skipped</li> <li><code>src/lib/transform/image-extraction-service.ts</code>: Image extraction service (deeper image-processing pipeline)</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#execution-in-code-ist","title":"Execution in Code (IST)","text":"<ul> <li>Start route</li> <li>Loads the PDF from storage via <code>getServerProvider</code>.</li> <li>Runs preprocessing and initializes steps (<code>extract_pdf</code>, <code>transform_template</code>, <code>ingest_rag</code>).</li> <li>Calls <code>gateExtractPdf</code> and phase policies to decide:<ul> <li>whether Extract should actually be sent to Secretary Service (<code>runExtract</code>),</li> <li>whether only Template/Ingestion should run,</li> <li>whether an ingest-only path without a new Secretary call is possible.</li> </ul> </li> <li> <p>When <code>runExtract</code> is true, sends an HTTP request to Secretary Service (<code>/api/pdf/process</code> or <code>/api/pdf/process-mistral-ocr</code>) with <code>callback_url</code> = <code>/api/external/jobs/{jobId}</code>.</p> </li> <li> <p>Callback route</p> </li> <li>Receives webhooks with <code>extracted_text</code> and image archives.</li> <li>Marks <code>extract_pdf</code> as completed as soon as a stable OCR result is available.</li> <li>If template and ingest phases are explicitly disabled, calls <code>runExtractOnly</code>, stores the transcript without frontmatter and optionally processes images.</li> <li>In all other cases it only ensures that Phase 1 is completed and passes the results to the template/ingestion logic.</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#example-output","title":"Example Output","text":"<pre><code>.document.pdf/\n\u251c\u2500\u2500 document.de.md       (Transcript - extracted text, no frontmatter)\n\u251c\u2500\u2500 page-001.png        (Extracted images)\n\u2514\u2500\u2500 page-002.png\n</code></pre>"},{"location":"architecture/pdf-transformation-phases.html#phase-2-template-metadata","title":"Phase 2: Template (Metadata)","text":""},{"location":"architecture/pdf-transformation-phases.html#purpose_1","title":"Purpose","text":"<p>Add structured metadata (frontmatter) to the extracted text, enabling structured queries and RAG integration.</p>"},{"location":"architecture/pdf-transformation-phases.html#what-happens_1","title":"What Happens","text":"<ol> <li>Template Processing:</li> <li>Transcript Markdown (<code>document.md</code>) is sent to Secretary Service template transformer</li> <li>LLM analyzes content and extracts structured metadata</li> <li>Frontmatter is generated with chapters, topics etc.</li> <li> <p>The total page count (<code>pages</code>) is not computed by the template but always reconstructed from the <code>--- Seite N ---</code> markers in the Markdown body.</p> </li> <li> <p>Markdown Creation:</p> </li> <li>Transcript content + frontmatter = transformed Markdown</li> <li>File name: <code>{originalName}.{language}.md</code> (with language suffix - transformed)</li> </ol>"},{"location":"architecture/pdf-transformation-phases.html#input_1","title":"Input","text":"<ul> <li>Transcript Markdown (<code>document.md</code>)</li> <li>Template content (structured schema)</li> <li>Target language</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#output_1","title":"Output","text":"<ul> <li>Transformed File: <code>document.de.md</code> (Markdown with frontmatter)</li> <li>Metadata: Structured data in YAML frontmatter</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#code-references-ist_1","title":"Code References (IST)","text":"<ul> <li>Routes &amp; orchestration</li> <li><code>src/app/api/external/jobs/[jobId]/route.ts</code>: Central callback route that, after receiving extract results, decides whether the template phase runs or is skipped and then saves the transformed Markdown.</li> <li>Template phase (core modules)</li> <li><code>src/lib/external-jobs/phase-template.ts</code>: Consolidated template phase (decision logic, repair cases, saving transformed Markdown)</li> <li><code>src/lib/external-jobs/template-run.ts</code>: Template transformation execution (calls the Secretary template transformer and parses the response)</li> <li><code>src/lib/external-jobs/chapters.ts</code>: Chapter detection and merge based on text</li> <li><code>src/lib/external-jobs/template-files.ts</code>: Template-Auswahl f\u00fcr External Jobs (MongoDB Source of Truth), serialisiert Secretary-kompatibel (ohne <code>creation</code>)</li> <li><code>src/lib/templates/template-service-mongodb.ts</code>: MongoDB Template-Service inkl. Serialisierung zu Template-Markdown (Frontmatter + Body + systemprompt)</li> <li>Hinweis (Legacy): <code>src/lib/templates/template-service.ts</code> l\u00e4dt Templates aus dem Library-Storage <code>/templates</code> Ordner und wird prim\u00e4r f\u00fcr Import/Migration genutzt.</li> <li><code>src/lib/processing/gates.ts</code> (<code>gateTransformTemplate</code>): Gate checking (e.g. skip if chapter metadata already exists)</li> <li><code>src/lib/external-jobs/storage.ts</code>: Saves transformed Markdown (<code>{originalName}.{language}.md</code>)</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#execution-in-code-ist_1","title":"Execution in Code (IST)","text":"<ul> <li>Callback route</li> <li>Runs a preprocess span (if not already present) to detect existing frontmatter and its quality.</li> <li>Reads policies and phase flags via <code>readPhasesAndPolicies</code> and <code>job.parameters.phases</code>.</li> <li>Determines from the callback body whether chapter metadata (<code>chapters</code>) is already present.</li> <li>Calls the consolidated template phase (<code>runTemplatePhase</code> in <code>phase-template.ts</code>), which:<ul> <li>combines policies (<code>metadata: force/skip/auto/ignore</code>),</li> <li>gates (<code>gateTransformTemplate</code>), and</li> <li>the repair needs of an existing shadow twin.</li> </ul> </li> <li>Template transformation is only executed if no chapter metadata (<code>chapters</code>) exists yet. If only <code>pages</code> are missing, they are reconstructed from the <code>--- Seite N ---</code> markers in the body.</li> <li>When template processing is executed:<ul> <li>it selects a template from MongoDB (TemplateDocument) and serialisiert es als Secretary-kompatibles Template-Markdown (ohne <code>creation</code>),</li> <li>calls the Secretary template endpoint and adds chapter information,</li> <li>strips old frontmatter and stores the new Markdown with frontmatter via <code>saveMarkdown</code> as <code>{originalName}.{language}.md</code>,</li> <li>and reliably marks the <code>transform_template</code> step as <code>completed</code> or <code>failed</code>.</li> </ul> </li> <li>When the template phase is skipped (chapters already exist), only missing <code>pages</code> are reconstructed and the existing frontmatter is used directly as the basis for ingestion.</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#example-output_1","title":"Example Output","text":"<pre><code>---\ntitle: \"Document Title\"\npages: 42\nchapters:\n  - title: \"Chapter 1\"\n    page: 1\n  - title: \"Chapter 2\"\n    page: 15\n---\n# Document Title\n\n[Extracted content...]\n</code></pre>"},{"location":"architecture/pdf-transformation-phases.html#skip-conditions","title":"Skip Conditions","text":"<ul> <li>Chapter metadata (<code>chapters</code>) already exists (frontmatter is complete with respect to chapters).</li> <li>Template phase disabled via policy.</li> <li>Previous job already completed the template phase.</li> </ul> <p>If only the page count (<code>pages</code>) is missing, the template phase is skipped and <code>pages</code> is silently reconstructed from the <code>--- Seite N ---</code> markers in the body.</p>"},{"location":"architecture/pdf-transformation-phases.html#phase-3-ingestion-rag","title":"Phase 3: Ingestion (RAG)","text":""},{"location":"architecture/pdf-transformation-phases.html#purpose_2","title":"Purpose","text":"<p>Ingest transformed Markdown into MongoDB Atlas Vector Search for RAG queries.</p>"},{"location":"architecture/pdf-transformation-phases.html#what-happens_2","title":"What Happens","text":"<ol> <li>Markdown Processing:</li> <li>Transformed Markdown (<code>document.de.md</code>) is parsed</li> <li>Images are processed and uploaded to Azure Storage (Slides, Cover, Markdown images)</li> <li> <p>Final Markdown (with Azure image URLs) is stored in MongoDB</p> </li> <li> <p>Vector Storage:</p> </li> <li>Complete document is sent to Secretary Service RAG API (<code>/api/rag/embed-text</code>)</li> <li>Secretary Service performs Markdown-aware chunking and embedding generation</li> <li>Chunks with embeddings are received and stored in MongoDB Vector Search Collection</li> <li>Meta-documents (without embeddings) are stored alongside chunks for gallery display</li> <li> <p>Facet metadata is duplicated into chunks for direct filtering during vector search</p> </li> <li> <p>MongoDB Storage:</p> </li> <li>All data stored in MongoDB: Meta-documents, chunks, and chapter summaries in same collection</li> <li>Collection structure: <code>vectors__${libraryId}</code> per library</li> <li>Document metadata stored as <code>kind: 'meta'</code> documents (no embeddings)</li> <li> <p>Chapter summaries stored as <code>kind: 'chapterSummary'</code> documents (with embeddings)</p> </li> <li> <p>Image Upload (Shadow-Twin \u2192 Azure Storage):</p> </li> <li>All image handling in Phase 3 is based on the Shadow-Twin directory and is centralized in the ingestion service.</li> <li>Session-mode documents (events with slides):<ul> <li><code>docMetaJson.slides[].image_url</code> is interpreted as a reference into the Shadow-Twin.</li> <li>Each slide image is resolved via <code>findShadowTwinImage</code>, uploaded to Azure Storage under the scoped path <code>\u2026/{libraryId}/sessions/{fileId}/{hash}.{ext}</code> and de-duplicated by hash.</li> <li>The resulting Azure URLs replace the original <code>slides[].image_url</code> values and are used directly by the frontend (<code>EventSlides</code>).</li> </ul> </li> <li>Book-mode documents (no slides):<ul> <li>A cover image is detected in the Shadow-Twin directory (<code>preview_001.jpg</code>), uploaded to Azure under <code>\u2026/{libraryId}/books/{fileId}/{hash}.{ext}</code> and stored as <code>docMetaJson.coverImageUrl</code>; this field is also available as a facet and is used by the gallery and book-detail views.</li> <li>Inline images in the Markdown body (Markdown <code>![]()</code>, HTML <code>&lt;img&gt;</code> and Obsidian <code>&lt;img-x.ext&gt;</code> syntax) are resolved against the Shadow-Twin, uploaded to Azure under the <code>books</code> scope and all references in the Markdown are rewritten to use the Azure URLs.</li> </ul> </li> <li>Frontend components (gallery cards, document detail, markdown viewer) use only these Azure URLs; direct access to Shadow-Twin image files from the browser is no longer required.</li> </ol>"},{"location":"architecture/pdf-transformation-phases.html#input_2","title":"Input","text":"<ul> <li>Transformed Markdown (<code>document.de.md</code>)</li> <li>Shadow-Twin directory (transcript, transformed Markdown, extracted images)</li> <li>Library configuration (including ingestion policies and facets)</li> <li>Storage provider + <code>shadowTwinFolderId</code> from the job\u2019s <code>shadowTwinState</code></li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#output_2","title":"Output","text":"<ul> <li>Vector embeddings: Stored in MongoDB Vector Search Collection (<code>vectors__${libraryId}</code>)</li> <li>Document metadata: Stored as meta-documents (<code>kind: 'meta'</code>) in same collection</li> <li>Image URLs: Azure Storage URLs in metadata</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#code-references-ist_2","title":"Code References (IST)","text":"<ul> <li>Routes &amp; orchestration</li> <li><code>src/app/api/external/jobs/[jobId]/start/route.ts</code>: Can execute an ingest-only path if a transformed shadow-twin Markdown already exists (without another Secretary request).</li> <li><code>src/app/api/external/jobs/[jobId]/route.ts</code>: Runs the regular ingestion after the template phase (including gates, policies, and error handling).</li> <li>Ingestion phase (core modules)</li> <li><code>src/lib/external-jobs/ingest.ts</code>: RAG ingestion pipeline (wrapper around the ingestion service)</li> <li><code>src/lib/chat/ingestion-service.ts</code>: Ingestion service (Secretary Service RAG API integration, MongoDB Vector Search upsert, image processing and Azure upload via <code>processSlideImagesToAzure</code>, <code>processMarkdownImagesToAzure</code>, <code>processCoverImageToAzure</code>)</li> <li><code>src/lib/chat/rag-embeddings.ts</code>: RAG embedding abstraction (Secretary Service client wrapper)</li> <li><code>src/lib/secretary/client.ts</code>: Secretary Service client (<code>embedTextRag()</code> for RAG API)</li> <li><code>src/lib/repositories/vector-repo.ts</code>: MongoDB Vector Search repository (upsert, query, meta-documents)</li> <li><code>src/lib/processing/gates.ts</code> (<code>gateIngestRag</code>): Gate checking (skip if already ingested; uses MongoDB query)</li> <li><code>src/lib/external-jobs/complete.ts</code>: Job completion handler (status, result, events)</li> <li>Storage &amp; metadata</li> <li><code>src/lib/repositories/doc-meta-repo.ts</code>: MongoDB document metadata repository (incl. <code>coverImageUrl</code>)</li> <li><code>src/lib/storage/shadow-twin.ts</code>: Shadow-Twin utilities (<code>findShadowTwinImage</code>, <code>resolveShadowTwinImageUrl</code>) for resolving images by relative path</li> <li><code>src/lib/services/azure-storage-service.ts</code>: Azure Storage client (scoped blob paths <code>books</code> / <code>sessions</code>, hash-based de-duplication)</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#execution-in-code-ist_2","title":"Execution in Code (IST)","text":"<ul> <li>Start route (ingest-only path)</li> <li> <p>If policies/gates decide that Extract/Template are not needed but ingestion should run:</p> <ul> <li>it searches for the already transformed Markdown in the shadow twin (directory first, then file),</li> <li>loads the Markdown text and parses frontmatter via <code>parseSecretaryMarkdownStrict</code>,</li> <li>calls <code>runIngestion</code> directly and completes the job after successful ingestion.</li> </ul> </li> <li> <p>Callback route (regular path)</p> </li> <li>Uses <code>gateIngestRag</code> and optionally <code>ingestionCheck</code> to determine whether vectors for this document already exist in the MongoDB Vector Search collection.</li> <li>Reads ingestion policies (<code>ingestPolicy: 'do' | 'force' | 'skip'</code> plus legacy flags from <code>job.parameters</code>).</li> <li>Determines <code>useIngestion</code> and marks <code>ingest_rag</code> as <code>skipped</code> if appropriate (including reason).</li> <li>When ingestion runs:<ul> <li>determines <code>fileId</code> and <code>fileName</code> of the document to ingest,</li> <li>loads Markdown for ingestion (directly from the current callback context or via storage fallback),</li> <li>calls <code>runIngestion</code>, which:</li> <li>calls <code>IngestionService.upsertMarkdown(...)</code>,</li> <li>stores chunks in Pinecone, and</li> <li>writes metadata (including chapter summaries) to MongoDB,</li> <li>updates the ingestion status in the job (<code>setIngestion</code>) and sets the <code>ingest_rag</code> step to <code>completed</code>.</li> </ul> </li> <li>Finally calls <code>setJobCompleted</code>, updates the shadow-twin state to <code>processingStatus: 'ready'</code> and sends a final <code>job_update</code> event with <code>refreshFolderIds</code>.</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#skip-conditions_1","title":"Skip Conditions","text":"<ul> <li>Document already ingested (check via <code>ingestionCheck</code>)</li> <li>Ingestion phase disabled via policy</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#phase-control","title":"Phase Control","text":""},{"location":"architecture/pdf-transformation-phases.html#policies","title":"Policies","text":"<p>Phases can be controlled via policies:</p> <pre><code>interface PhasePolicies {\n  extract: 'force' | 'skip' | 'auto' | 'ignore';\n  metadata: 'force' | 'skip' | 'auto' | 'ignore';\n  ingest: 'force' | 'skip' | 'auto' | 'ignore';\n}\n</code></pre> <ul> <li><code>force</code>: Always execute phase (even if artifacts exist)</li> <li><code>skip</code>: Skip phase (even if artifacts don't exist)</li> <li><code>auto</code>: Execute if needed (check gates)</li> <li><code>ignore</code>: Phase disabled</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#gates","title":"Gates","text":"<p>Gates check if phases should be skipped:</p> <ul> <li><code>gateExtractPdf()</code>: Checks for existing Shadow-Twin files</li> <li><code>gateTransformTemplate()</code>: Checks for existing frontmatter</li> <li><code>gateIngestRag()</code>: Checks for existing ingestion</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#execution-flow","title":"Execution Flow","text":"<pre><code>PDF File\n  \u2193\n[Gate: Extract] \u2192 Skip if Shadow-Twin exists\n  \u2193\nPhase 1: Extract \u2192 document.md + images\n  \u2193\n[Gate: Template] \u2192 Skip if frontmatter exists\n  \u2193\nPhase 2: Template \u2192 document.de.md\n  \u2193\n[Gate: Ingestion] \u2192 Skip if already ingested\n  \u2193\nPhase 3: Ingestion \u2192 Vector storage + MongoDB\n  \u2193\nComplete\n</code></pre>"},{"location":"architecture/pdf-transformation-phases.html#file-naming-convention","title":"File Naming Convention","text":""},{"location":"architecture/pdf-transformation-phases.html#v2-only-artifact-naming-shadowtwin","title":"v2-only artifact naming (Shadow\u2011Twin)","text":"<p>In the current runtime, file naming is deterministic and shared across all media types. Do not rely on legacy \u201c<code>originalName.md</code>\u201d heuristics.</p>"},{"location":"architecture/pdf-transformation-phases.html#transcript-artifact-phase-1","title":"Transcript artifact (Phase 1)","text":"<ul> <li>Format: <code>{baseName}.{language}.md</code></li> <li>Example: <code>document.de.md</code></li> <li>Content: extracted Markdown (typically without frontmatter)</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#transformation-artifact-phase-2","title":"Transformation artifact (Phase 2)","text":"<ul> <li>Format: <code>{baseName}.{templateName}.{language}.md</code></li> <li>Example: <code>document.pdfanalyse.de.md</code></li> <li>Content: Markdown with frontmatter/metadata</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#location","title":"Location","text":"<p>Artifacts can live either: 1) inside a dot-folder <code>.{originalName}/</code> (recommended when multiple assets exist), or 2) as siblings next to the PDF (common when only Markdown exists).</p>"},{"location":"architecture/pdf-transformation-phases.html#update-semantics","title":"Update semantics","text":"<p>Re-running the same phase updates (overwrites) the canonical artifact instead of creating duplicates.</p>"},{"location":"architecture/pdf-transformation-phases.html#error-handling","title":"Error Handling","text":"<ul> <li>Phase failures: Logged in job document, job status set to <code>failed</code></li> <li>Partial completion: Intermediate artifacts preserved</li> <li>Retry: Failed phases can be retried independently</li> <li>Skip on error: Subsequent phases can still execute if previous phase failed (depending on policy)</li> </ul>"},{"location":"architecture/pdf-transformation-phases.html#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Parallel processing: Images processed in parallel with text extraction</li> <li>Caching: Secretary Service caches OCR results</li> <li>Batch processing: Multiple PDFs processed in parallel</li> <li>Incremental updates: Only changed phases re-executed</li> </ul>"},{"location":"architecture/pipeline-phases.html","title":"Pipeline-Phasen Architektur","text":""},{"location":"architecture/pipeline-phases.html#ubersicht","title":"\u00dcbersicht","text":"<p>Die Dokumentenverarbeitung erfolgt in drei Phasen, die \u00fcber External Jobs orchestriert werden:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Pipeline-Phasen                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Phase 1        \u2502   Phase 2            \u2502   Phase 3                    \u2502\n\u2502   EXTRACT        \u2502   TRANSFORM          \u2502   INGEST                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 - OCR/Transkript \u2502 - Template anwenden  \u2502 - RAG-Vektoren erstellen     \u2502\n\u2502 - Text extrah.   \u2502 - Metadaten gener.   \u2502 - MongoDB-Index aktualis.    \u2502\n\u2502 - Bilder laden   \u2502 - Cover-Bild gener.  \u2502 - Chat-Suche erm\u00f6glichen     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/pipeline-phases.html#unified-pipeline-endpoint","title":"Unified Pipeline Endpoint","text":"<p>Alle Pipeline-Operationen laufen \u00fcber einen zentralen Endpoint:</p> <pre><code>POST /api/pipeline/process\n</code></pre>"},{"location":"architecture/pipeline-phases.html#request-format","title":"Request-Format","text":"<pre><code>interface PipelineRequest {\n  libraryId: string\n\n  // Einzeldatei ODER Batch\n  item?: PipelineItem           // Einzeldatei\n  items?: PipelineItem[]        // Batch (mehrere Dateien)\n\n  config: PipelineConfig\n  batchName?: string            // Optional: Name f\u00fcr Batch-Verarbeitung\n\n  // PDF-spezifische Optionen\n  extractionMethod?: string\n  includeOcrImages?: boolean\n  includePageImages?: boolean\n  useCache?: boolean\n}\n\ninterface PipelineConfig {\n  targetLanguage: TargetLanguage\n  templateName?: string\n  phases: { extract: boolean; template: boolean; ingest: boolean }\n  policies: { extract: PhasePolicy; metadata: PhasePolicy; ingest: PhasePolicy }\n  generateCoverImage?: boolean\n  coverImagePrompt?: string\n}\n</code></pre>"},{"location":"architecture/pipeline-phases.html#response-format","title":"Response-Format","text":"<pre><code>interface PipelineResponse {\n  successCount: number\n  failureCount: number\n  jobs: Array&lt;{ jobId: string; mediaKind: MediaKind }&gt;\n  failures: Array&lt;{ itemId: string; error: string }&gt;\n}\n</code></pre>"},{"location":"architecture/pipeline-phases.html#verwendung-im-code","title":"Verwendung im Code","text":"<pre><code>import { runPipelineForFile, runPipelineUnified } from \"@/lib/pipeline/run-pipeline\"\n\n// Einzeldatei (mit Convenience-Wrapper)\nconst { jobId } = await runPipelineForFile({\n  libraryId,\n  sourceFile,\n  parentId,\n  kind: 'pdf',\n  targetLanguage: 'de',\n  policies: { extract: 'do', metadata: 'do', ingest: 'do' }\n})\n\n// Batch (direkter Endpoint-Aufruf)\nconst response = await fetch('/api/pipeline/process', {\n  method: 'POST',\n  body: JSON.stringify({\n    libraryId,\n    items: files.map(f =&gt; ({ fileId: f.id, parentId, name: f.name })),\n    config: { targetLanguage: 'de', phases: { extract: true, template: true, ingest: true }, ... }\n  })\n})\n</code></pre>"},{"location":"architecture/pipeline-phases.html#medientypen","title":"Medientypen","text":"<p>Die Pipeline unterst\u00fctzt verschiedene Medientypen (definiert in <code>src/lib/media-types.ts</code>):</p> MediaKind Phase 1 Phase 2 Phase 3 Beschreibung <code>pdf</code> OCR via Secretary Service Template-Transformation RAG-Ingestion PDF-Dokumente <code>audio</code> Whisper-Transkription Template-Transformation RAG-Ingestion Audio-Dateien <code>video</code> Video-zu-Audio + Whisper Template-Transformation RAG-Ingestion Video-Dateien <code>markdown</code> SKIP (Quelle = Transkript) Template-Transformation RAG-Ingestion Markdown/Text <code>image</code> OCR (geplant) Template-Transformation RAG-Ingestion Bild-Dateien"},{"location":"architecture/pipeline-phases.html#markdown-sonderfall","title":"Markdown-Sonderfall","text":"<p>Bei Markdown-Dateien ist die Quelldatei selbst das \"Transkript\". Die Extract-Phase wird \u00fcbersprungen, und die Quelldatei wird direkt als Input f\u00fcr die Template-Transformation verwendet.</p>"},{"location":"architecture/pipeline-phases.html#route-architektur","title":"Route-Architektur","text":"<p>Zwei API-Routen orchestrieren die Phasen:</p>"},{"location":"architecture/pipeline-phases.html#1-start-route-apiexternaljobsjobidstart","title":"1. Start-Route (<code>/api/external/jobs/[jobId]/start</code>)","text":"<p>Wann aufgerufen: Vom Worker, um einen Job zu starten</p> <p>Verantwortlich f\u00fcr: - Datei aus Storage laden - Shadow-Twin-Analyse durchf\u00fchren - Bei PDF/Audio/Video: Request an Secretary Service senden - Bei Markdown: Direkt Template-Phase ausf\u00fchren (kein Secretary-Aufruf)</p>"},{"location":"architecture/pipeline-phases.html#2-callback-route-apiexternaljobsjobid","title":"2. Callback-Route (<code>/api/external/jobs/[jobId]</code>)","text":"<p>Wann aufgerufen: Vom Secretary Service nach Abschluss der Extraktion</p> <p>Verantwortlich f\u00fcr: - Ergebnis von Phase 1 verarbeiten - Template-Phase ausf\u00fchren (f\u00fcr PDF/Audio/Video) - Ingest-Phase ausf\u00fchren - Job abschlie\u00dfen</p>"},{"location":"architecture/pipeline-phases.html#unterschiedliche-flows-nach-medientyp","title":"Unterschiedliche Flows nach Medientyp","text":"<pre><code>PDF/Audio/Video:\n  start/route.ts \u2500\u2500\u25ba Secretary Service \u2500\u2500\u25ba route.ts (Callback)\n                                              \u2502\n                                              \u251c\u2500\u25ba Template-Phase\n                                              \u2514\u2500\u25ba Ingest-Phase\n\nMarkdown:\n  start/route.ts \u2500\u2500\u25ba Template-Phase (direkt)\n                       \u2502\n                       \u2514\u2500\u25ba Ingest-Phase\n</code></pre>"},{"location":"architecture/pipeline-phases.html#policies","title":"Policies","text":"<p>Jede Phase kann mit einer Policy gesteuert werden:</p> Policy Bedeutung <code>ignore</code> Phase \u00fcberspringen <code>do</code> Ausf\u00fchren, wenn Gate nicht existiert <code>force</code> Immer ausf\u00fchren (Gate ignorieren) <p>Gates pr\u00fcfen, ob das Ergebnis einer Phase bereits existiert: - Extract-Gate: Existiert ein Transcript im Shadow-Twin? - Template-Gate: Existiert eine Transformation im Shadow-Twin? - Ingest-Gate: Ist das Dokument bereits im RAG-Index?</p>"},{"location":"architecture/pipeline-phases.html#cover-bild-generierung","title":"Cover-Bild-Generierung","text":"<p>Die Cover-Bild-Generierung ist Teil der Template-Phase (Phase 2):</p>"},{"location":"architecture/pipeline-phases.html#parameter","title":"Parameter","text":"Parameter Quelle Beschreibung <code>generateCoverImage</code> Job-Parameter oder Library-Config Boolean: Bild generieren? <code>coverImagePrompt</code> Job-Parameter oder Library-Config Custom Prompt (optional)"},{"location":"architecture/pipeline-phases.html#ablauf","title":"Ablauf","text":"<ol> <li>Template-Transformation abgeschlossen</li> <li>Pr\u00fcfung: <code>generateCoverImage === true</code> UND kein Cover-Bild existiert</li> <li>Prompt erstellen aus Title + Summary der Transformation</li> <li>API-Aufruf an Secretary Service (<code>/text2image/generate</code>)</li> <li>Bild als Base64 empfangen</li> <li>Upload nach Azure Blob Storage</li> <li>URL im Shadow-Twin speichern (<code>coverImageUrl</code>)</li> </ol>"},{"location":"architecture/pipeline-phases.html#route-trennung-race-condition-fix","title":"Route-Trennung (Race-Condition-Fix)","text":"<p>Cover-Bilder werden nur in EINER Route generiert:</p> Job-Typ Cover-Bild-Route Grund <code>text</code> (Markdown) <code>start/route.ts</code> Template wird direkt ausgef\u00fchrt <code>pdf</code>, <code>audio</code>, <code>video</code> <code>route.ts</code> (Callback) Template wird nach Secretary-Callback ausgef\u00fchrt <p>Dies verhindert Race Conditions bei paralleler Ausf\u00fchrung.</p>"},{"location":"architecture/pipeline-phases.html#job-struktur","title":"Job-Struktur","text":"<pre><code>interface ExternalJob {\n  jobId: string\n  job_type: \"pdf\" | \"audio\" | \"video\" | \"text\"\n  status: \"queued\" | \"running\" | \"completed\" | \"failed\"\n\n  parameters: {\n    targetLanguage: string\n    template?: string\n    phases: {\n      extract: boolean\n      template: boolean\n      ingest: boolean\n    }\n    policies: {\n      extract: \"ignore\" | \"do\" | \"force\"\n      metadata: \"ignore\" | \"do\" | \"force\"\n      ingest: \"ignore\" | \"do\" | \"force\"\n    }\n    generateCoverImage?: boolean\n    coverImagePrompt?: string\n  }\n\n  steps: [\n    { name: \"extract_pdf\" | \"extract_audio\" | \"extract_video\", status: StepStatus }\n    { name: \"transform_template\", status: StepStatus }\n    { name: \"ingest_rag\", status: StepStatus }\n  ]\n\n  shadowTwinState: {\n    baseItem: { id: string, metadata: { name: string } }\n    transcriptFiles: Array&lt;{ id: string, metadata: { name: string } }&gt;\n    transformed: { id: string, metadata: { name: string } } | null\n    shadowTwinFolderId: string | null\n  }\n}\n</code></pre>"},{"location":"architecture/pipeline-phases.html#dateien","title":"Dateien","text":"Datei Beschreibung <code>src/lib/media-types.ts</code> Zentrale Medientyp-Definitionen <code>src/lib/pipeline/run-pipeline.ts</code> Pipeline-Start-Funktionen <code>src/lib/external-jobs/phase-template.ts</code> Template-Phase + Cover-Bild <code>src/lib/external-jobs/phase-ingest.ts</code> Ingest-Phase <code>src/app/api/external/jobs/[jobId]/route.ts</code> Callback-Route <code>src/app/api/external/jobs/[jobId]/start/route.ts</code> Start-Route"},{"location":"architecture/pipeline-phases.html#ui-komponenten","title":"UI-Komponenten","text":"Komponente Beschreibung <code>PipelineSheet</code> Dialog zur Pipeline-Konfiguration (Phasen, Policies, Cover-Bild) <code>FlowActions</code> Pipeline-Steuerung im Flow-View (Experten-Modus) <code>FilePreview</code> Pipeline-Steuerung in der Datei-Vorschau (Einzeldatei) <code>MediaBatchDialog</code> Batch-Verarbeitung von Verzeichnissen (alle Medientypen)"},{"location":"architecture/pipeline-phases.html#mediabatchdialog-ehemals-pdfbulkimportdialog","title":"MediaBatchDialog (ehemals PdfBulkImportDialog)","text":"<p>Der Dialog f\u00fcr Batch-Verarbeitung unterst\u00fctzt jetzt alle Medientypen:</p> <ul> <li>Scannt Verzeichnisse nach unterst\u00fctzten Dateien (PDF, Audio, Video, Markdown)</li> <li>Verwendet die Library-Standardwerte f\u00fcr Template und Sprache</li> <li>Ruft <code>/api/pipeline/process</code> mit <code>items[]</code> f\u00fcr Batch-Verarbeitung auf</li> <li>Zeigt Fortschritt und Ergebnisse (Erfolge/Fehler) an</li> </ul>"},{"location":"architecture/pipeline-phases.html#legacy-endpoints-deprecated","title":"Legacy-Endpoints (Deprecated)","text":"<p>Die folgenden Endpoints existieren noch, werden aber nicht mehr prim\u00e4r verwendet:</p> Endpoint Medientyp Status <code>/api/secretary/process-pdf</code> PDF Deprecated <code>/api/secretary/process-audio/job</code> Audio Deprecated <code>/api/secretary/process-video/job</code> Video Deprecated <code>/api/secretary/process-text/job</code> Markdown Deprecated <code>/api/secretary/process-pdf/batch</code> PDF (Batch) Deprecated <p>Empfehlung: F\u00fcr neue Entwicklungen immer <code>/api/pipeline/process</code> verwenden.</p>"},{"location":"architecture/requirements-artifact-pipeline-v3.html","title":"Requirements artifact pipeline v3","text":""},{"location":"architecture/requirements-artifact-pipeline-v3.html#ziel","title":"Ziel","text":"<p>Diese Anforderungen definieren die artefakt\u2011zentrierte Pipeline (Variante 3) in einer Weise, die:</p> <ul> <li>Implementierung mit minimalem Code erm\u00f6glicht (Strangler, additive Erweiterung),</li> <li>Regression-Risiken kontrolliert,</li> <li>neue Quellen/Formate (PDF, Audio, Video, DOCX, XLSX, \u2026) \u00fcber dieselbe Orchestrierung integrierbar macht.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#ausgangslage-annahmen","title":"Ausgangslage / Annahmen","text":"<ul> <li>Alle operativen Extractionen und Transformationen laufen im Secretary Service (kein lokales Extrahieren im Next.js Backend).</li> <li>Orchestrierung erfolgt \u00fcber bestehende External Jobs (Worker + Start + Callback + Phasenmodule).</li> <li>Deployment ist Single\u2011Node, daher funktioniert der in-memory SSE EventBus zuverl\u00e4ssig.</li> <li>Template\u2011Identit\u00e4t ist Name-only (kein Version/Hash im Artefakt-Namen).</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#functional-requirements-fr","title":"Functional Requirements (FR)","text":""},{"location":"architecture/requirements-artifact-pipeline-v3.html#fr1-einheitliches-artefaktmodell","title":"FR\u20111: Einheitliches Artefaktmodell","text":"<ul> <li>F\u00fcr jede Quelle entstehen Artefakte im Shadow\u2011Twin:</li> <li>Extract/Transcript: <code>{base}.{lang}.md</code></li> <li>Transformation: <code>{base}.{template}.{lang}.md</code></li> <li>Assets (z.B. PDF pages/images ZIP) werden als URLs/Refs verwaltet; keine gro\u00dfen Base64 Payloads als Standard.</li> <li>Storage Policy (Zielbild):</li> <li>Dot\u2011Folder ist kanonisch f\u00fcr alle Medien (Write-Pfad).</li> <li>Siblings gelten als Legacy und werden nur noch als Read-Only Fallback toleriert, bis ein Repair/Migration-Run sie eliminiert.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#fr2-template-ziel-quelle-agnostisch","title":"FR\u20112: Template = Ziel (quelle-agnostisch)","text":"<ul> <li>Template definiert Ziel\u2011Markdown + Frontmatter (Felder/Facetten/Struktur).</li> <li>Quelle liefert nur Extract (Text/Markdown + Assets), ohne \u201eAnalyse\u2011Speziallogik\u201c pro Format im UI.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#fr3-eine-orchestrierung-strangler","title":"FR\u20113: Eine Orchestrierung (Strangler)","text":"<ul> <li>Kein paralleler Orchestrator.</li> <li>Neue Formate werden additiv \u00fcber neue Jobtypen/Adapter integriert.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#fr4-gatespolicies-idempotenz-wiederaufnahme","title":"FR\u20114: Gates/Policies (Idempotenz &amp; Wiederaufnahme)","text":"<ul> <li>Gates entscheiden pro Phase, ob bereits vorhandene Artefakte eine Phase skippen.</li> <li>Policies k\u00f6nnen Gates \u00fcberschreiben (z.B. <code>force</code>).</li> <li>Reruns erzeugen keine doppelten Artefakte und keine doppelten Ingest\u2011Chunks.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#fr5-ingest-rag","title":"FR\u20115: Ingest (RAG)","text":"<ul> <li>Ingest verwendet bevorzugt das transformierte Markdown (Transformation\u2011Artefakt).</li> <li>Ergebnis wird in MongoDB Vector Search gespeichert (Meta + Chunks) und ist \u00fcber UI nutzbar.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#fr6-uxentrypoints","title":"FR\u20116: UX/Entry\u2011Points","text":"<ul> <li>Archiv\u2011Pro:</li> <li>Single\u2011File Verarbeitung aus File\u2011Liste</li> <li>Batch/Verzeichnis Jobs erzeugen und \u00fcberwachen</li> <li>Wizard\u2011User:</li> <li>Quelle w\u00e4hlen \u2192 Template w\u00e4hlen \u2192 Start \u2192 Ergebnis anzeigen/\u00f6ffnen</li> <li>Automation:</li> <li>API Jobs triggern, Status &amp; Result refs abrufen</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#fr7-live-status-async-ergebnis","title":"FR\u20117: Live Status / Async Ergebnis","text":"<ul> <li>UI erh\u00e4lt Live Updates \u00fcber SSE (job_update).</li> <li>UI kann nach <code>completed</code> das Ergebnisartefakt \u00f6ffnen/selektieren.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#nonfunctional-requirements-nfr","title":"Non\u2011Functional Requirements (NFR)","text":""},{"location":"architecture/requirements-artifact-pipeline-v3.html#nfr1-observability-minimal-aber-ausreichend","title":"NFR\u20111: Observability (minimal, aber ausreichend)","text":"<ul> <li>Jobs haben nachvollziehbare Steps/Trace/Fehlercodes.</li> <li>Watchdog verhindert \u201eh\u00e4ngende\u201c Jobs.</li> <li>Logs sind zielgerichtet (nicht spammy).</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#nfr2-performance","title":"NFR\u20112: Performance","text":"<ul> <li>Worker kann mehrere Jobs parallel verarbeiten (konfigurierbare Concurrency).</li> <li>Gro\u00dfe Assets werden als URLs/ZIP gehandhabt, nicht als Base64.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#nfr3-sicherheit","title":"NFR\u20113: Sicherheit","text":"<ul> <li>Keine Secrets/Tokens an Client ausgeben.</li> <li>Secretary Auth via Server\u2011Routes; interne Tokens maskieren.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#nfr4-kompatibilitat-regression-safety","title":"NFR\u20114: Kompatibilit\u00e4t (Regression Safety)","text":"<ul> <li>Bestehende Flows bleiben funktionsf\u00e4hig.</li> <li>Neue V3 Pfade sind additiv und abschaltbar (Entry\u2011Point Feature Gate).</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#risiken-guardrails","title":"Risiken / Guardrails","text":""},{"location":"architecture/requirements-artifact-pipeline-v3.html#risiko-template-name-only-ist-nicht-reproduzierbar","title":"Risiko: Template Name-only ist nicht reproduzierbar","text":"<ul> <li>Guardrail: optionales Frontmatter <code>template_revision</code> (z.B. timestamp/hash) wird beim Run gespeichert.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#risiko-sse-eventbus-ist-in-memory","title":"Risiko: SSE EventBus ist in-memory","text":"<ul> <li>Single\u2011Node ok.</li> <li>Multi\u2011Node/Serverless ben\u00f6tigt sp\u00e4ter Redis/DB PubSub; dokumentiert als zuk\u00fcnftige Erweiterung.</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#risiko-secretary-endpoints-fur-docxxlsx-evtl-nicht-vorhanden","title":"Risiko: Secretary Endpoints f\u00fcr DOCX/XLSX evtl. nicht vorhanden","text":"<ul> <li>Guardrail: Schnittstellen zuerst dokumentieren; fehlende Endpoints als separaten Task planen (Secretary Erweiterung oder Adapter).</li> </ul>"},{"location":"architecture/requirements-artifact-pipeline-v3.html#v0-acceptance-pdf-mistral-ocr-pagesimages","title":"V0 Acceptance (PDF Mistral OCR + Pages/Images)","text":"<p>Die V0 Definition of Done wird im Design/Plan dokumentiert; V0 ist die harte Abnahmebasis, bevor V1 (weitere Formate/Entry\u2011Points) folgt.</p>"},{"location":"architecture/secretary-format-interfaces.html","title":"Secretary format interfaces","text":""},{"location":"architecture/secretary-format-interfaces.html#ziel","title":"Ziel","text":"<p>Dieses Dokument definiert die formatspezifischen Schnittstellen zwischen:</p> <ul> <li>CommonKnowledgeScout (Next.js App) als Orchestrator/Proxy/Artifact-Manager</li> <li>Common Secretary Services als einzigem System f\u00fcr Extraction und Transformation</li> </ul> <p>Ziel ist ein Implementationsvertrag f\u00fcr die artefakt\u2011zentrierte Pipeline (Variante 3), insbesondere f\u00fcr V0 (PDF Mistral OCR + Pages/Images) und V1 (Audio/Video/YouTube/DOCX/XLSX).</p> <p>Quellen: - API overview (work-in-progress): <code>docs/_analysis/SecretaryService API overview.md</code> - Bestehende Next Routes: <code>src/app/api/secretary/*/route.ts</code> - Bestehende Typen: <code>src/lib/secretary/client.ts</code></p>"},{"location":"architecture/secretary-format-interfaces.html#gemeinsame-prinzipien-fur-alle-formate","title":"Gemeinsame Prinzipien (f\u00fcr alle Formate)","text":""},{"location":"architecture/secretary-format-interfaces.html#auth","title":"Auth","text":"<ul> <li>Next.js \u2192 Secretary: <code>Authorization: Bearer &lt;SECRETARY_SERVICE_API_KEY&gt;</code> oder <code>X-Secretary-Api-Key: &lt;...&gt;</code></li> <li>Client \u2192 Next.js: Clerk Auth (wie in den bestehenden Routes)</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#standard-response-secretary","title":"Standard-Response (Secretary)","text":"<ul> <li>Responses folgen einem Standard-Schema mit <code>status</code>, optional <code>request</code>, optional <code>process</code>, <code>data</code>, <code>error</code>.</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#async-orchestrierung-variante-3","title":"Async Orchestrierung (Variante 3)","text":"<ul> <li>F\u00fcr lange Prozesse (PDF Mistral OCR, Video, gro\u00dfe Dateien) gilt: Next erstellt External Job, Worker startet, Secretary liefert Ergebnis via Callback/Webhook (oder Next pollt).</li> <li>UI erh\u00e4lt Updates \u00fcber SSE <code>/api/external/jobs/stream</code>.</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#artefakt-outputs-shadow-twin","title":"Artefakt-Outputs (Shadow Twin)","text":"<ul> <li>Extract/Transcript: <code>{base}.{lang}.md</code></li> <li>Transformation: <code>{base}.{template}.{lang}.md</code></li> <li>Assets: per URL/Refs (ZIP/Files), keine gro\u00dfen Base64 als Standard.</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#pdf-mistral-ocr-v0-pflicht","title":"PDF \u2013 Mistral OCR (V0 Pflicht)","text":""},{"location":"architecture/secretary-format-interfaces.html#next-entry-point-bestehend","title":"Next Entry Point (bestehend)","text":"<ul> <li><code>POST /api/secretary/process-pdf</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#request-formdata","title":"Request (FormData)","text":"<ul> <li><code>file</code>: PDF Datei</li> <li><code>targetLanguage</code>: string, default <code>de</code></li> <li><code>extractionMethod</code>: string, f\u00fcr V0 = <code>mistral_ocr</code></li> <li><code>includeOcrImages</code>: boolean string (<code>true|false</code>) \u2013 default bei <code>mistral_ocr</code> = <code>true</code></li> <li><code>includePageImages</code>: boolean string (<code>true|false</code>) \u2013 default bei <code>mistral_ocr</code> = <code>true</code></li> <li><code>useCache</code>: string (<code>true|false</code>)</li> <li>optional: <code>template</code>: string (f\u00fcr template\u2011Phase)</li> <li>optional: <code>policies</code>: JSON string (extract/metadata/ingest)</li> <li>optional (Batch): <code>batchId</code>, <code>batchName</code></li> <li>optional: <code>originalItemId</code>, <code>parentId</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#response-json","title":"Response (JSON)","text":"<ul> <li><code>{ status: 'accepted', job: { id: string } }</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#secretary-endpoint-extern","title":"Secretary Endpoint (extern)","text":"<ul> <li><code>POST /api/pdf/process-mistral-ocr</code> (laut API overview)</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#callback-payload-erwartete-felder","title":"Callback Payload (erwartete Felder)","text":"<p>Minimal ben\u00f6tigt: - <code>data.extracted_text</code> (Markdown/Text) - <code>data.pages_archive_url</code> (ZIP: Pages als Bilder) oder \u00e4quivalent - <code>data.images_archive_url</code> oder <code>data.mistral_ocr_images_url</code> (ZIP: extrahierte Bilder) oder \u00e4quivalent - optional: <code>data.mistral_ocr_raw_url</code> / <code>data.mistral_ocr_raw_metadata</code></p> <p>Guardrail: - Keine gro\u00dfen Base64 Blobs im Job-Dokument persistieren; URLs/Refs bevorzugen.</p>"},{"location":"architecture/secretary-format-interfaces.html#audio","title":"Audio","text":""},{"location":"architecture/secretary-format-interfaces.html#next-entry-point-bestehend_1","title":"Next Entry Point (bestehend)","text":"<ul> <li><code>POST /api/secretary/process-audio</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#request-formdata_1","title":"Request (FormData)","text":"<ul> <li><code>file</code>: Audio Datei</li> <li>optional: <code>source_language</code> oder <code>sourceLanguage</code></li> <li><code>target_language</code> oder <code>targetLanguage</code> (default <code>de</code>)</li> <li>optional: <code>template</code> (wenn Secretary direkt templatebasiert transformieren soll)</li> <li><code>useCache</code> wird in der Route aktuell fest auf <code>false</code> gesetzt</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#response","title":"Response","text":"<ul> <li>passt zu <code>SecretaryAudioResponse</code> (siehe <code>src/lib/secretary/client.ts</code>)</li> <li>insbesondere: <code>data.transcription.text</code>, <code>data.transcription.source_language</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#secretary-endpoint-extern_1","title":"Secretary Endpoint (extern)","text":"<ul> <li><code>POST /api/audio/process</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#video","title":"Video","text":""},{"location":"architecture/secretary-format-interfaces.html#next-entry-point-bestehend_2","title":"Next Entry Point (bestehend)","text":"<ul> <li><code>POST /api/secretary/process-video</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#request-formdata_2","title":"Request (FormData)","text":"<ul> <li><code>file</code>: Video Datei (oder URL \u2013 abh\u00e4ngig von geplanter Erweiterung)</li> <li><code>targetLanguage</code> \u2192 mapped auf <code>target_language</code></li> <li><code>sourceLanguage</code> \u2192 mapped auf <code>source_language</code> (default <code>auto</code>)</li> <li>optional: <code>template</code></li> <li>optional: <code>useCache</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#response_1","title":"Response","text":"<ul> <li>passt zu <code>SecretaryVideoResponse</code> (siehe <code>src/lib/secretary/client.ts</code>)</li> <li>insbesondere: <code>data.transcription.text</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#secretary-endpoint-extern_2","title":"Secretary Endpoint (extern)","text":"<ul> <li><code>POST /api/video/process</code></li> <li>F\u00fcr YouTube (extern): <code>POST /api/video/youtube</code> (noch als dedizierter Next Proxy zu erg\u00e4nzen/standardisieren)</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#text-markdown-txt","title":"Text / Markdown / TXT","text":""},{"location":"architecture/secretary-format-interfaces.html#next-entry-point-bestehend_3","title":"Next Entry Point (bestehend)","text":"<ul> <li><code>POST /api/secretary/process-text</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#request-formdata_3","title":"Request (FormData)","text":"<ul> <li><code>text</code>: string (Korpus oder File\u2011Text)</li> <li><code>target_language</code> oder <code>targetLanguage</code></li> <li><code>source_language</code> optional</li> <li><code>template</code> (Name) oder <code>template_content</code></li> <li>Header <code>X-Library-Id</code>: zur Template-Aufl\u00f6sung aus MongoDB (falls kein Standard-Template)</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#response_2","title":"Response","text":"<ul> <li>Route gibt aktuell <code>data.data</code> zur\u00fcck (nicht die gesamte Secretary Response).</li> <li>Erwartet: <code>structured_data</code> + <code>markdown</code> (je nach Secretary Template Output).</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#secretary-endpoint-extern_3","title":"Secretary Endpoint (extern)","text":"<ul> <li><code>POST /api/transformer/template</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#url-website-extract","title":"URL / Website Extract","text":""},{"location":"architecture/secretary-format-interfaces.html#next-entry-point-bestehend_4","title":"Next Entry Point (bestehend)","text":"<ul> <li><code>POST /api/secretary/import-from-url</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#ziel_1","title":"Ziel","text":"<ul> <li>Website/Text extrahieren und in einem Folge-Schritt via <code>process-text</code> template-basiert transformieren.</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#docx-word-contract-noch-fehlend-in-nextsecretary","title":"DOCX (Word) \u2013 Contract (noch fehlend in Next/Secretary)","text":"<p>Status: noch nicht als Next Route dokumentiert. F\u00fcr V1 definieren wir den erwarteten Contract.</p>"},{"location":"architecture/secretary-format-interfaces.html#erwarteter-secretary-endpoint-extern-zu-erganzen","title":"Erwarteter Secretary Endpoint (extern, zu erg\u00e4nzen)","text":"<ul> <li>Vorschlag: <code>POST /api/document/docx</code> oder <code>POST /api/transformer/file</code> (falls Secretary bereits ein generisches File\u2011Transform hat)</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#erwarteter-output","title":"Erwarteter Output","text":"<ul> <li><code>data.extracted_text</code> als Markdown/Text mit Struktur (\u00dcberschriften, Listen, Tabellen als Markdown).</li> <li>optional: Asset\u2011Refs (eingebettete Bilder).</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#xlsx-excel-contract-noch-fehlend-in-nextsecretary","title":"XLSX (Excel) \u2013 Contract (noch fehlend in Next/Secretary)","text":"<p>Status: noch nicht als Next Route dokumentiert. F\u00fcr V1 definieren wir den erwarteten Contract.</p>"},{"location":"architecture/secretary-format-interfaces.html#erwarteter-secretary-endpoint-extern-zu-erganzen_1","title":"Erwarteter Secretary Endpoint (extern, zu erg\u00e4nzen)","text":"<ul> <li>Vorschlag: <code>POST /api/document/xlsx</code> oder <code>POST /api/transformer/html-table</code> (falls als Zwischenschritt)</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#erwarteter-output_1","title":"Erwarteter Output","text":"<ul> <li><code>data.extracted_text</code> als Markdown mit Tabellen/Summary pro Sheet.</li> <li>optional: strukturierte Daten f\u00fcr Facetten.</li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#image-ocr-spater","title":"Image OCR (sp\u00e4ter)","text":""},{"location":"architecture/secretary-format-interfaces.html#next-entry-point-bestehend_5","title":"Next Entry Point (bestehend)","text":"<ul> <li><code>POST /api/secretary/process-image</code></li> </ul>"},{"location":"architecture/secretary-format-interfaces.html#secretary-endpoint-extern_4","title":"Secretary Endpoint (extern)","text":"<ul> <li><code>POST /api/imageocr/process</code></li> </ul>"},{"location":"architecture/shadow-twin.html","title":"Shadow\u2011Twin (architecture)","text":"<p>Status: active Last verified: 2026-01-06  </p> <p>User-facing overview: <code>docs/guides/shadow-twin.md</code></p>"},{"location":"architecture/shadow-twin.html#scope","title":"Scope","text":"<p>This document describes the intended storage model and contracts for Shadow\u2011Twin artifacts in the current system. It is intentionally focused on naming, layout, and resolver/writer contracts (not UI details).</p>"},{"location":"architecture/shadow-twin.html#glossary","title":"Glossary","text":"<ul> <li>Source file: the original file (PDF/audio/video/image/\u2026).</li> <li>Shadow\u2011Twin: derived artifacts (Markdown + assets) stored next to the source.</li> <li>Transcript: extracted text as Markdown (typically without frontmatter).</li> <li>Transformation: template-based Markdown with frontmatter/metadata.</li> <li>Dot-folder: hidden folder <code>.{originalName}</code> grouping multiple related artifacts.</li> </ul>"},{"location":"architecture/shadow-twin.html#concept","title":"Concept","text":"<p>A Shadow\u2011Twin is the text/metadata representation of an original file (PDF, audio, video, image, \u2026). It may include: - Markdown artifacts (transcript + transformation) - Images/assets (e.g. extracted from PDFs)</p> <p>Shadow\u2011Twins exist to enable: - searchability - structured metadata - reliable downstream ingestion / RAG</p>"},{"location":"architecture/shadow-twin.html#user-story-mapping-how-this-feels-in-the-ui","title":"User story mapping (how this feels in the UI)","text":"<p>Even for expert users, the mental model is usually intent-driven, not file-driven. We therefore describe the pipeline as a 3\u2011step story:</p> <ol> <li>Text erzeugen (media-dependent)</li> <li>PDF/Image: OCR/Extract \u2192 transcript artifact</li> <li>Audio/Video: Transkription \u2192 transcript artifact</li> <li>Transformieren (journalistic moment)</li> <li>LLM/template converts raw text into structured, meaningful content \u2192 transformation artifact</li> <li>Ver\u00f6ffentlichen</li> <li>ingestion into the Library/RAG index \u2192 Mongo Vector Search (meta + chunks)</li> </ol> <p>Storage-wise these steps map deterministically to Shadow\u2011Twin artifacts: - Step 1 \u2192 Transcript <code>{base}.{lang}.md</code> - Step 2 \u2192 Transformation <code>{base}.{template}.{lang}.md</code> - Step 3 \u2192 Ingestion records keyed by the source fileId (index/chunks)</p>"},{"location":"architecture/shadow-twin.html#storage-layout","title":"Storage layout","text":"<p>Shadow\u2011Twins have a single canonical write layout and one legacy read fallback.</p>"},{"location":"architecture/shadow-twin.html#1-dotfolder-canonical","title":"1) Dot\u2011folder (canonical)","text":"<p>Hidden folder (starts with <code>.</code>), containing all related files:</p> <pre><code>.document.pdf/\n\u251c\u2500\u2500 document.de.md                 (Transcript)\n\u251c\u2500\u2500 document.&lt;template&gt;.de.md      (Transformation)\n\u251c\u2500\u2500 page-001.png                   (Extracted images)\n\u2514\u2500\u2500 ...\n</code></pre> <p>Folder naming: <code>.{originalName}</code> (e.g. <code>.document.pdf/</code>) Length limit: 255 characters (truncated if necessary).</p>"},{"location":"architecture/shadow-twin.html#2-siblings-legacy-read-fallback-only","title":"2) Siblings (legacy read fallback only)","text":"<p>Files stored next to the original (legacy). The system may still resolve these for backwards compatibility, but new writes should not create siblings. A future repair/migration run is expected to move siblings into the dot-folder and remove them.</p> <pre><code>document.pdf\ndocument.de.md                 (Transcript)\ndocument.&lt;template&gt;.de.md      (Transformation)\n</code></pre>"},{"location":"architecture/shadow-twin.html#naming-conventions-current","title":"Naming conventions (current)","text":""},{"location":"architecture/shadow-twin.html#transcript-artifact","title":"Transcript artifact","text":"<ul> <li>Format: <code>{baseName}.{language}.md</code></li> <li>Example: <code>document.de.md</code></li> <li>Created: after Extract/Transcribe</li> <li>Content: extracted markdown (typically without frontmatter)</li> </ul>"},{"location":"architecture/shadow-twin.html#transformation-artifact","title":"Transformation artifact","text":"<ul> <li>Format: <code>{baseName}.{templateName}.{language}.md</code></li> <li>Example: <code>document.pdfanalyse.de.md</code></li> <li>Created: after Template transformation</li> <li>Content: markdown with frontmatter/metadata</li> </ul>"},{"location":"architecture/shadow-twin.html#dotfolder","title":"Dot\u2011folder","text":"<ul> <li>Format: <code>.{originalName}</code></li> <li>Example: <code>.document.pdf/</code></li> </ul>"},{"location":"architecture/shadow-twin.html#resolution-model-how-the-ui-finds-the-right-artifact","title":"Resolution model (how the UI finds the \u201cright\u201d artifact)","text":"<p>For library browsing (e.g. <code>file-list.tsx</code>) the UI does not implement filename heuristics. Instead:</p> <ol> <li>UI calls <code>POST /api/library/[libraryId]/artifacts/batch-resolve</code> (in batches of \u2264100).</li> <li>Server resolves each source via <code>resolveArtifact()</code>:</li> <li>checks the dot\u2011folder first (if present)</li> <li>falls back to siblings</li> <li>if <code>preferredKind === 'transformation'</code> and no <code>templateName</code> is provided, the resolver selects the best matching transformation for the language (currently: newest by <code>modifiedAt</code>)</li> <li>Server returns <code>ResolvedArtifactWithItem</code> so the UI does not need additional per-item fetches.</li> </ol> <p>Entry points: - <code>src/app/api/library/[libraryId]/artifacts/batch-resolve/route.ts</code> - <code>src/lib/shadow-twin/artifact-resolver.ts</code> - <code>src/lib/shadow-twin/artifact-client.ts</code> - <code>src/hooks/use-shadow-twin-analysis.ts</code></p>"},{"location":"architecture/shadow-twin.html#writing-model-how-artifacts-are-stored","title":"Writing model (how artifacts are stored)","text":"<p>Writing is centralized to avoid duplicates and to enforce deterministic updates: - <code>writeArtifact()</code> uses a canonical filename derived from the artifact key - if the target file already exists \u2192 it is overwritten (update, not duplicate) - optionally writes into a dot\u2011folder (when needed for related assets)</p> <p>Entry point: - <code>src/lib/shadow-twin/artifact-writer.ts</code></p>"},{"location":"architecture/shadow-twin.html#code-references-current","title":"Code references (current)","text":"<ul> <li>Naming &amp; parsing: <code>src/lib/shadow-twin/artifact-naming.ts</code></li> <li>Resolver: <code>src/lib/shadow-twin/artifact-resolver.ts</code></li> <li>Writer: <code>src/lib/shadow-twin/artifact-writer.ts</code></li> <li>Bulk API: <code>src/app/api/library/[libraryId]/artifacts/batch-resolve/route.ts</code></li> <li>Client wrapper: <code>src/lib/shadow-twin/artifact-client.ts</code></li> </ul>"},{"location":"architecture/shadow-twin.html#usage-examples","title":"Usage examples","text":""},{"location":"architecture/shadow-twin.html#resolve-an-artifact-server-side","title":"Resolve an artifact (server-side)","text":"<pre><code>import { resolveArtifact } from '@/lib/shadow-twin/artifact-resolver';\n\nconst resolved = await resolveArtifact(provider, {\n  sourceItemId,\n  sourceName: 'document.pdf',\n  parentId,\n  targetLanguage: 'de',\n  preferredKind: 'transformation',\n  templateName: 'pdfanalyse',\n});\n</code></pre>"},{"location":"architecture/shadow-twin.html#write-an-artifact-server-side","title":"Write an artifact (server-side)","text":"<pre><code>import { writeArtifact } from '@/lib/shadow-twin/artifact-writer';\n\nawait writeArtifact(provider, {\n  key: {\n    sourceId: sourceItemId,\n    kind: 'transformation',\n    targetLanguage: 'de',\n    templateName: 'pdfanalyse',\n  },\n  sourceName: 'document.pdf',\n  parentId,\n  content: markdownWithFrontmatter,\n  createFolder: true,\n});\n</code></pre>"},{"location":"architecture/shadow-twin.html#best-practices","title":"Best practices","text":"<ol> <li>UI must not implement filename heuristics: use the bulk resolver API.</li> <li>Use centralized naming: <code>buildArtifactName()</code> for canonical filenames.</li> <li>Use centralized writing: <code>writeArtifact()</code> to enforce update semantics.</li> <li>Dot\u2011folder naming must respect the 255 char limit: rely on <code>generateShadowTwinFolderName()</code>.</li> </ol>"},{"location":"architecture/template-system.html","title":"Template-System (MongoDB Templates, Secretary-Transformation, Creation Wizard)","text":""},{"location":"architecture/template-system.html#warum-dieses-dokument","title":"Warum dieses Dokument?","text":"<p>Im Projekt wird \u201eTemplate\u201c in unterschiedlichen Kontexten benutzt. Das f\u00fchrt leicht zu Fehlinterpretationen. Dieses Dokument beschreibt das tats\u00e4chliche System (Source of Truth, Datenmodell, Flows) und \u00fcbersetzt es in den \u201eJournalist\u2011Moment\u201c: Was der Anwender im Template\u2011Editor definiert und was dann wo passiert.</p>"},{"location":"architecture/template-system.html#kernaussage-eine-zeile","title":"Kernaussage (eine Zeile)","text":"<p>Ein Template ist ein MongoDB-Dokument (<code>TemplateDocument</code>), das gleichzeitig (A) ein extraktives Schema + Regeln f\u00fcr Secretary und (B) einen optionalen Creation\u2011Flow f\u00fcr den Wizard enth\u00e4lt.</p>"},{"location":"architecture/template-system.html#begriffe-prazise","title":"Begriffe (pr\u00e4zise)","text":""},{"location":"architecture/template-system.html#1-templatedocument-source-of-truth","title":"1) TemplateDocument (Source of Truth)","text":"<p>Ein Template wird in MongoDB gespeichert und ist strukturiert:</p> <ul> <li><code>metadata.fields[]</code>: Frontmatter-Felder als \u201eFragen\u201c / Platzhalter (extraktiv).</li> <li><code>systemprompt</code>: Rolle/Regeln/Policies f\u00fcr die Transformation.</li> <li><code>markdownBody</code>: Ausgabeformat als Markdown (mit Platzhaltern <code>{{key|...}}</code>).</li> <li><code>creation</code> (optional): UI-Flow f\u00fcr den Creation Wizard (Steps, supportedSources, preview, save rules).</li> </ul> <p>Typdefinition: <code>src/lib/templates/template-types.ts</code> (<code>TemplateDocument</code>).</p>"},{"location":"architecture/template-system.html#2-secretary-template-content-wire-format","title":"2) Secretary-Template-Content (Wire Format)","text":"<p>Der Secretary Service bekommt keinen <code>TemplateDocument</code> als JSON, sondern Markdown mit YAML-Frontmatter + systemprompt + body.</p> <p>Wichtig: Der Secretary kann nur \u201eflaches YAML\u201c \u2013 daher wird der <code>creation</code>\u2011Block vor dem Senden entfernt.</p>"},{"location":"architecture/template-system.html#3-templates-ordner-im-library-storage-legacyimport","title":"3) /templates Ordner im Library-Storage (Legacy/Import)","text":"<p>Es gibt zus\u00e4tzlich ein Legacy-Konzept \u201eTemplates als Dateien im Library-Root <code>/templates</code> Ordner\u201c. Dieses Konzept wird heute vor allem f\u00fcr Import nach MongoDB genutzt (<code>/api/templates/import</code>). Es ist nicht die prim\u00e4re Quelle f\u00fcr die laufende Transformation, wenn Templates in MongoDB vorhanden sind.</p>"},{"location":"architecture/template-system.html#der-journalistmoment-im-templateeditor-wie-der-anwender-denkt","title":"Der \u201eJournalist\u2011Moment\u201c im Template\u2011Editor (wie der Anwender denkt)","text":"<p>Im Template-Editor werden (in einem Dokument) vier Dinge gepflegt:</p> <p>1) Schema / Metadaten (Frontmatter)    - \u201eWelche F\u00e4lle/Felder sollen extrahiert werden?\u201c    - \u2192 <code>metadata.fields[]</code> (Key + Frage/Description + rawValue)</p> <p>2) Rollenanweisung / Regeln    - \u201eWie streng/extraktiv? Welche Priorit\u00e4ten? Welche Normalisierung?\u201c    - \u2192 <code>systemprompt</code></p> <p>3) Struktur / Ausgabeformat    - \u201eWie soll der Bericht aussehen?\u201c (Markdown mit Platzhaltern)    - \u2192 <code>markdownBody</code></p> <p>4) Creation Flow    - \u201eWie f\u00fchrt der Wizard den User durch die Datenerfassung?\u201c    - \u2192 <code>creation</code> (optional)</p> <p>UI: <code>src/components/templates/structured-template-editor.tsx</code> und <code>src/components/templates/template-management.tsx</code>.</p>"},{"location":"architecture/template-system.html#wie-das-system-das-template-benutzt-3-wichtigste-flows","title":"Wie das System das Template benutzt (3 wichtigste Flows)","text":""},{"location":"architecture/template-system.html#flow-a-external-jobs-artefakt-pipeline","title":"Flow A: External Jobs (Artefakt-Pipeline)","text":"<pre><code>flowchart TD\n  job[External Job] --&gt; pick[pickTemplate() aus MongoDB]\n  pick --&gt; serialize[serializeTemplateToMarkdown(includeCreation=false)]\n  serialize --&gt; secretary[Secretary /transformer/template]\n  secretary --&gt; transformMd[Transformations-Artefakt speichern]</code></pre> <ul> <li>Template-Load: <code>src/lib/external-jobs/template-files.ts</code> (<code>pickTemplate</code>)</li> <li>Serialisierung: <code>src/lib/templates/template-service-mongodb.ts</code> (<code>serializeTemplateToMarkdown</code>)</li> </ul>"},{"location":"architecture/template-system.html#flow-b-prozess-text-felder-wizard-template-tests","title":"Flow B: Prozess \u201eText \u2192 Felder\u201c (Wizard &amp; Template-Tests)","text":"<p>Wizard/Tests rufen heute h\u00e4ufig <code>POST /api/secretary/process-text</code>:</p> <ul> <li>Wenn <code>template</code> kein Standard-Template ist, wird das Template aus MongoDB geladen.</li> <li>Danach wird es in Secretary\u2011kompatibles Template-Content serialisiert (ohne <code>creation</code>).</li> </ul> <p>Route: <code>src/app/api/secretary/process-text/route.ts</code></p>"},{"location":"architecture/template-system.html#flow-c-creation-wizard-ui","title":"Flow C: Creation Wizard (UI)","text":"<p>Der Wizard l\u00e4dt die Template-Konfiguration als JSON (inkl. <code>creation</code>) aus MongoDB:</p> <ul> <li>Client Load: <code>src/lib/templates/template-service-client.ts</code> (<code>loadTemplateConfig</code>)</li> <li>Wizard UI: <code>src/components/creation-wizard/creation-wizard.tsx</code></li> </ul> <p>Der Wizard nutzt also:</p> <ul> <li><code>creation</code> f\u00fcr Steps/UX</li> <li><code>metadata.fields</code> f\u00fcr Felder/Frontmatter-Keys</li> <li><code>markdownBody</code> f\u00fcr Preview/Render</li> </ul>"},{"location":"architecture/template-system.html#wo-es-leicht-schiefgeht-typische-missverstandnisse","title":"Wo es leicht schiefgeht (typische Missverst\u00e4ndnisse)","text":"<p>1) \u201eTemplate = template-samples/pdfanalyse.md im Repo\u201c    - Das Repo-File ist eine Snapshot/Referenz, nicht automatisch die laufende Quelle.    - Laufende Quelle ist: MongoDB Template-Dokument (Name <code>pdfanalyse</code>).</p> <p>2) \u201eCreation geh\u00f6rt in Secretary Template\u201c    - Intern ja (weil es im gleichen Dokument gespeichert ist).    - Aber wire-format an Secretary: <code>creation</code> muss entfernt werden.</p> <p>3) \u201eTemplate-Service l\u00e4dt aus /templates, also ist /templates Source of Truth\u201c    - Das stimmt nur f\u00fcr den Legacy Storage Import.    - F\u00fcr Pipeline/Wizard ist MongoDB die prim\u00e4re Quelle.</p>"},{"location":"architecture/template-system.html#empfehlung-aktuelle-richtung","title":"Empfehlung (aktuelle Richtung)","text":"<ul> <li>MongoDB ist Source of Truth f\u00fcr Templates.</li> <li><code>/templates</code> im Library-Storage ist optionaler Importpfad.</li> <li>Repo-Ordner <code>template-samples/</code> sollte als \u201eBeispiel/Export\u201c dokumentiert werden, nicht als aktive Quelle.</li> </ul>"},{"location":"architecture/testimonial-artifacts.html","title":"Testimonial-Artefakte: Was steht wo?","text":""},{"location":"architecture/testimonial-artifacts.html#ubersicht","title":"\u00dcbersicht","text":"<p>Bei der Erstellung eines Testimonials (anonym oder \u00fcber Wizard) werden zwei Dateien erstellt:</p> <ol> <li>Source-Datei (<code>source.txt</code> oder <code>audio.webm</code>)</li> <li>Transcript-Artefakt (<code>source.de.md</code>)</li> </ol> <p>WICHTIG: Das Transformation-Artefakt wird nicht bei der Erstellung erstellt, sondern sp\u00e4ter im Finalisieren-Wizard, wo alle Testimonial-Transcripte zusammen verarbeitet werden.</p>"},{"location":"architecture/testimonial-artifacts.html#dateistruktur","title":"Dateistruktur","text":"<pre><code>testimonials/\n\u2514\u2500\u2500 {testimonial-id}/                    (z.B. 2e305b30-395c-4cab-bdaf-7f67f5afa000)\n    \u251c\u2500\u2500 source.txt                       (Source: User-Eingabe)\n    \u2514\u2500\u2500 .source.txt/                      (Shadow-Twin Dot-Folder)\n        \u2514\u2500\u2500 source.de.md                 (Transcript-Artefakt)\n\n# Transformation-Artefakt wird sp\u00e4ter im Finalisieren-Wizard erstellt\n</code></pre>"},{"location":"architecture/testimonial-artifacts.html#1-source-datei","title":"1. Source-Datei","text":"<p>Dateiname: <code>source.txt</code> (wenn Text) oder <code>audio.webm</code> (wenn Audio)</p> <p>Inhalt:  - Text-Fall: Roher Text, den der User eingegeben hat - Audio-Fall: Audio-Datei (WebM-Format)</p> <p>Zweck:  - Original-Quelle des Testimonials - Wird f\u00fcr sp\u00e4tere Re-Transformation verwendet - Erm\u00f6glicht Nachvollziehbarkeit</p> <p>Beispiel (<code>source.txt</code>): <pre><code>Das ist mein Testimonial-Text, den ich eingegeben habe.\n</code></pre></p>"},{"location":"architecture/testimonial-artifacts.html#2-transcript-artefakt","title":"2. Transcript-Artefakt","text":"<p>Dateiname: <code>source.de.md</code> (Format: <code>{baseName}.{language}.md</code>)</p> <p>Inhalt:  - Minimales Frontmatter mit Metadaten (speakerName, createdAt, testimonialId, eventFileId, consent) - Roher Text-Body (identisch mit <code>source.txt</code>, wenn Text vorhanden) - Oder Transkription aus Audio (wenn nur Audio vorhanden)</p> <p>Zweck: - Authentisches Abbild der Quelle - Autor = Quelle (nicht User) - Metadaten f\u00fcr sofortige Anzeige (speakerName wird ben\u00f6tigt) - Wird f\u00fcr RAG-Ingestion verwendet (roher Text aus Body)</p> <p>Beispiel (<code>source.de.md</code>): <pre><code>---\nspeakerName: \"Max Mustermann\"\ncreatedAt: \"2026-01-14T15:38:00.000Z\"\ntestimonialId: \"2e305b30-395c-4cab-bdaf-7f67f5afa000\"\neventFileId: \"event-123\"\nconsent: true\n---\n\nDas ist mein Testimonial-Text, den ich eingegeben habe.\n</code></pre></p> <p>WICHTIG:  - Frontmatter enth\u00e4lt nur Metadaten (kein Template-Body) - Body enth\u00e4lt den rohen Text - Speaker-Name wird hier gespeichert, damit er sofort in der \u00dcbersicht angezeigt werden kann</p>"},{"location":"architecture/testimonial-artifacts.html#3-transformation-artefakt-wird-spater-erstellt","title":"3. Transformation-Artefakt (wird sp\u00e4ter erstellt)","text":"<p>Dateiname: <code>source.event-testimonial-creation-de.de.md</code> (Format: <code>{baseName}.{templateName}.{language}.md</code>)</p> <p>WICHTIG: Das Transformation-Artefakt wird nicht bei der Erstellung erstellt, sondern sp\u00e4ter im Finalisieren-Wizard, wo alle Testimonial-Transcripte zusammen verarbeitet werden.</p> <p>Inhalt (wenn erstellt): - Frontmatter mit Metadaten (speakerName, createdAt, eventFileId, etc.) - Gerenderten Template-Body mit Platzhaltern ersetzt</p> <p>Zweck: - User-autored, Template-basierte Interpretation - Strukturierte Metadaten f\u00fcr Suche/Filterung - Wird f\u00fcr UI-Anzeige verwendet (Session Detail, Wizard)</p> <p>Beispiel (<code>source.event-testimonial-creation-de.de.md</code>): <pre><code>---\nspeakerName: \"Max Mustermann\"\ncreatedAt: \"2026-01-14T15:38:00.000Z\"\ntestimonialId: \"2e305b30-395c-4cab-bdaf-7f67f5afa000\"\neventFileId: \"event-123\"\nconsent: true\ndetailViewType: \"testimonial\"\n---\n\nMax Mustermann hat am 2026-01-14T15:38:00.000Z gesagt: Das ist mein Testimonial-Text, den ich eingegeben habe.\n</code></pre></p> <p>Wann wird es erstellt? - Im Finalisieren-Wizard, wenn alle Testimonials zusammen verarbeitet werden - Dort werden die originalen Transcripte verwendet, um strukturierte Transformation-Artefakte zu erstellen</p>"},{"location":"architecture/testimonial-artifacts.html#vergleich-transcript-vs-transformation","title":"Vergleich: Transcript vs Transformation","text":"Aspekt Transcript Transformation Dateiname <code>source.de.md</code> <code>source.template.de.md</code> Frontmatter \u2705 Minimal (nur Metadaten) \u2705 Vollst\u00e4ndig (Metadaten + Template-Felder) Body Roher Text Gerendertes Template Autor Quelle User (via Template) Verwendung RAG-Ingestion, UI-Anzeige (Metadaten) UI-Anzeige, Suche Gr\u00f6\u00dfe Klein (Metadaten + Text) Gr\u00f6\u00dfer (Frontmatter + Template-Body)"},{"location":"architecture/testimonial-artifacts.html#beispiel-aus-deinem-dateisystem","title":"Beispiel aus deinem Dateisystem","text":"<p>Basierend auf deiner Struktur:</p> <pre><code>testimonials/2e305b30-395c-4cab-bdaf-7f67f5afa000/\n\u251c\u2500\u2500 source.txt (262 bytes)\n\u2514\u2500\u2500 .source.txt/\n    \u2514\u2500\u2500 source.de.md (262 bytes)                    \u2190 Transcript: roher Text\n</code></pre> <p>Erwartete Inhalte:</p> <ol> <li><code>source.txt</code>: Dein eingegebener Text (z.B. \"Das ist mein Testimonial\")</li> <li><code>source.de.md</code>: </li> <li>Frontmatter mit Metadaten (speakerName, createdAt, etc.)</li> <li>Body mit dem gleichen Text wie <code>source.txt</code></li> </ol> <p>Transformation-Artefakt wird sp\u00e4ter im Finalisieren-Wizard erstellt, wenn alle Testimonials zusammen verarbeitet werden.</p>"},{"location":"architecture/testimonial-artifacts.html#warum-beide-artefakte","title":"Warum beide Artefakte?","text":"<ul> <li>Transcript: Authentisches Abbild der Quelle, wird bei Erstellung erstellt</li> <li>Transformation: Strukturierte Metadaten + gerendertes Template, wird sp\u00e4ter im Finalisieren-Wizard erstellt</li> </ul> <p>Aktuell: Bei Text-Eingabe wird nur das Transcript-Artefakt erstellt. Das Transformation-Artefakt wird sp\u00e4ter im Finalisieren-Wizard erstellt, wo alle Testimonial-Transcripte zusammen verarbeitet werden.</p> <p>Bei Audio-only wird nur die Source-Datei erstellt, und ein Job erzeugt sp\u00e4ter das Transcript-Artefakt.</p>"},{"location":"architecture/testimonial-artifacts.html#prufung-der-inhalte","title":"Pr\u00fcfung der Inhalte","text":"<p>Um zu pr\u00fcfen, ob die Artefakte korrekt erstellt wurden:</p> <ol> <li> <p>Transcript (<code>source.de.md</code>):    <pre><code># Sollte nur Text enthalten, kein Frontmatter\ncat testimonials/.../.source.txt/source.de.md\n</code></pre></p> </li> <li> <p>Transformation (<code>source.event-testimonial-creation-de.de.md</code>):    <pre><code># Sollte Frontmatter + Body enthalten\ncat testimonials/.../.source.txt/source.event-testimonial-creation-de.de.md\n</code></pre></p> </li> <li> <p>Source (<code>source.txt</code>):    <pre><code># Sollte identisch mit Transcript sein (wenn Text vorhanden)\ncat testimonials/.../source.txt\n</code></pre></p> </li> </ol>"},{"location":"architecture/testimonial-artifacts.html#haufige-fragen","title":"H\u00e4ufige Fragen","text":"<p>Q: Warum ist <code>source.de.md</code> genauso gro\u00df wie <code>source.txt</code>? A: Das ist korrekt! Der Transcript enth\u00e4lt nur den rohen Text (ohne Frontmatter), daher sollte er identisch gro\u00df sein.</p> <p>Q: Warum ist die Transformation gr\u00f6\u00dfer? A: Die Transformation enth\u00e4lt Frontmatter (Metadaten) + gerenderten Template-Body, daher ist sie gr\u00f6\u00dfer.</p> <p>Q: Was passiert, wenn ich das Template \u00e4ndere? A: Die Transformation wird beim n\u00e4chsten Re-Run aktualisiert (gleicher Dateiname = Update statt Duplikat).</p>"},{"location":"architecture/use-cases-and-personas.html","title":"Use cases and personas","text":""},{"location":"architecture/use-cases-and-personas.html#ziel","title":"Ziel","text":"<p>Dieses Dokument beschreibt Rollen/Personas und eine systematische Use\u2011Case\u2011Liste f\u00fcr die artefakt\u2011zentrierte Pipeline (Variante 3). Es ist so strukturiert, dass sich jeder neue Use Case mit minimaler Redundanz dokumentieren und sp\u00e4ter implementieren l\u00e4sst.</p>"},{"location":"architecture/use-cases-and-personas.html#rollen-anwendungsbereiche-personas","title":"Rollen / Anwendungsbereiche (Personas)","text":""},{"location":"architecture/use-cases-and-personas.html#archiv-pro-technisch-versiert","title":"Archiv-Pro (technisch versiert)","text":"<ul> <li>Entry Points: File\u2011Liste (Single\u2011File), Batch/Verzeichnis, Monitoring/Traces</li> <li>Ziel: deterministische Verarbeitung, Resume/Skip, Kontrolle \u00fcber Policies/Gates, Debugbarkeit, saubere Facetten (Gallery/Archiv)</li> <li>Erwartung an UI: Optionen sichtbar (Template/Language/Policies), Fehler nachvollziehbar, Artefakt\u2011Explorer (Shadow\u2011Twin) schnell erreichbar</li> </ul>"},{"location":"architecture/use-cases-and-personas.html#wizard-user-nicht-technisch","title":"Wizard-User (nicht technisch)","text":"<ul> <li>Entry Points: Wizard (Quelle w\u00e4hlen \u2192 Template w\u00e4hlen \u2192 Start \u2192 Ergebnis pr\u00fcfen \u2192 Speichern)</li> <li>Ziel: sichere Defaults, verst\u00e4ndlicher Fortschritt, m\u00f6glichst wenige Entscheidungen, Ergebnis schnell nutzbar</li> <li>Erwartung an UI: \u201eEin Knopf\u201c, klare Statusanzeige (SSE), verst\u00e4ndliche Fehlermeldungen, Ergebnis-Preview + \u201eErgebnis \u00f6ffnen\u201c</li> </ul>"},{"location":"architecture/use-cases-and-personas.html#automation-integration","title":"Automation / Integration","text":"<ul> <li>Entry Points: API/Jobs (ohne UI), optional Batch-Automation</li> <li>Ziel: idempotent, standardisierte Artefakte/Outputs, klare Fehlercodes, robuste Wiederholbarkeit</li> <li>Erwartung an API: stabile Contracts (Request/Response), Polling oder Webhook, maschinenlesbare Result-Refs (Artefakt-IDs/URLs)</li> </ul>"},{"location":"architecture/use-cases-and-personas.html#usecase-liste-systematisch","title":"Use\u2011Case Liste (systematisch)","text":""},{"location":"architecture/use-cases-and-personas.html#singlesource-use-cases-v1-nahe-roadmap","title":"Single\u2011Source Use Cases (V1 + nahe Roadmap)","text":"<ul> <li>Audio: Audio-Datei \u2192 Transcript (Originalsprache/TargetLanguage) \u2192 Template\u2011Bericht \u2192 Ingest</li> <li>Video: Video-Datei \u2192 (Audio-Extraktion) \u2192 Transcript \u2192 Template\u2011Bericht \u2192 Ingest</li> <li>YouTube: YouTube URL \u2192 Download/Extract \u2192 Transcript \u2192 Template\u2011Bericht \u2192 Ingest</li> <li>PDF: PDF \u2192 Mistral OCR (Markdown) + Pages/Images \u2192 Template\u2011Bericht \u2192 Ingest</li> <li>Word (DOCX): DOCX \u2192 Extract (Text/Struktur) \u2192 Template\u2011Bericht \u2192 Ingest</li> <li>Excel (XLSX): XLSX \u2192 Extract (Sheets/Tables) \u2192 Template\u2011Bericht \u2192 Ingest</li> </ul>"},{"location":"architecture/use-cases-and-personas.html#singlesource-use-cases-spater-aber-vorgesehen","title":"Single\u2011Source Use Cases (sp\u00e4ter, aber vorgesehen)","text":"<ul> <li>Image: Bild \u2192 OCR \u2192 Template\u2011Bericht \u2192 Ingest</li> <li>PowerPoint/Slides: PPTX/Slides \u2192 Extract (Text + Bilder) \u2192 Template\u2011Bericht \u2192 Ingest</li> </ul>"},{"location":"architecture/use-cases-and-personas.html#multisource-use-cases-ausblick-wichtig-furs-zielbild","title":"Multi\u2011Source Use Cases (Ausblick; wichtig f\u00fcrs Zielbild)","text":"<ul> <li>Event Bundle: Slides + Vortrag (Video/Audio) + optional Web\u2011Text + optional PDF/Handout \u2192 Bundle\u2011Korpus \u2192 Template\u2011Bericht \u2192 Ingest</li> <li>Wichtig: Multi\u2011Source ben\u00f6tigt eine stabile Bundle Identity (z.B. <code>folderId</code> oder <code>wizardSessionId</code>) f\u00fcr Artefakte/Gates.</li> </ul>"},{"location":"architecture/use-cases-and-personas.html#einheitliche-usecase-matrix-schablone-wiewowarum","title":"Einheitliche Use\u2011Case Matrix (Schablone: wie/wo/warum)","text":"<p>Diese Schablone wird pro Use Case ausgef\u00fcllt (und pro Persona/Entry\u2011Point referenziert), um Redundanzen sichtbar zu machen und die Implementierung minimal zu halten.</p>"},{"location":"architecture/use-cases-and-personas.html#matrix-felder","title":"Matrix-Felder","text":"<ul> <li>UseCaseId: z.B. <code>pdf_mistral_report</code>, <code>audio_transcript_report</code></li> <li>Persona/EntryPoint: Archiv-Pro/File\u2011Liste, Archiv-Pro/Batch, Wizard-User/Wizard, Automation/API</li> <li>Input</li> <li><code>sourceRef</code> oder <code>sourceBundle</code></li> <li><code>templateName</code>, <code>targetLanguage</code>, <code>policies</code></li> <li>Orchestrierung</li> <li>External Job: <code>job_type</code>, <code>operation</code>, <code>worker</code></li> <li>Steps/Phasen: <code>extract \u2192 template \u2192 ingest</code></li> <li>Secretary Calls</li> <li>Endpoint + Parameter</li> <li>Sync vs Async (Job/Webhook)</li> <li>Erwartetes Callback-Payload (Keys, URLs statt Base64)</li> <li>Artefakte (Shadow Twin)</li> <li>Extract/Transcript: <code>{base}.{lang}.md</code></li> <li>Transformation: <code>{base}.{template}.{lang}.md</code></li> <li>Assets: pages/images archives (URLs) + Ablagekonvention</li> </ul> <p>Hinweis zur Storage-Policy (Zielbild): - Artefakte werden kanonisch im Dot\u2011Folder gespeichert (<code>.{originalName}/</code>). - Siblings gelten als Legacy und werden nur noch im Read-Only Modus toleriert, bis ein Repair/Migration-Run sie eliminiert. - Gates/Policies   - Welche Artefakte skippen welche Phase?   - Welche Policies \u00fcberschreiben Gates (<code>force</code>)? - Persistenz/Publishing   - Storage (Artefakte)   - Mongo (Ingest) + Facetten/Metadaten - UI/Ergebnis   - Status/Progress (SSE)   - \u201eErgebnis \u00f6ffnen/selektieren\u201c   - Fehlerdarstellung (verst\u00e4ndlich, ohne Internals)</p>"},{"location":"architecture/use-cases-and-personas.html#matrix-tabellarisch","title":"Matrix (tabellarisch)","text":"<p>Die Tabelle ist bewusst \u201ebreit\u201c, damit man pro Use Case alles auf einen Blick sieht. F\u00fcr die Detailausarbeitung (z.B. konkrete Payload-Keys) referenzieren wir dann die Secretary\u2011Schnittstellen-Doku.</p>"},{"location":"architecture/use-cases-and-personas.html#vorlage-zum-ausfullen","title":"Vorlage (zum Ausf\u00fcllen)","text":"UseCaseId Persona/EntryPoint Input (Quelle+Template) Orchestrierung (Job) Secretary Calls (sync/async) Artefakte (Shadow Twin) Gates/Policies (Skip/Force) Persistenz/Publishing UI/Ergebnis <code>...</code> <code>...</code> <code>sourceRef/sourceBundle; templateName; targetLanguage; policies</code> <code>job_type; operation; worker; steps</code> <code>endpoints; callback/webhook; erwartete keys</code> <code>extract/transcript; transformation; assets</code> <code>gate criteria; policy override</code> <code>storage; mongo ingest; facets</code> <code>SSE progress; open result; error UX</code>"},{"location":"architecture/use-cases-and-personas.html#beispiel-v0-pdf_mistral_report-archivpro-fileliste","title":"Beispiel (V0) \u2013 <code>pdf_mistral_report</code> (Archiv\u2011Pro / File\u2011Liste)","text":"UseCaseId Persona/EntryPoint Input (Quelle+Template) Orchestrierung (Job) Secretary Calls (sync/async) Artefakte (Shadow Twin) Gates/Policies (Skip/Force) Persistenz/Publishing UI/Ergebnis <code>pdf_mistral_report</code> <code>Archiv-Pro / File-Liste (Single)</code> <code>sourceRef=PDF(itemId,parentId); templateName; targetLanguage=de; policies (extract/metadata/ingest)</code> <code>External Job: job_type=pdf; operation=extract; worker=secretary; steps=extract\u2192template\u2192ingest</code> <code>POST /api/secretary/process-pdf (extractionMethod=mistral_ocr, includePageImages=true, includeOcrImages=true); async: Worker startet; Callback POST /api/external/jobs/{jobId}</code> <code>Extract: {base}.de.md; Transform: {base}.{template}.de.md; Assets: pages/images ZIP per URL/Refs</code> <code>Wenn Transform-Artefakt existiert \u2192 template skip (au\u00dfer force); wenn ingest existiert \u2192 ingest skip</code> <code>Storage: Artefakte; Mongo: Ingest (Meta+Chunks) + Facetten</code> <code>SSE /api/external/jobs/stream; nach completed: Ergebnis \u00f6ffnen/selektieren</code>"},{"location":"architecture/use-cases-and-personas.html#matrix-alle-media-use-cases-vereinheitlicht","title":"Matrix \u2013 alle Media Use Cases (vereinheitlicht)","text":"<p>Hinweis zur Vermeidung von Redundanz: - Die Zeilen sind medientyp-spezifisch, aber entrypoint-neutral. - Unterschiede zwischen File\u2011Liste/Batch/Wizard/API sind \u00fcberall gleich:   - File\u2011Liste: genau 1 Quelle starten   - Batch/Verzeichnis: viele Quellen \u2192 viele Jobs (oder BatchId)   - Wizard: Quelle w\u00e4hlen + Template w\u00e4hlen \u2192 Job starten \u2192 SSE + Preview/Save   - Automation/API: Job erstellen \u2192 Polling/Webhook \u2192 Artefakt\u2011Refs konsumieren</p> UseCaseId EntryPoints (wer nutzt es) Input (Quelle+Template) Orchestrierung (Job) Secretary Calls (sync/async) Artefakte (Shadow Twin) Gates/Policies (Skip/Force) Persistenz/Publishing Status/Ergebnis <code>audio_transcript_report</code> <code>File-Liste, Batch, Wizard, API</code> <code>sourceRef=Audio(file); templateName; targetLanguage; policies</code> <code>job_type=audio; operation=transcribe/extract; worker=secretary; steps=extract\u2192template\u2192ingest</code> <code>POST /api/secretary/process-audio; async via External Jobs Callback (V3)</code> <code>Extract: {base}.{lang}.md (Transcript); Transform: {base}.{template}.{lang}.md</code> <code>Skip wenn Transform existiert; force \u00fcberschreibt</code> <code>Storage Artefakte; optional Ingest</code> <code>SSE job_update; Ergebnis \u00f6ffnen/selektieren</code> <code>video_transcript_report</code> <code>File-Liste, Batch, Wizard, API</code> <code>sourceRef=Video(file); templateName; targetLanguage; policies</code> <code>job_type=video; operation=transcribe/extract; worker=secretary; steps=extract\u2192template\u2192ingest</code> <code>POST /api/secretary/process-video; async via External Jobs Callback (V3)</code> <code>Extract: {base}.{lang}.md; Transform: {base}.{template}.{lang}.md</code> <code>Skip/force wie oben</code> <code>Storage; optional Ingest</code> <code>SSE; Ergebnis \u00f6ffnen</code> <code>youtube_transcript_report</code> <code>Wizard, API</code> <code>sourceRef=YouTube(url); templateName; targetLanguage; policies</code> <code>job_type=video; operation=extract; worker=secretary</code> <code>POST /api/secretary/process-video (url); async via External Jobs Callback (V3)</code> <code>Extract: {base}.{lang}.md; Transform: {base}.{template}.{lang}.md</code> <code>Skip/force wie oben</code> <code>Storage; optional Ingest</code> <code>SSE/Poll; Ergebnis \u00f6ffnen</code> <code>pdf_mistral_report</code> <code>File-Liste, Batch, Wizard, API</code> <code>sourceRef=PDF(file/itemId); templateName; targetLanguage; policies; extractionMethod=mistral_ocr</code> <code>job_type=pdf; operation=extract; worker=secretary; steps=extract\u2192template\u2192ingest</code> <code>POST /api/secretary/process-pdf (mistral_ocr, includePageImages=true, includeOcrImages=true); async Callback</code> <code>Extract: {base}.{lang}.md; Transform: {base}.{template}.{lang}.md; Assets: pages/images ZIP URLs/Refs</code> <code>Skip wenn Transform existiert; force \u00fcberschreibt; ingest skip wenn vorhanden</code> <code>Storage; optional Ingest (V0 Pflichtf\u00e4hig)</code> <code>SSE; Ergebnis \u00f6ffnen</code> <code>markdown_file_report</code> <code>File-Liste, Batch, Wizard, API</code> <code>sourceRef=Markdown/TXT(file); templateName; targetLanguage; policies</code> <code>job_type=text; operation=extract/transform; worker=secretary</code> <code>POST /api/secretary/process-text (template)</code> <code>Transform: {base}.{template}.{lang}.md (Extract kann = Source sein)</code> <code>Skip wenn Transform existiert</code> <code>Storage; optional Ingest</code> <code>SSE/Poll oder sync UI</code> <code>website_report</code> <code>Wizard, API</code> <code>sourceRef=URL; templateName; targetLanguage; policies</code> <code>job_type=text; operation=extract; worker=secretary</code> <code>POST /api/secretary/import-from-url (extract) \u2192 danach POST /api/secretary/process-text (template)</code> <code>Extract: {base}.{lang}.md (raw website text optional); Transform: {base}.{template}.{lang}.md</code> <code>Skip wenn Transform existiert</code> <code>Storage; optional Ingest</code> <code>SSE/Poll; Ergebnis \u00f6ffnen</code> <code>docx_report</code> <code>File-Liste, Batch, Wizard, API</code> <code>sourceRef=DOCX(file); templateName; targetLanguage; policies</code> <code>job_type=document; operation=extract; worker=secretary</code> <code>TBD: Secretary DOCX endpoint (Contract needed)</code> <code>Extract: {base}.{lang}.md; Transform: {base}.{template}.{lang}.md</code> <code>Skip/force wie oben</code> <code>Storage; optional Ingest</code> <code>SSE/Poll; Ergebnis \u00f6ffnen</code> <code>xlsx_report</code> <code>File-Liste, Batch, Wizard, API</code> <code>sourceRef=XLSX(file); templateName; targetLanguage; policies</code> <code>job_type=document; operation=extract; worker=secretary</code> <code>TBD: Secretary XLSX endpoint (Contract needed)</code> <code>Extract: {base}.{lang}.md (tables/sheets); Transform: {base}.{template}.{lang}.md</code> <code>Skip/force wie oben</code> <code>Storage; optional Ingest</code> <code>SSE/Poll; Ergebnis \u00f6ffnen</code> <code>image_ocr_report</code> <code>File-Liste, Batch, Wizard, API</code> <code>sourceRef=Image(file/url); templateName; targetLanguage; policies</code> <code>job_type=image; operation=extract; worker=secretary</code> <code>POST /api/secretary/process-image (OCR) \u2192 optional Template Transform</code> <code>Extract: {base}.{lang}.md; Transform: {base}.{template}.{lang}.md</code> <code>Skip/force wie oben</code> <code>Storage; optional Ingest</code> <code>SSE/Poll</code> <code>slides_pptx_report</code> <code>File-Liste, Batch, Wizard, API</code> <code>sourceRef=PPTX/Slides(file); templateName; targetLanguage; policies</code> <code>job_type=document; operation=extract; worker=secretary</code> <code>TBD: Secretary PPTX/Slides endpoint (Contract needed)</code> <code>Extract: {base}.{lang}.md (+ slide images refs); Transform: {base}.{template}.{lang}.md</code> <code>Skip/force wie oben</code> <code>Storage; optional Ingest</code> <code>SSE/Poll</code> <code>event_bundle_report</code> <code>Wizard, API (sp\u00e4ter)</code> <code>sourceBundle=multiple sources; templateName; targetLanguage; policies</code> <code>job_type=event; operation=extract+transform; worker=secretary</code> <code>POST /api/secretary/session/process-async (oder events/*) + Callback; ggf. mehrere Extracts + 1 Template</code> <code>Transform: {bundle}.{template}.{lang}.md; Assets: refs; (Bundle Identity zwingend)</code> <code>Skip/force auf Bundle-Artefakt-Ebene</code> <code>Storage; Ingest; Facetten (Event)</code> <code>SSE; Ergebnis \u00f6ffnen</code>"},{"location":"decisions/remove-story-creator.html","title":"Entscheidung: Story Creator eliminieren und Pipeline direkt in Preview integrieren","text":"<p>Datum: 2026-01-26 Status: Implementiert Entscheidung: Variante A</p>"},{"location":"decisions/remove-story-creator.html#problem","title":"Problem","text":"<p>Der Story Creator existiert als separate Route (<code>/library/story-creator</code>), die faktisch nur eine Toolbar (<code>FlowActions</code>) und einen Viewer (<code>ShadowTwinViewer</code>) rendert. Dies f\u00fchrt zu:</p> <ul> <li>Doppelte Funktionalit\u00e4t: Der Preview-Mode zeigt bereits alle drei Phasen (Transkript, Transformation, Story) als Tabs an</li> <li>Zeitverlust: User muss zwischen Preview und Story Creator wechseln</li> <li>Kognitive Last: Zwei verschiedene Modi f\u00fcr dieselbe Aufgabe</li> </ul>"},{"location":"decisions/remove-story-creator.html#varianten","title":"Varianten","text":""},{"location":"decisions/remove-story-creator.html#variante-a-pipeline-direkt-im-preview-gemeinsame-pipeline-runner-logik","title":"Variante A: Pipeline direkt im Preview + gemeinsame Pipeline-Runner-Logik \u2705","text":"<p>Was: Preview bekommt \"Jetzt erstellen\"-Buttons bei fehlenden Phasen, die den <code>PipelineSheet</code> Dialog \u00f6ffnen. <code>FlowActions</code> und Preview teilen sich eine extrahierte <code>runPipelineForFile()</code>-Funktion.</p> <p>Pro: - Keine parallelen Modi - Minimale kognitive Last - Kein Code-Duplikat der Enqueue-Logik</p> <p>Contra: - Kleiner Refactor n\u00f6tig (Logik aus <code>flow-actions.tsx</code> herausl\u00f6sen)</p>"},{"location":"decisions/remove-story-creator.html#variante-b-flowactions-im-preview-wiederverwenden","title":"Variante B: <code>FlowActions</code> im Preview wiederverwenden","text":"<p>Was: Preview rendert intern <code>FlowActions</code> (oder einen abgespeckten Wrapper), nutzt deren <code>PipelineSheet</code>-State und <code>runPipeline()</code> unver\u00e4ndert.</p> <p>Pro: - Weniger Refactor</p> <p>Contra: - <code>FlowActions</code> bringt viel Toolbar-UI/Query-Param-Logik mit - Integration in <code>file-preview.tsx</code> wird schnell \"komisch\"</p>"},{"location":"decisions/remove-story-creator.html#variante-c-neues-kleines-pipelinelauncher-modul-geringe-duplikation","title":"Variante C: Neues kleines \"PipelineLauncher\"-Modul + geringe Duplikation","text":"<p>Was: Preview nutzt einen neuen minimalen Launcher, der die 3\u20134 Enqueue-Calls lokal abbildet (aus <code>flow-actions.tsx</code> kopiert/vereinfacht).</p> <p>Pro: - Schnell implementierbar</p> <p>Contra: - Duplikation; driftet mit der Zeit auseinander</p>"},{"location":"decisions/remove-story-creator.html#entscheidung","title":"Entscheidung","text":"<p>Variante A wurde gew\u00e4hlt, weil sie den Story-Creator sauber ersetzt und Duplikation vermeidet.</p>"},{"location":"decisions/remove-story-creator.html#konsequenzen","title":"Konsequenzen","text":"<ol> <li>Route entfernt: <code>/library/story-creator</code> gibt 404</li> <li>Neue UI: Preview zeigt \"Jetzt erstellen\"-Buttons bei fehlenden Phasen</li> <li>Vorauswahl: Dialog ist je nach fehlender Phase vorselektiert:</li> <li>Transkript fehlt \u2192 nur Extract/Transkription aktiv</li> <li>Transformation fehlt \u2192 nur Transformation aktiv (Template erforderlich)</li> <li>Story fehlt \u2192 nur Ingestion aktiv</li> <li>Job-Status: Preview zeigt Job-Status (queued/running/completed/failed) wie im Job Monitor, aber ohne Auto-Refresh der Shadow-Twin-Artefakte (nur manueller Refresh)</li> </ol>"},{"location":"decisions/remove-story-creator.html#technische-details","title":"Technische Details","text":"<ul> <li>Pipeline-Runner-Logik wurde in <code>src/lib/pipeline/run-pipeline.ts</code> extrahiert</li> <li><code>PipelineSheet</code> unterst\u00fctzt jetzt optionale <code>defaultSteps</code> Props</li> <li>Preview nutzt denselben SSE-Mechanismus (<code>/api/external/jobs/stream</code>) wie der Job Monitor f\u00fcr Status-Updates</li> </ul>"},{"location":"guides/integration-tests.html","title":"Integration tests","text":""},{"location":"guides/integration-tests.html#integrationstests-pdf-audio","title":"Integrationstests (PDF &amp; Audio)","text":""},{"location":"guides/integration-tests.html#was-ist-das","title":"Was ist das?","text":"<p>Integrationstests validieren End-to-End Use-Cases \u00fcber das echte External-Job-System:</p> <ul> <li>Orchestrator startet Jobs, wartet auf Abschluss, validiert Contracts</li> <li>Shadow\u2011Twin Artefakte werden \u00fcber <code>ShadowTwinService</code> gepr\u00fcft (storage-agnostisch)</li> <li>Testl\u00e4ufe werden persistent in MongoDB gespeichert (<code>integration_tests</code>) und sind in der UI unter <code>/integration-tests</code> sichtbar (inkl. Notes)</li> </ul>"},{"location":"guides/integration-tests.html#warum-machen-wir-das","title":"Warum machen wir das?","text":"<ul> <li>Regression-Schutz f\u00fcr Jobs/Contracts (z.B. <code>result.savedItemId</code>, Step-Status-Konsistenz)</li> <li>Storage-Agnostik: Tests m\u00fcssen sowohl f\u00fcr Mongo-only als auch Filesystem/Provider funktionieren</li> <li>Agent/CI-f\u00e4hig: Tests k\u00f6nnen per CLI gestartet, maschinell ausgewertet und als Notes dokumentiert werden</li> </ul>"},{"location":"guides/integration-tests.html#wie-ist-es-gebaut-wichtige-bausteine","title":"Wie ist es gebaut? (Wichtige Bausteine)","text":"<ul> <li>Testcases (Suite): <code>src/lib/integration-tests/test-cases.ts</code></li> <li>jedes Szenario hat eine <code>id</code> (z.B. <code>audio_transcription.happy_path</code>)</li> <li><code>target</code> (<code>pdf|audio</code>) steuert, welche Dateien im Ordner als Targets gelten</li> <li><code>phases</code> + <code>policies</code> steuern Extract/Template/Ingest Verhalten</li> <li><code>expected</code> beschreibt die Erwartungen (inkl. Transcript-Checks f\u00fcr Audio)</li> <li>Orchestrator: <code>src/lib/integration-tests/orchestrator.ts</code></li> <li>listet Testdateien im Ordner (PDF/AUDIO)</li> <li>bereitet Pre-Conditions vor (<code>clean|exists|incomplete_frontmatter</code>)</li> <li>erstellt Jobs via interner Create-Route und startet sie</li> <li>Validatoren: <code>src/lib/integration-tests/validators.ts</code></li> <li>pr\u00fcfen globale Contracts und UseCase-spezifische Erwartungen</li> <li>Audio: pr\u00fcft <code>extract_audio</code> und (bei Extract-only) Transcript statt Transformation</li> <li>UI: <code>src/app/integration-tests/page.tsx</code></li> <li>Dateityp (PDF/AUDIO) + Datei-Auswahl (optional), Suite-Filter, Run-History + Notes</li> </ul>"},{"location":"guides/integration-tests.html#globale-qualitatsregeln-wichtig","title":"Globale Qualit\u00e4tsregeln (wichtig)","text":"<ul> <li>Leeres Markdown ist ein Fehler:</li> <li><code>ShadowTwinService.upsertMarkdown()</code> wirft bei leerem/Whitespace Markdown.</li> <li>Zus\u00e4tzlich Defense-in-Depth in Stores/Repo.</li> <li>Ziel: kein \u201ecompleted Job\u201c, der ein leeres Transcript/Artefakt persistiert.</li> <li>Global Contract:</li> <li><code>completed</code> darf keine <code>pending</code> Steps enthalten</li> <li><code>completed</code> darf keine <code>running</code> Steps enthalten</li> </ul>"},{"location":"guides/integration-tests.html#zielbild-one-pipeline-many-sources","title":"Zielbild: One Pipeline, Many Sources","text":""},{"location":"guides/integration-tests.html#leitidee","title":"Leitidee","text":"<p>Alle Quellen (PDF, Audio, Markdown/TXT, Website, CSV, \u2026) durchlaufen eine einheitliche Pipeline:</p> <ol> <li>Normalize (quellenspezifisch): Konvertiert die Quelle in Canonical Markdown (Text-only) + Frontmatter + Original-Rohdaten-Referenz</li> <li>Template (einheitlich): Erzeugt/validiert strukturierendes Frontmatter (falls nicht schon vollst\u00e4ndig)</li> <li>Ingest (einheitlich): Schreibt Vektoren/Meta in MongoDB Vector Search</li> </ol>"},{"location":"guides/integration-tests.html#canonical-markdown-gemeinsame-reprasentation","title":"Canonical Markdown (gemeinsame Repr\u00e4sentation)","text":"<p>Jede Quelle wird zuerst in ein kanonisches Markdown-Format normalisiert:</p> <ul> <li>Text-only: Reiner Markdown-Text (keine Asset-Downloads im Normalize-Schritt)</li> <li>Frontmatter verpflichtend: Quelle, Titel, Datum/Crawl-Zeit, Typ, Origin-Ref</li> <li>Lossless Origin: Original-Rohdaten (HTML/CSV/TXT/MD) werden zus\u00e4tzlich als Artefakt gespeichert/verlinkt</li> <li>Bilder/Assets: Zun\u00e4chst nur Links/Refs; Asset-Download als sp\u00e4teres Add-on (klar abgrenzen)</li> </ul>"},{"location":"guides/integration-tests.html#test-matrix-format-phasen","title":"Test-Matrix (Format \u00d7 Phasen)","text":"Format Normalize Template Ingest Status PDF Extract \u2192 Transcript-MD \u2705 \u2705 \u2705 Implementiert Audio Transcribe \u2192 Transcript-MD \u2705 \u2705 \u2705 Implementiert Markdown Normalize (trim, Frontmatter erzwingen) \u2705 \u2705 \ud83d\udea7 In Arbeit TXT Wrap \u2192 Markdown + Frontmatter \u2705 \u2705 \ud83d\udea7 Geplant Website Fetch HTML \u2192 HTML\u2192MD + Frontmatter \u2705 \u2705 \ud83d\udea7 Geplant CSV Parse \u2192 Markdown-Tabellen + Frontmatter \u2705 \u2705 \ud83d\udea7 Geplant"},{"location":"guides/integration-tests.html#globale-contracts-fur-alle-formate","title":"Globale Contracts (f\u00fcr alle Formate)","text":"<p>Jeder Integrationstest pr\u00fcft dieselben globalen Contracts:</p> <ul> <li>Canonical Markdown non-empty: Normalize-Schritt darf kein leeres/Whitespace-Markdown erzeugen</li> <li>Template Output: Transformation erzeugt Markdown mit (mindestens) Frontmatter</li> <li>Ingest Vectors: <code>chunksUpserted &gt; 0</code> und Meta/Chunks existieren in Vector Search</li> <li>Job Contracts: <code>completed</code> Jobs haben keine <code>pending</code>/<code>running</code> Steps</li> </ul>"},{"location":"guides/integration-tests.html#architektur-details","title":"Architektur-Details","text":"<p>Detaillierte Architektur-/Trade-off-Analyse siehe: <code>docs/analysis/unified-pipeline-architecture.md</code></p>"},{"location":"guides/integration-tests.html#ausfuhren-ui","title":"Ausf\u00fchren (UI)","text":"<ol> <li>\u00d6ffne <code>/integration-tests</code></li> <li>W\u00e4hle Dateityp (PDF oder Audio)</li> <li>Optional: w\u00e4hle eine konkrete Datei (sonst: alle Dateien im Ordner)</li> <li>W\u00e4hle Suite (z.B. \u201eNur Audio\u201c) und starte den Run</li> <li>\u00d6ffne einen Run in der History und lies Results/Notes</li> </ol>"},{"location":"guides/integration-tests.html#ausfuhren-cli","title":"Ausf\u00fchren (CLI)","text":""},{"location":"guides/integration-tests.html#voraussetzungen","title":"Voraussetzungen","text":"<ul> <li>Next Dev Server l\u00e4uft (<code>pnpm dev</code>)</li> <li>Secretary Service ist erreichbar (je nach Setup lokal, z.B. <code>http://127.0.0.1:5001</code>)</li> <li>MongoDB ist erreichbar (f\u00fcr Run-History + Notes)</li> </ul>"},{"location":"guides/integration-tests.html#beispiel-audio-ordner-testfolder","title":"Beispiel: Audio-Ordner (Testfolder)","text":"<pre><code>pnpm -s test:integration:api -- \\\n  --libraryId 7911fdb9-8608-4b24-908b-022a4015cbca \\\n  --folderId YXVkaW8vdGVzdA== \\\n  --userEmail peter.aichner@crystal-design.com \\\n  --fileKind audio \\\n  --testCaseIds audio_transcription.happy_path,audio_transcription.gate_skip_extract,audio_transcription.force_recompute\n</code></pre> <p>Das Kommando gibt JSON aus (inkl. <code>runId</code>, Summary, per-Test Validation Messages).</p>"},{"location":"guides/integration-tests.html#agent-playbook-damit-der-agent-genau-wei-was-zu-tun-ist","title":"Agent-Playbook (damit der Agent \u201egenau wei\u00df, was zu tun ist\u201c)","text":""},{"location":"guides/integration-tests.html#zieldefinition-definition-of-done","title":"Zieldefinition (Definition of Done)","text":"<ul> <li>Run-Summary: failed = 0</li> <li>Keine globalen Contract-Fehler (z.B. <code>completed</code> mit <code>running</code> Steps)</li> <li>F\u00fcr Audio: Transcript-Checks erf\u00fcllen die Schwellenwerte (<code>minTranscriptChars</code>, etc.)</li> </ul>"},{"location":"guides/integration-tests.html#ablauf-loop","title":"Ablauf (Loop)","text":"<ol> <li>Run starten (CLI oder UI)</li> <li>Ergebnis auswerten</li> <li>Wenn <code>failed &gt; 0</code>: Fehler-Cluster nach H\u00e4ufigkeit bilden (Validator-Messages)</li> <li>Analyse + Next Steps persistieren</li> <li>Entweder via API (wenn <code>INTERNAL_TEST_TOKEN</code> vorhanden)</li> <li>Oder direkt via DB-Script:</li> </ol> <pre><code>node --import tsx scripts/post-integration-note.ts &lt;runId&gt;\n</code></pre> <ol> <li>Minimalen Fix implementieren (1 Ursache \u2192 1 Fix)</li> <li>Suite erneut ausf\u00fchren</li> <li>Wiederholen bis DoD erf\u00fcllt</li> </ol> <p>Wichtig: \u00c4nderungen an Validatoren/Testcases gelten als Code-\u00c4nderungen und sollten wie Feature-Code getestet werden (Unit + Integration).</p>"},{"location":"guides/integration-tests.html#methode-agent-loop-mit-persistenter-protokollierung-waswiewarum","title":"Methode: \u201eAgent Loop\u201c mit persistenter Protokollierung (Was/Wie/Warum)","text":"<p>Das Verfahren ist absichtlich so gebaut, dass ein Agent ohne UI in eine Iterationsschleife gehen kann und dabei jeden Schritt persistiert:</p> <ul> <li>Was wird persistiert?</li> <li>Jeder Testlauf ist ein Run in der MongoDB-Collection <code>integration_tests</code> (Run-History).</li> <li>Jeder Run enth\u00e4lt <code>result.summary</code> + <code>result.results[]</code> (inkl. <code>jobId</code> und Validator-Messages).</li> <li> <p>Zus\u00e4tzlich k\u00f6nnen <code>notes[]</code> an einen Run angeh\u00e4ngt werden (Analyse + Next Steps pro Iteration).</p> </li> <li> <p>Warum persistieren wir das?</p> </li> <li>Debugbarkeit: man kann alte Runs und \u201ewarum wurde was gefixt\u201c sp\u00e4ter nachvollziehen.</li> <li>Agenten-Loop: der Agent hat eine stabile Quelle der Wahrheit (DB), nicht nur fl\u00fcchtige Console-Ausgabe.</li> <li> <p>Reproduzierbarkeit: jeder Zyklus hat eine Run-ID, an die man sich \u201eanh\u00e4ngen\u201c kann.</p> </li> <li> <p>Wie kommt der Agent an die Run-ID?</p> </li> <li>CLI: <code>pnpm -s test:integration:api ...</code> gibt direkt JSON aus (inkl. <code>runId</code>).</li> <li>Server-Log: <code>POST /api/integration-tests/run</code> loggt zus\u00e4tzlich eine einzeilige Marker-Zeile:<ul> <li><code>[INTEGRATION_TEST_RUN] {\"runId\":\"...\",\"summary\":{...}}</code></li> </ul> </li> </ul>"},{"location":"guides/integration-tests.html#ablauf-eines-zyklus-deterministisch","title":"Ablauf eines Zyklus (deterministisch)","text":"<ol> <li>Run starten (CLI oder UI)</li> <li>Run-ID + Result speichern (passiert automatisch in <code>integration_tests</code>)</li> <li>Fehler clustern (typisch: nach <code>ValidationMessage.type === \"error\"</code> und gleicher Message)</li> <li>Analyse/Next Steps als Note persistieren</li> <li>Variante A (HTTP, wenn <code>INTERNAL_TEST_TOKEN</code> gesetzt ist):<ul> <li><code>POST /api/integration-tests/runs/&lt;runId&gt;/analyze</code> (auto)</li> <li>oder <code>POST /api/integration-tests/runs/&lt;runId&gt;/notes</code> (manuell/agent)</li> </ul> </li> <li>Variante B (ohne Token, direkt in Mongo):</li> </ol> <pre><code>node --import tsx scripts/post-integration-note.ts &lt;runId&gt;\n</code></pre> <ol> <li>Minimalen Fix implementieren</li> <li>Regel: 1 Fehler-Cluster \u2192 1 minimaler Fix</li> <li>Danach Unit-Tests f\u00fcr den betroffenen Bereich laufen lassen (mindestens die direkt betroffenen)</li> <li>Suite erneut ausf\u00fchren</li> <li>Wiederholen, bis DoD erf\u00fcllt ist (failed=0 + Contracts ok)</li> </ol>"},{"location":"guides/integration-tests.html#konvention-fur-notes-damit-der-verlauf-lesbar-bleibt","title":"Konvention f\u00fcr Notes (damit der Verlauf lesbar bleibt)","text":"<ul> <li>Eine Note pro Zyklus, mit:</li> <li>Titel: z.B. <code>Cycle N: Fix &lt;kurz&gt;</code> oder <code>Auto-Analyse: &lt;x&gt; Fehler</code></li> <li>Analyse: warum ist es ein Fehler, wo liegt wahrscheinlich die Ursache, welche Dateien sind betroffen</li> <li>Next Steps: konkrete ToDos (klein, ausf\u00fchrbar, mit Tests)</li> </ul>"},{"location":"guides/integration-tests.html#neue-szenarien-erganzen","title":"Neue Szenarien erg\u00e4nzen","text":""},{"location":"guides/integration-tests.html#1-testcase-hinzufugen-minimal","title":"1) Testcase hinzuf\u00fcgen (minimal)","text":"<p>In <code>src/lib/integration-tests/test-cases.ts</code>:</p> <ul> <li>neue <code>id</code> nach Schema <code>&lt;useCaseId&gt;.&lt;scenarioId&gt;</code></li> <li><code>target</code>: <code>pdf</code> oder <code>audio</code></li> <li><code>phases</code> + <code>policies</code></li> <li><code>shadowTwinState</code> (wenn Pre-Condition n\u00f6tig)</li> <li><code>expected</code>:</li> <li>PDF: typischerweise Transformation/ShadowTwin Existence, optional Ingestion</li> <li>Audio (Extract-only): <code>expectTranscriptNonEmpty</code> + <code>minTranscriptChars</code></li> </ul>"},{"location":"guides/integration-tests.html#2-pre-condition-sicherstellen-falls-notig","title":"2) Pre-Condition sicherstellen (falls n\u00f6tig)","text":"<p><code>src/lib/integration-tests/pdf-upload.ts</code> (historischer Name, enth\u00e4lt generische Helpers):</p> <ul> <li><code>clean</code>: l\u00f6scht deterministisch (Mongo + Filesystem)</li> <li><code>exists</code>: erzeugt deterministische Artefakte via <code>ShadowTwinService.upsertMarkdown()</code></li> <li><code>incomplete_frontmatter</code>: erzeugt \u201ekaputtes\u201c Artefakt f\u00fcr Repair-Szenarien</li> </ul> <p>Wenn ein neues Szenario einen anderen Startzustand braucht, erweitere hier die Vorbereitung.</p>"},{"location":"guides/integration-tests.html#3-validator-erweitern-falls-notig","title":"3) Validator erweitern (falls n\u00f6tig)","text":"<p><code>src/lib/integration-tests/validators.ts</code>:</p> <ul> <li>neue Assertions in <code>validateExternalJobForTestCase()</code></li> <li>bevorzugt: \u00fcber Job-Step Details, <code>ShadowTwinService.getMarkdown()</code> und globale Contracts</li> <li>vermeide Filesystem-Annahmen (Dot-Folder), wenn <code>persistToFilesystem=false</code> m\u00f6glich ist</li> </ul>"},{"location":"guides/integration-tests.html#4-tests-hinzufugen","title":"4) Tests hinzuf\u00fcgen","text":"<ul> <li>Unit-Tests f\u00fcr neue Domain-Regeln/Validator-Logik:</li> <li>z.B. <code>tests/unit/shadow-twin/shadow-twin-service.test.ts</code></li> <li>z.B. <code>tests/unit/integration-tests/*.test.ts</code></li> </ul>"},{"location":"guides/integration-tests.html#referenzen","title":"Referenzen","text":"<ul> <li><code>docs/analysis/integration-tests-agent-mode.md</code></li> <li><code>docs/analysis/integration-tests-storage-agnostic.md</code></li> <li><code>docs/analysis/audio-integration-tests.md</code></li> <li><code>docs/analysis/unified-pipeline-architecture.md</code>: Detaillierte Architektur f\u00fcr einheitliche Pipeline</li> </ul>"},{"location":"guides/shadow-twin.html","title":"Shadow\u2011Twin (User Guide)","text":""},{"location":"guides/shadow-twin.html#what-is-a-shadowtwin","title":"What is a Shadow\u2011Twin?","text":"<p>A Shadow\u2011Twin is the \u201cworking text representation\u201d of an original file (PDF, audio, video, image, \u2026). It is created when you run Extract/Transcribe and/or a Template transformation.</p>"},{"location":"guides/shadow-twin.html#why-does-it-exist","title":"Why does it exist?","text":"<ul> <li>Searchability: turn non-text sources into searchable Markdown.</li> <li>Consistency: store structure/metadata in a stable form.</li> <li>Downstream processing: make ingestion/RAG use the correct Markdown reliably.</li> </ul>"},{"location":"guides/shadow-twin.html#key-principles-current-system","title":"Key principles (current system)","text":"<ul> <li>Transcript vs. Transformation is semantic</li> <li>Transcript: the authentic extracted text (typically without frontmatter).</li> <li>Transformation: a prepared/structured version (typically with frontmatter), driven by a template.</li> <li>No big storage reshuffle</li> <li>Shadow\u2011Twins live next to the source file or inside a hidden dot-folder.</li> <li>Re\u2011runs update instead of duplicating</li> <li>Same source + same parameters \u2192 the existing result is updated.</li> <li>UI stays simple</li> <li>The UI does not guess filenames; it asks the backend resolver (bulk) for the best match.</li> </ul>"},{"location":"guides/shadow-twin.html#what-will-i-see-in-the-library","title":"What will I see in the Library?","text":"<p>You still work primarily with the original file (e.g. a PDF). Additionally, you may see: - Transcript Markdown: result of Extract/Transcribe - Transformed Markdown: result of Template transformation - Optionally a hidden Shadow\u2011Twin folder (starts with <code>.</code>) when many assets exist (e.g. extracted images)</p> <p>The UI should automatically pick the right companion Markdown when previewing metadata/content.</p>"},{"location":"guides/shadow-twin.html#faq","title":"FAQ","text":""},{"location":"guides/shadow-twin.html#why-are-there-multiple-markdown-files","title":"Why are there multiple Markdown files?","text":"<p>Because transcript and transformation serve different purposes: - transcript = raw text - transformation = structured text + metadata</p>"},{"location":"guides/shadow-twin.html#where-are-shadowtwin-files-stored","title":"Where are Shadow\u2011Twin files stored?","text":"<p>Either: - next to the original file, or - in a hidden dot-folder (starts with <code>.</code>) when additional assets belong together (images, media).</p>"},{"location":"guides/shadow-twin.html#why-is-the-file-list-faster-now","title":"Why is the file list faster now?","text":"<p>The UI resolves Shadow\u2011Twin information via bulk backend calls, instead of doing many per-item requests.</p>"},{"location":"guides/shadow-twin.html#what-to-do-if-the-ui-shows-the-wrong-file","title":"What to do if the UI shows the wrong file?","text":"<p>Please capture: - Library (name/id) - Source file name - Expected outcome (transcript vs transformation, language, template) - Screenshot + browser console logs (if possible)</p> <p>This is usually enough to validate resolver behavior and metadata consistency.</p>"},{"location":"implementation/generic-finalize-wizard-plan.html","title":"Implementierungsplan: Generischer Finalize/Publish-Wizard","text":""},{"location":"implementation/generic-finalize-wizard-plan.html#ubersicht","title":"\u00dcbersicht","text":"<p>Transformiere den Event-spezifischen Finalize-Wizard in einen generischen Wizard, der Inhalte eines Verzeichnisses zusammenf\u00fchrt, transformiert und publiziert.</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#aktuelle-situation","title":"Aktuelle Situation","text":""},{"location":"implementation/generic-finalize-wizard-plan.html#event-spezifische-endpunkte-werden-entfernt","title":"Event-spezifische Endpunkte (werden entfernt)","text":"<ul> <li><code>/api/library/[libraryId]/events/finalize</code> - Erstellt Final-Datei</li> <li><code>/api/library/[libraryId]/events/publish-final</code> - Index-Swap</li> </ul>"},{"location":"implementation/generic-finalize-wizard-plan.html#event-spezifische-templates-werden-angepasst","title":"Event-spezifische Templates (werden angepasst)","text":"<ul> <li><code>event-finalize-de.md</code> - Wird generisch (funktioniert f\u00fcr beliebige Verzeichnisse)</li> <li><code>event-publish-final-de.md</code> - Wird entfernt (Publish-Step integriert)</li> </ul>"},{"location":"implementation/generic-finalize-wizard-plan.html#implementierungsschritte","title":"Implementierungsschritte","text":""},{"location":"implementation/generic-finalize-wizard-plan.html#phase-1-generische-discovery-funktion","title":"Phase 1: Generische Discovery-Funktion","text":"<p>Datei: <code>src/lib/creation/folder-artifact-discovery.ts</code> (neu)</p> <pre><code>interface FolderArtifact {\n  fileId: string\n  fileName: string\n  createdAt: string\n  type: 'main' | 'testimonial' | 'other'\n  content: string // Markdown-Body\n  metadata: Record&lt;string, unknown&gt; // Frontmatter\n}\n\n/**\n * Entdeckt alle Artefakte in einem Verzeichnis\n * - Haupt-Artefakt (z.B. Event-Markdown)\n * - Zus\u00e4tzliche Artefakte (z.B. Testimonial-Transcripte)\n * - Sortiert chronologisch\n */\nexport async function discoverFolderArtifacts(\n  provider: StorageProvider,\n  folderId: string,\n  options?: {\n    mainArtifactPattern?: RegExp // z.B. /^event.*\\.md$/i\n    testimonialPattern?: RegExp // z.B. /testimonial/i\n  }\n): Promise&lt;FolderArtifact[]&gt;\n</code></pre> <p>Aufgaben: 1. \u2705 Verzeichnis durchsuchen 2. \u2705 Haupt-Artefakt identifizieren (Pattern-basiert) 3. \u2705 Testimonial-Artefakte finden (via <code>discoverTestimonials</code>) 4. \u2705 Chronologisch sortieren 5. \u2705 Frontmatter + Body parsen</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#phase-2-generischer-select-step","title":"Phase 2: Generischer Select-Step","text":"<p>Datei: <code>src/components/creation-wizard/steps/select-related-artifacts-step.tsx</code> (neu)</p> <p>Generische Version von <code>select-related-testimonials-step.tsx</code>: - Funktioniert f\u00fcr beliebige Artefakte (nicht nur Testimonials) - Verwendet <code>discoverFolderArtifacts</code> - Zeigt chronologische Liste - User kann ausw\u00e4hlen, welche verwendet werden sollen</p> <p>Aufgaben: 1. \u2705 Generische <code>FolderArtifact</code>-Liste anzeigen 2. \u2705 Checkboxen f\u00fcr Auswahl 3. \u2705 Chronologische Sortierung 4. \u2705 Zusammenfassung pro Artefakt (Name, Datum, Text-Ausschnitt)</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#phase-3-template-anpassen","title":"Phase 3: Template anpassen","text":"<p>Datei: <code>template-samples/event-finalize-de.md</code> (anpassen)</p> <pre><code>creation:\n  supportedSources:\n    - id: folder\n      type: folder\n      label: \"Verzeichnis mit Artefakten\"\n  flow:\n    steps:\n      - id: Welcome\n        preset: welcome\n      - id: Select\n        preset: selectRelatedArtifacts  # Generisch!\n      - id: Generate\n        preset: generateDraft\n      - id: Review\n        preset: editDraft\n      - id: Preview\n        preset: previewDetail\n      - id: Publish\n        preset: publish  # Immer am Ende\n</code></pre> <p>Aufgaben: 1. \u2705 <code>selectRelatedTestimonials</code> \u2192 <code>selectRelatedArtifacts</code> 2. \u2705 <code>publish</code> Step hinzuf\u00fcgen 3. \u2705 <code>event-publish-final-de.md</code> entfernen</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#phase-4-creation-wizard-erweitern","title":"Phase 4: Creation-Wizard erweitern","text":"<p>Datei: <code>src/components/creation-wizard/creation-wizard.tsx</code></p> <p>Neue Presets: - <code>selectRelatedArtifacts</code> - Generische Artefakt-Auswahl - <code>publish</code> - Bereits vorhanden, aber f\u00fcr Finalize-Wizard anpassen</p> <p>Aufgaben: 1. \u2705 <code>selectRelatedArtifacts</code> Preset hinzuf\u00fcgen 2. \u2705 <code>publish</code> Preset f\u00fcr Finalize-Wizard anpassen 3. \u2705 Index-Swap-Logik integrieren (aus <code>publish-final</code> Route)</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#phase-5-publish-logik-integrieren","title":"Phase 5: Publish-Logik integrieren","text":"<p>Datei: <code>src/components/creation-wizard/creation-wizard.tsx</code> (onPublish)</p> <p>Index-Swap-Logik: <pre><code>// 1. Final ingestieren\nawait IngestionService.upsertMarkdown(...)\n\n// 2. Original aus Index l\u00f6schen\nawait deleteVectorsByFileId(libraryKey, originalFileId)\n</code></pre></p> <p>Aufgaben: 1. \u2705 Index-Swap-Logik in <code>onPublish</code> integrieren 2. \u2705 Fehlerbehandlung (falls Ingestion fehlschl\u00e4gt, Original nicht l\u00f6schen) 3. \u2705 Progress-Anzeige</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#phase-6-alte-endpunkte-entfernen","title":"Phase 6: Alte Endpunkte entfernen","text":"<p>Dateien: - <code>src/app/api/library/[libraryId]/events/finalize/route.ts</code> - Entfernen - <code>src/app/api/library/[libraryId]/events/publish-final/route.ts</code> - Entfernen - <code>template-samples/event-publish-final-de.md</code> - Entfernen</p> <p>Aufgaben: 1. \u2705 Endpunkte entfernen 2. \u2705 Template entfernen 3. \u2705 Referenzen im Code entfernen</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#migration","title":"Migration","text":""},{"location":"implementation/generic-finalize-wizard-plan.html#bestehende-final-dateien","title":"Bestehende Final-Dateien","text":"<p>Bestehende Final-Dateien (erstellt via <code>/events/finalize</code>) bleiben erhalten. Der neue Wizard kann sie als \"Resume\" \u00f6ffnen und direkt publizieren.</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#neue-final-dateien","title":"Neue Final-Dateien","text":"<p>Werden \u00fcber den generischen Wizard erstellt: 1. User startet Wizard aus Event-Verzeichnis 2. Wizard entdeckt automatisch Event + Testimonials 3. User w\u00e4hlt aus, welche verwendet werden sollen 4. Wizard transformiert \u2192 Final-Datei 5. User publiziert \u2192 Index-Swap</p>"},{"location":"implementation/generic-finalize-wizard-plan.html#vorteile","title":"Vorteile","text":"<ol> <li>Generisch: Funktioniert f\u00fcr Events, Dialogr\u00e4ume, etc.</li> <li>Konsistent: Gleiche Logik wie Creation-Wizard</li> <li>Einfacher: Ein Wizard statt zwei (Finalize + Publish)</li> <li>Wartbar: Weniger Code-Duplikation</li> </ol>"},{"location":"implementation/generic-finalize-wizard-plan.html#offene-fragen","title":"Offene Fragen","text":"<ol> <li>Wie identifizieren wir das Haupt-Artefakt?</li> <li>Option A: Pattern-basiert (z.B. <code>/^event.*\\.md$/i</code>)</li> <li>Option B: Erste Markdown-Datei im Verzeichnis</li> <li> <p>Option C: Konfigurierbar im Template</p> </li> <li> <p>Wie sortieren wir chronologisch?</p> </li> <li>Option A: Nach <code>createdAt</code> aus Frontmatter</li> <li>Option B: Nach Dateiname (falls Datum enthalten)</li> <li> <p>Option C: Nach Datei-Erstellungsdatum</p> </li> <li> <p>Wie behandeln wir Transformation-Artefakte?</p> </li> <li>Option A: Immer Transformation-Artefakt verwenden (falls vorhanden)</li> <li>Option B: Transcript-Artefakt verwenden (roher Text)</li> <li>Option C: User kann w\u00e4hlen</li> </ol>"},{"location":"implementation/generic-finalize-wizard-plan.html#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ol> <li>\u2705 <code>discoverFolderArtifacts</code> implementieren</li> <li>\u2705 <code>selectRelatedArtifacts</code> Step erstellen</li> <li>\u2705 Template anpassen</li> <li>\u2705 Creation-Wizard erweitern</li> <li>\u2705 Publish-Logik integrieren</li> <li>\u2705 Alte Endpunkte entfernen</li> <li>\u2705 Tests schreiben</li> </ol>"},{"location":"reference/file-index.html","title":"File Index","text":"<p>Complete index of all documented source files with descriptions, exports, and usage information.</p>"},{"location":"reference/file-index.html#core-infrastructure","title":"Core Infrastructure \u2705","text":"File Path Module Description Exports Used In <code>src/middleware.ts</code> core Authentication and routing middleware <code>default</code>, <code>config</code> Next.js framework, all routes <code>src/app/layout.tsx</code> core Root layout component <code>default</code>, <code>metadata</code> Next.js framework, all pages <code>src/instrumentation.ts</code> core Next.js instrumentation hook <code>register</code> Next.js framework <code>src/lib/env.ts</code> core Environment variable helpers <code>getPublicAppUrl</code>, <code>getSelfBaseUrl</code>, <code>getSecretaryConfig</code>, <code>getVimeoConfig</code> API routes, services <code>src/lib/auth.ts</code> core Authentication helpers <code>getLibraryId</code>, <code>isAuthenticated</code>, <code>getUserInfo</code> API routes, components <code>src/lib/mongodb-service.ts</code> core MongoDB database service <code>connectToDatabase</code>, <code>getCollection</code> Services, repositories, API routes"},{"location":"reference/file-index.html#storage-layer","title":"Storage Layer \u2705","text":"File Path Module Description Exports Used In <code>src/lib/storage/types.ts</code> storage Storage type definitions <code>StorageItemMetadata</code>, <code>StorageItem</code>, <code>StorageValidationResult</code>, <code>StorageProvider</code> All storage files <code>src/lib/storage/storage-factory.ts</code> storage Storage provider factory <code>StorageFactory</code>, <code>LocalStorageProvider</code> Contexts, API routes, components <code>src/lib/storage/filesystem-provider.ts</code> storage Local filesystem provider <code>FileSystemProvider</code> Storage factory <code>src/lib/storage/onedrive-provider.ts</code> storage OneDrive provider <code>OneDriveProvider</code> Storage factory <code>src/lib/storage/storage-factory-mongodb.ts</code> storage MongoDB storage factory <code>MongoDBStorageFactory</code> MongoDB operations <code>src/lib/storage/filesystem-client.ts</code> storage Filesystem client <code>FileSystemClient</code> Client-side operations <code>src/lib/storage/server-provider.ts</code> storage Server-side provider helper <code>getServerProvider</code> API routes <code>src/lib/storage/supported-types.ts</code> storage Supported library types <code>SUPPORTED_LIBRARY_TYPES</code>, <code>isSupportedLibraryType</code>, <code>getSupportedLibraryTypesString</code> Storage factory <code>src/contexts/storage-context.tsx</code> storage Storage React context <code>StorageContextProvider</code>, <code>useStorage</code> Components <code>src/hooks/use-storage-provider.tsx</code> storage Storage provider hook <code>useStorageProvider</code> Components"},{"location":"reference/file-index.html#library-system","title":"Library System \u2705","text":"File Path Module Description Exports Used In <code>src/types/library.ts</code> library Library type definitions <code>ClientLibrary</code>, <code>Library</code>, <code>LibraryChatConfig</code>, <code>StorageConfig</code>, <code>PublicLibraryConfig</code> All library files <code>src/atoms/library-atom.ts</code> library Library state atoms <code>libraryAtom</code>, <code>activeLibraryIdAtom</code>, <code>librariesAtom</code>, <code>activeLibraryAtom</code>, <code>currentFolderIdAtom</code> Components <code>src/lib/services/library-service.ts</code> library Library service <code>LibraryService</code>, <code>UserLibraries</code> API routes, components <code>src/components/library/library.tsx</code> library Main library component <code>Library</code> Library page <code>src/components/library/library-header.tsx</code> library Library header component TBD Library component <code>src/components/library/library-switcher.tsx</code> library Library switcher component TBD Library header <code>src/components/library/file-list.tsx</code> library File list with header actions and record operations <code>FileList</code> Library component"},{"location":"reference/file-index.html#chat-system","title":"Chat System \u2705","text":"File Path Module Description Exports Used In <code>src/types/chat.ts</code> chat Chat type definitions <code>Chat</code> Chat system <code>src/lib/chat/constants.ts</code> chat Chat constants <code>AnswerLength</code>, <code>Retriever</code>, <code>TargetLanguage</code>, <code>Character</code>, <code>SocialContext</code> Chat system <code>src/lib/chat/orchestrator.ts</code> chat Chat orchestration <code>runChatOrchestrated</code>, <code>OrchestratorInput</code>, <code>OrchestratorOutput</code> Chat API routes <code>src/lib/chat/loader.ts</code> chat Chat loader <code>loadLibraryChatContext</code>, <code>LibraryChatContext</code> Chat orchestrator <code>src/lib/chat/config.ts</code> chat Chat configuration <code>chatConfigSchema</code>, <code>normalizeChatConfig</code>, <code>getVectorIndexForLibrary(library, chatConfig?)</code> Chat system <code>src/lib/chat/retrievers/chunks.ts</code> chat Chunk retriever <code>chunksRetriever</code> Chat orchestrator <code>src/lib/chat/retrievers/summaries-mongo.ts</code> chat Summary retriever <code>summariesMongoRetriever</code> Chat orchestrator <code>src/lib/chat/common/prompt.ts</code> chat Prompt building <code>buildPrompt</code>, <code>buildTOCPrompt</code>, <code>getSourceDescription</code> Chat orchestrator <code>src/lib/chat/common/llm.ts</code> chat LLM calling <code>callOpenAI</code>, <code>parseOpenAIResponseWithUsage</code>, <code>parseStructuredLLMResponse</code> Chat orchestrator <code>src/app/api/chat/[libraryId]/stream/route.ts</code> chat Chat streaming endpoint <code>POST</code> Chat components"},{"location":"reference/file-index.html#external-jobs-system","title":"External Jobs System \u2705","text":"File Path Module Description Exports Used In <code>src/lib/external-jobs-repository.ts</code> external-jobs MongoDB repository for external jobs <code>ExternalJobsRepository</code> Worker, watchdog, API routes, orchestration <code>src/lib/external-jobs-worker.ts</code> external-jobs Background worker for processing jobs <code>ExternalJobsWorker</code> Instrumentation, worker status endpoint <code>src/lib/external-jobs-watchdog.ts</code> external-jobs Timeout monitoring for jobs <code>startWatchdog</code>, <code>bumpWatchdog</code>, <code>clearWatchdog</code> Job callbacks, job start <code>src/lib/external-jobs/context.ts</code> external-jobs Request context parsing <code>readContext</code> Job callback <code>src/lib/external-jobs/auth.ts</code> external-jobs Authorization and bypass checks <code>isInternalAuthorized</code>, <code>authorizeCallback</code>, <code>guardProcessId</code> Job callbacks, job start <code>src/lib/external-jobs/policies.ts</code> external-jobs Phase policy extraction <code>readPhasesAndPolicies</code> Job callback <code>src/lib/external-jobs/template-decision.ts</code> external-jobs Template execution decision logic <code>decideTemplateRun</code> Job callback <code>src/lib/external-jobs/template-run.ts</code> external-jobs Template transformation execution <code>runTemplateTransform</code> Job callback <code>src/lib/external-jobs/chapters.ts</code> external-jobs Chapter detection and merging <code>analyzeAndMergeChapters</code> Job callback <code>src/lib/external-jobs/storage.ts</code> external-jobs Markdown file storage <code>saveMarkdown</code> Job callback <code>src/lib/external-jobs/images.ts</code> external-jobs Image archive extraction <code>processAllImageSources</code> Job callback <code>src/lib/external-jobs/ingest.ts</code> external-jobs RAG ingestion pipeline <code>runIngestion</code> Job callback, job start <code>src/lib/external-jobs/complete.ts</code> external-jobs Job completion handler <code>setJobCompleted</code> Job callback, job start <code>src/lib/external-jobs/preprocess.ts</code> external-jobs Job preprocessing and analysis <code>preprocess</code>, <code>PreprocessResult</code> Job start, job callback <code>src/lib/external-jobs/provider.ts</code> external-jobs Storage provider construction <code>buildProvider</code> Preprocessing, job callback <code>src/lib/external-jobs/progress.ts</code> external-jobs Progress update processing <code>handleProgressIfAny</code> Job callback <code>src/app/api/external/jobs/[jobId]/route.ts</code> external-jobs Main job processing endpoint <code>GET</code>, <code>POST</code> Secretary Service, worker <code>src/app/api/external/jobs/[jobId]/start/route.ts</code> external-jobs Job execution trigger <code>POST</code> Worker <code>src/app/api/external/jobs/route.ts</code> external-jobs Job query endpoint <code>GET</code> Event monitor components"},{"location":"reference/file-index.html#secretary-service","title":"Secretary Service \u2705","text":"File Path Module Description Exports Used In <code>src/lib/secretary/client.ts</code> secretary HTTP client for Secretary Service API <code>SecretaryServiceClient</code>, <code>SecretaryServiceError</code>, response interfaces Secretary API routes, external jobs <code>src/lib/secretary/adapter.ts</code> secretary Low-level API call functions <code>callPdfProcess</code>, <code>callTemplateTransform</code> Secretary client, template runner <code>src/lib/secretary/response-parser.ts</code> secretary Markdown response parsing <code>parseSecretaryMarkdownStrict</code>, <code>FrontmatterParseResult</code> External jobs, Secretary API routes <code>src/lib/secretary/types.ts</code> secretary Type definitions for Secretary Service Request/response interfaces Secretary client, API routes, external jobs <code>src/app/api/secretary/process-pdf/route.ts</code> secretary PDF transformation endpoint <code>POST</code> Library components <code>src/app/api/secretary/process-audio/route.ts</code> secretary Audio transformation endpoint <code>POST</code> Library components <code>src/app/api/secretary/process-video/route.ts</code> secretary Video transformation endpoint <code>POST</code> Library components <code>src/app/api/secretary/process-image/route.ts</code> secretary Image OCR endpoint <code>POST</code> Library components <code>src/app/api/secretary/session/process/route.ts</code> secretary Session import endpoint <code>POST</code> Event monitor components, session processing"},{"location":"reference/file-index.html#event-job-system","title":"Event Job System \u2705","text":"File Path Module Description Exports Used In <code>src/lib/event-job-repository.ts</code> event-job MongoDB repository for event jobs <code>EventJobRepository</code> API routes, session processor, event monitor <code>src/lib/session/session-processor.ts</code> event-job Session data processing utilities <code>vttToPlainText</code>, <code>extractVideoTranscript</code>, <code>buildSessionPayload</code> API routes, event monitor components <code>src/lib/session-repository.ts</code> event-job MongoDB repository for sessions <code>SessionRepository</code> API routes, event monitor components <code>src/app/api/event-job/jobs/[jobId]/route.ts</code> event-job Individual job operations <code>GET</code>, <code>DELETE</code>, <code>PATCH</code> Event monitor components <code>src/app/api/event-job/batches/[batchId]/route.ts</code> event-job Individual batch operations <code>GET</code>, <code>DELETE</code> Event monitor components <code>src/app/api/event-job/events/route.ts</code> event-job Event list and migration <code>GET</code>, <code>POST</code> Event monitor components"},{"location":"reference/file-index.html#transform-processing","title":"Transform &amp; Processing \u2705","text":"File Path Module Description Exports Used In <code>src/lib/transform/transform-service.ts</code> transform Central transformation service <code>TransformService</code>, transform option interfaces, <code>TransformResult</code> Library components, transform API routes <code>src/lib/transform/image-extraction-service.ts</code> transform PDF image extraction and storage <code>ImageExtractionService</code>, <code>ExtractedPageImage</code>, <code>ImageExtractionResult</code> Transform service, external jobs <code>src/lib/processing/gates.ts</code> processing Phase gate checking utilities <code>gateExtractPdf</code>, <code>gateTransformTemplate</code>, <code>gateIngestRag</code>, <code>GateContext</code>, <code>GateResult</code> Template decision, external jobs <code>src/lib/processing/phase-policy.ts</code> processing Processing phase control policies <code>PhaseDirective</code>, <code>PhasePolicies</code>, policy utilities External jobs, gates, Secretary API routes"},{"location":"reference/file-index.html#shadow-twin-system","title":"Shadow-Twin System \u2705","text":"File Path Module Description Exports Used In <code>src/lib/shadow-twin/shared.ts</code> shadow-twin Shared Shadow-Twin types and utilities <code>ShadowTwinState</code>, <code>toMongoShadowTwinState</code> Backend (Job documents), Frontend (Atoms) <code>src/lib/shadow-twin/analyze-shadow-twin.ts</code> shadow-twin Shadow-Twin analysis logic <code>analyzeShadowTwin</code> Frontend hooks, job start <code>src/lib/storage/shadow-twin.ts</code> shadow-twin Shadow-Twin file and directory utilities <code>generateShadowTwinName</code>, <code>generateShadowTwinFolderName</code>, <code>findShadowTwinFolder</code>, <code>findShadowTwinMarkdown</code> External jobs, gates, analysis <code>src/lib/external-jobs/shadow-twin-helpers.ts</code> shadow-twin Shadow-Twin folder creation utilities <code>findOrCreateShadowTwinFolder(provider, parentId, originalName, jobId)</code> \u2192 <code>string | undefined</code> External jobs <code>src/atoms/shadow-twin-atom.ts</code> shadow-twin Frontend Shadow-Twin state atom <code>shadowTwinStateAtom</code>, <code>FrontendShadowTwinState</code> Library components, file list, file preview <code>src/hooks/use-shadow-twin-analysis.ts</code> shadow-twin React hook for Shadow-Twin analysis <code>useShadowTwinAnalysis</code> File list component <p>Documentation: See Shadow-Twin Architecture and PDF Transformation Phases</p>"},{"location":"reference/file-index.html#database-repositories","title":"Database Repositories \u2705","text":"File Path Module Description Exports Used In <code>src/lib/db/chats-repo.ts</code> chat MongoDB repository for chat management <code>createChat</code>, <code>listChats</code>, <code>getChatById</code>, <code>touchChat</code>, <code>deleteChat</code> Chat API routes, chat components <code>src/lib/db/queries-repo.ts</code> chat MongoDB repository for query logging <code>insertQueryLog</code>, <code>appendRetrievalStep</code>, <code>updateQueryLogPartial</code>, <code>getQueryLogById</code>, <code>listRecentQueries</code>, <code>getFilteredDocumentCount(libraryOrId, filter)</code> Chat API routes, chat modules, query logger <code>src/lib/repositories/doc-meta-repo.ts</code> chat MongoDB repository for document metadata <code>computeDocMetaCollectionName</code>, <code>ensureFacetIndexes</code>, <code>upsertDocMeta</code>, <code>findDocs</code>, <code>deleteDocMeta</code> Summary retriever, ingestion service"},{"location":"reference/file-index.html#api-routes","title":"API Routes \u2705","text":"File Path Module Description Exports Used In <code>src/app/api/storage/filesystem/route.ts</code> storage Filesystem storage API <code>GET</code>, <code>POST</code>, <code>DELETE</code>, <code>PATCH</code> Storage providers <code>src/app/api/libraries/route.ts</code> library Library management API <code>GET</code>, <code>POST</code> Settings, storage context"},{"location":"reference/file-index.html#notes","title":"Notes","text":"<ul> <li>Files are organized by functional module</li> <li>\u2705 = Fully documented with JSDoc headers</li> <li>Export information completed for documented files</li> <li>Usage information updated based on dependency analysis</li> </ul>"},{"location":"reference/file-index.html#status","title":"Status","text":"<ul> <li>\u2705 Core Infrastructure: Documented (6 files)</li> <li>\u2705 Storage Layer: Documented (10 files)</li> <li>\u2705 Library System: Documented (4 files)</li> <li>\u2705 Chat System: Documented (9 files)</li> <li>\u2705 External Jobs System: Documented (18 files)</li> <li>\u2705 Secretary Service: Documented (9 files)</li> <li>\u2705 Event Job System: Documented (6 files)</li> <li>\u2705 Transform &amp; Processing: Documented (4 files)</li> <li>\u2705 Database Repositories: Documented (3 files)</li> <li>\u2705 API Routes: Documented (2 files)</li> <li>Total Documented: 71 files (~16.7% of ~424 files)</li> <li>\u23f3 Remaining Components: Pending</li> <li>\u23f3 Remaining API Routes: Pending</li> </ul>"},{"location":"reference/modules/chat.html","title":"Chat Module","text":"<p>Complete documentation for the Chat module.</p>"},{"location":"reference/modules/chat.html#overview","title":"Overview","text":"<p>The Chat module provides RAG-based chat functionality for knowledge exploration. Supports both regular chat mode and story mode with structured topic exploration.</p>"},{"location":"reference/modules/chat.html#key-files","title":"Key Files","text":""},{"location":"reference/modules/chat.html#types","title":"Types","text":"<ul> <li><code>src/types/chat.ts</code>: Chat interface for conversation management</li> <li><code>src/types/chat-response.ts</code>: Chat response types</li> <li><code>src/types/chat-processing.ts</code>: Chat processing step types</li> <li><code>src/types/retriever.ts</code>: Retriever input/output types</li> </ul>"},{"location":"reference/modules/chat.html#constants-configuration","title":"Constants &amp; Configuration","text":"<ul> <li><code>src/lib/chat/constants.ts</code>: Central chat configuration definitions</li> <li><code>src/lib/chat/config.ts</code>: Chat configuration normalization</li> </ul>"},{"location":"reference/modules/chat.html#orchestration","title":"Orchestration","text":"<ul> <li><code>src/lib/chat/orchestrator.ts</code>: Main orchestration for chat response generation</li> <li><code>src/lib/chat/loader.ts</code>: Library chat context loading</li> </ul>"},{"location":"reference/modules/chat.html#retrievers","title":"Retrievers","text":"<ul> <li><code>src/lib/chat/retrievers/chunks.ts</code>: Chunk-based retriever</li> <li><code>src/lib/chat/retrievers/summaries-mongo.ts</code>: Summary-based retriever</li> <li><code>src/lib/chat/retrievers/metadata-extractor.ts</code>: Metadata extraction</li> </ul>"},{"location":"reference/modules/chat.html#common-utilities","title":"Common Utilities","text":"<ul> <li><code>src/lib/chat/common/prompt.ts</code>: Prompt building utilities</li> <li><code>src/lib/chat/common/llm.ts</code>: LLM calling utilities</li> <li><code>src/lib/chat/common/filters.ts</code>: Filter building utilities</li> <li><code>src/lib/chat/common/question-analyzer.ts</code>: Question analysis for retriever selection</li> <li><code>src/lib/chat/common/budget.ts</code>: Budget management for source reduction</li> </ul>"},{"location":"reference/modules/chat.html#api-routes","title":"API Routes","text":"<ul> <li><code>src/app/api/chat/[libraryId]/stream/route.ts</code>: Chat streaming endpoint</li> </ul>"},{"location":"reference/modules/chat.html#exports","title":"Exports","text":""},{"location":"reference/modules/chat.html#types_1","title":"Types","text":"<ul> <li><code>Chat</code>: Chat conversation interface</li> <li><code>ChatResponse</code>: Chat response structure</li> <li><code>ChatProcessingStep</code>: Processing step types</li> <li><code>RetrieverInput</code>: Retriever input interface</li> <li><code>RetrieverOutput</code>: Retriever output interface</li> <li><code>OrchestratorInput</code>: Orchestration input</li> <li><code>OrchestratorOutput</code>: Orchestration output</li> </ul>"},{"location":"reference/modules/chat.html#constants","title":"Constants","text":"<ul> <li><code>AnswerLength</code>: Answer length type and values</li> <li><code>Retriever</code>: Retriever method type and values</li> <li><code>TargetLanguage</code>: Target language type and values</li> <li><code>Character</code>: Character type and values</li> <li><code>SocialContext</code>: Social context type and values</li> </ul>"},{"location":"reference/modules/chat.html#functions","title":"Functions","text":"<ul> <li><code>runChatOrchestrated()</code>: Main orchestration function</li> <li><code>analyzeQuestionForRetriever()</code>: Question analysis function</li> <li><code>buildPrompt()</code>: Prompt building function</li> <li><code>callOpenAI()</code>: LLM calling function</li> <li><code>getVectorIndexForLibrary(library, chatConfig?)</code>: Get vector index name for library</li> </ul>"},{"location":"reference/modules/chat.html#usage-examples","title":"Usage Examples","text":""},{"location":"reference/modules/chat.html#chat-streaming-api-route","title":"Chat Streaming (API Route)","text":"<pre><code>// POST /api/chat/[libraryId]/stream\nconst response = await fetch('/api/chat/library-id/stream', {\n  method: 'POST',\n  body: JSON.stringify({\n    message: 'What is this library about?',\n    answerLength: 'ausf\u00fchrlich',\n    chatId: 'optional-chat-id'\n  })\n});\n</code></pre>"},{"location":"reference/modules/chat.html#using-chat-orchestrator","title":"Using Chat Orchestrator","text":"<pre><code>import { runChatOrchestrated } from '@/lib/chat/orchestrator';\n\nconst result = await runChatOrchestrated({\n  libraryId: 'lib-id',\n  question: 'What is this about?',\n  retriever: 'chunk',\n  chatConfig: { targetLanguage: 'de' }\n});\n</code></pre>"},{"location":"reference/modules/chat.html#getting-vector-index-name","title":"Getting Vector Index Name","text":"<pre><code>import { getVectorIndexForLibrary } from '@/lib/chat/config';\n\n// Get vector index name for a library\n// Uses config.vectorStore.indexName if set, otherwise derives from library label\nconst indexName = getVectorIndexForLibrary(\n  { id: 'lib-id', label: 'My Library' },\n  { vectorStore: { indexName: 'custom-index' } } // optional chat config\n);\n</code></pre>"},{"location":"reference/modules/chat.html#dependencies","title":"Dependencies","text":"<ul> <li>Library System: Uses <code>@/lib/services/library-service</code> for library access</li> <li>Database: Uses <code>@/lib/mongodb-service</code> for chat and query persistence</li> <li>Storage: Uses storage providers for file access</li> <li>External: Uses OpenAI API for LLM calls, MongoDB Atlas Vector Search for vector search</li> </ul>"},{"location":"reference/modules/chat.html#chat-flow","title":"Chat Flow","text":"<ol> <li>Question Analysis: Analyze question to recommend retriever</li> <li>Retrieval: Retrieve relevant sources using selected retriever</li> <li>Prompt Building: Build prompt with sources and configuration</li> <li>LLM Call: Call OpenAI API with prompt</li> <li>Response Parsing: Parse structured response</li> <li>Logging: Log query and response for analytics</li> </ol>"},{"location":"reference/modules/chat.html#retriever-types","title":"Retriever Types","text":"<ul> <li><code>chunk</code>: Semantic search in MongoDB Vector Search for specific chunks</li> <li><code>summary</code>: MongoDB search for document summaries</li> <li><code>chunkSummary</code>: Loads all chunks from MongoDB without vector search</li> <li><code>auto</code>: Automatic retriever selection based on question analysis</li> </ul>"},{"location":"reference/modules/chat.html#story-mode","title":"Story Mode","text":"<p>Story mode provides structured topic exploration: - TOC (Table of Contents) queries - Structured topic hierarchy - Narrative exploration of knowledge</p>"},{"location":"reference/modules/chat.html#configuration-options","title":"Configuration Options","text":"<ul> <li>Answer Length: kurz, mittel, ausf\u00fchrlich, unbegrenzt</li> <li>Target Language: de, en, it, fr, es, ar</li> <li>Character: Various character perspectives</li> <li>Social Context: Formal, informal, technical</li> <li>Gender Inclusive: Gender-neutral formulations</li> </ul>"},{"location":"reference/modules/library.html","title":"Library Module","text":"<p>Complete documentation for the Library module.</p>"},{"location":"reference/modules/library.html#overview","title":"Overview","text":"<p>The Library module manages library configuration, state, and UI components. Libraries represent collections of files organized by storage backend and user ownership.</p>"},{"location":"reference/modules/library.html#key-files","title":"Key Files","text":""},{"location":"reference/modules/library.html#types","title":"Types","text":"<ul> <li><code>src/types/library.ts</code>: Complete library type definitions including <code>Library</code>, <code>ClientLibrary</code>, <code>LibraryChatConfig</code>, <code>StorageConfig</code>, and <code>PublicLibraryConfig</code></li> </ul>"},{"location":"reference/modules/library.html#state-management","title":"State Management","text":"<ul> <li><code>src/atoms/library-atom.ts</code>: Jotai atoms for library state management including active library, folder navigation, and file caching</li> </ul>"},{"location":"reference/modules/library.html#service","title":"Service","text":"<ul> <li><code>src/lib/services/library-service.ts</code>: MongoDB-based library service for CRUD operations</li> </ul>"},{"location":"reference/modules/library.html#components","title":"Components","text":"<ul> <li><code>src/components/library/library.tsx</code>: Main library component combining file tree, list, and preview</li> <li><code>src/components/library/library-header.tsx</code>: Library header with switcher and actions</li> <li><code>src/components/library/library-switcher.tsx</code>: Library selection component</li> <li><code>src/components/library/file-list.tsx</code>: File list component with header actions and record-level operations</li> </ul>"},{"location":"reference/modules/library.html#exports","title":"Exports","text":""},{"location":"reference/modules/library.html#types_1","title":"Types","text":"<ul> <li><code>Library</code>: Complete library configuration type</li> <li><code>ClientLibrary</code>: Client-side library type</li> <li><code>LibraryChatConfig</code>: Chat/RAG configuration</li> <li><code>StorageConfig</code>: Storage provider configuration</li> <li><code>PublicLibraryConfig</code>: Public publishing configuration</li> <li><code>StorageProviderType</code>: Supported storage provider types</li> </ul>"},{"location":"reference/modules/library.html#atoms","title":"Atoms","text":"<ul> <li><code>libraryAtom</code>: Main library state atom</li> <li><code>activeLibraryIdAtom</code>: Active library ID atom</li> <li><code>librariesAtom</code>: Libraries list atom</li> <li><code>activeLibraryAtom</code>: Active library object atom</li> <li><code>currentFolderIdAtom</code>: Current folder ID atom</li> <li><code>folderItemsAtom</code>: Folder items atom family</li> </ul>"},{"location":"reference/modules/library.html#service_1","title":"Service","text":"<ul> <li><code>LibraryService</code>: Singleton service class for library operations</li> </ul>"},{"location":"reference/modules/library.html#components_1","title":"Components","text":"<ul> <li><code>Library</code>: Main library component</li> <li><code>LibraryHeader</code>: Library header component</li> <li><code>LibrarySwitcher</code>: Library switcher component</li> <li><code>FileList</code>: File list component with actions and batch operations</li> </ul>"},{"location":"reference/modules/library.html#usage-examples","title":"Usage Examples","text":""},{"location":"reference/modules/library.html#accessing-library-state","title":"Accessing Library State","text":"<pre><code>import { useAtomValue } from 'jotai';\nimport { activeLibraryAtom, librariesAtom } from '@/atoms/library-atom';\n\nfunction MyComponent() {\n  const activeLibrary = useAtomValue(activeLibraryAtom);\n  const libraries = useAtomValue(librariesAtom);\n  // Use library data\n}\n</code></pre>"},{"location":"reference/modules/library.html#using-library-service","title":"Using Library Service","text":"<pre><code>import { LibraryService } from '@/lib/services/library-service';\n\nconst service = LibraryService.getInstance();\nconst libraries = await service.getUserLibraries(userEmail);\nconst library = await service.getLibrary(userEmail, libraryId);\n</code></pre>"},{"location":"reference/modules/library.html#library-component","title":"Library Component","text":"<pre><code>import { Library } from '@/components/library/library';\n\nexport default function LibraryPage() {\n  return &lt;Library /&gt;;\n}\n</code></pre>"},{"location":"reference/modules/library.html#using-root-items-hook","title":"Using Root Items Hook","text":"<pre><code>import { useRootItems, useRootItemsSync } from '@/hooks/use-root-items';\n\nfunction MyComponent() {\n  // Get function to load root items (async)\n  const getRootItems = useRootItems();\n\n  // Get root items synchronously if already loaded\n  const rootItems = useRootItemsSync();\n\n  useEffect(() =&gt; {\n    if (!rootItems) {\n      // Load root items if not available\n      getRootItems().then(items =&gt; {\n        console.log('Root items loaded:', items);\n      });\n    }\n  }, [getRootItems, rootItems]);\n}\n</code></pre>"},{"location":"reference/modules/library.html#dependencies","title":"Dependencies","text":"<ul> <li>Storage Layer: Uses <code>@/lib/storage/storage-factory</code> for provider access</li> <li>Database: Uses <code>@/lib/mongodb-service</code> for persistence</li> <li>State Management: Uses Jotai for state management</li> <li>Chat System: Uses <code>@/lib/chat/constants</code> for chat configuration types</li> </ul>"},{"location":"reference/modules/library.html#library-configuration","title":"Library Configuration","text":"<p>Libraries support: - Storage Configuration: Provider type and authentication - Chat Configuration: RAG settings, target language, character - Public Publishing: Gallery and story mode configuration - Gallery Configuration: Facets, detail view types</p>"},{"location":"reference/modules/library.html#state-management_1","title":"State Management","text":"<p>Library state is managed through Jotai atoms with a centralized caching strategy:</p>"},{"location":"reference/modules/library.html#state-architecture","title":"State Architecture","text":"<p>The Library module uses a centralized state management approach with Jotai atoms:</p> <ul> <li>Global State: Libraries list, active library</li> <li>Navigation State: Current folder, path</li> <li>UI State: Loading states, selected files</li> <li>Cache: Folder items cache for performance</li> </ul>"},{"location":"reference/modules/library.html#central-state-logic","title":"Central State Logic","text":""},{"location":"reference/modules/library.html#1-folder-items-cache-folderitemsatom","title":"1. Folder Items Cache (<code>folderItemsAtom</code>)","text":"<p>The <code>folderItemsAtom</code> is an atom family that caches folder contents by folder ID:</p> <pre><code>// Atom family for folder-specific caching\nexport const folderItemsAtom = atomFamily((folderId: string) =&gt; \n  atom&lt;StorageItem[] | null&gt;(null)\n);\n</code></pre> <p>How it works: - Each folder has its own cached state - When <code>currentFolderId === 'root'</code>, root items are cached - Components can access cached items synchronously without API calls - Cache is updated when folders are loaded via <code>StorageContext</code></p> <p>Benefits: - Eliminates duplicate API calls for the same folder - Provides instant access to already-loaded data - Reduces server load and improves performance</p>"},{"location":"reference/modules/library.html#2-root-items-central-management-userootitems","title":"2. Root Items Central Management (<code>useRootItems</code>)","text":"<p>The <code>useRootItems</code> hook provides centralized access to root items:</p> <pre><code>// Hook automatically uses cache if available\nconst getRootItems = useRootItems();\n\n// Synchronous access if root items are already cached\nconst rootItems = useRootItemsSync();\n</code></pre> <p>How it works: - Checks <code>folderItemsAtom</code> if <code>currentFolderId === 'root'</code> - Falls back to API call via <code>StorageContext.listItems('root')</code> - Uses request deduplication from <code>StorageContext</code> - All components share the same cached root items</p> <p>Integration with StorageContext: - <code>StorageContext</code> loads root items once when library is initialized - Updates <code>folderItemsAtom</code> when root items are loaded - <code>useRootItems</code> reads from cache, avoiding duplicate requests</p>"},{"location":"reference/modules/library.html#3-request-deduplication","title":"3. Request Deduplication","text":"<p>The <code>StorageContext</code> implements request deduplication:</p> <ul> <li>Multiple simultaneous requests for the same folder are merged</li> <li>Only one API call is made, all callers receive the same promise</li> <li>Prevents duplicate network requests during rapid navigation</li> </ul>"},{"location":"reference/modules/library.html#4-state-flow","title":"4. State Flow","text":"<pre><code>1. User navigates to folder\n   \u2193\n2. StorageContext.listItems(folderId)\n   \u2193\n3. Request deduplication checks for pending requests\n   \u2193\n4. API call (if not cached/deduplicated)\n   \u2193\n5. folderItemsAtom updated with results\n   \u2193\n6. All components using folderItemsAtom receive updates\n</code></pre>"},{"location":"reference/modules/library.html#state-atoms-reference","title":"State Atoms Reference","text":"Atom Type Purpose <code>libraryAtom</code> <code>LibraryState</code> Main library state container <code>activeLibraryIdAtom</code> <code>string</code> Currently active library ID <code>librariesAtom</code> <code>ClientLibrary[]</code> List of all user libraries <code>activeLibraryAtom</code> <code>ClientLibrary \\| undefined</code> Active library object (derived) <code>currentFolderIdAtom</code> <code>string</code> Current folder ID (default: 'root') <code>folderItemsAtom</code> <code>atomFamily</code> Folder items cache by folder ID <code>libraryStatusAtom</code> <code>LibraryStatus</code> Library loading status"},{"location":"reference/modules/library.html#best-practices","title":"Best Practices","text":"<ol> <li>Always use <code>folderItemsAtom</code> for folder contents - Don't make direct API calls</li> <li>Use <code>useRootItems</code> for root items - Provides cache-aware access</li> <li>Let StorageContext manage loading - Components should read from atoms, not trigger loads</li> <li>Cache is automatically updated - No manual cache invalidation needed</li> </ol>"},{"location":"reference/modules/library.html#file-list-component","title":"File List Component","text":"<p>The <code>FileList</code> component displays files and folders in a table format with header actions and record-level operations.</p>"},{"location":"reference/modules/library.html#header-actions","title":"Header Actions","text":"<p>The header bar (visible when not in compact mode) provides batch operations:</p> Button Icon Function When Visible Refresh <code>RefreshCw</code> Reloads current folder contents Always File Category Filter Filter icon Filters files by category (PDF, Audio, Video, etc.) Always Batch Transcription <code>ScrollText</code> Opens transcription dialog for selected audio/video files When audio/video files are selected Batch Transformation <code>Plus</code> Opens transformation dialog for selected PDF files When PDF files are selected Batch Ingest Text button Ingests selected documents into RAG system When PDF/Markdown files are selected Bulk Delete <code>Trash2</code> Deletes all selected files When any files are selected <p>Usage: 1. Select files using checkboxes 2. Header buttons appear automatically based on file types selected 3. Click button to perform batch operation 4. Operation runs in background, progress shown per file</p>"},{"location":"reference/modules/library.html#record-level-actions","title":"Record-Level Actions","text":"<p>Each file row provides the following actions:</p> Element Function Details Checkbox Select file for batch operations Leftmost column, enables batch actions File Icon Visual file type indicator Shows icon based on MIME type (PDF, Audio, Video, Text) File Name Select/Edit file Click to select, double-click to rename Shadow-Twin Icon View Shadow-Twin files Blue <code>FileText</code> icon, shows if Shadow-Twin exists (transcript or transformed file or directory) Create Transcript Create new transcript Plus icon, only shown for transcribable files without Shadow-Twin Delete Button Delete file Red <code>Trash2</code> icon, deletes file after confirmation <p>File Interactions: - Single Click: Selects file (opens in preview) - Double Click: Enters rename mode - Long Press (touch): Opens context menu - Drag &amp; Drop: Reorder files (if supported)</p> <p>Shadow-Twin Integration: - Shadow-Twin files (transcripts and transformed files) are grouped with their base files - Single Shadow-Twin icon indicates if Shadow-Twin exists (file or directory) - Clicking Shadow-Twin icon opens the transformed file (if available) or first transcript file - Shadow-Twin state is automatically analyzed and displayed</p>"},{"location":"reference/modules/library.html#file-categories","title":"File Categories","text":"<p>Files are automatically categorized: - PDF Files: Can be transformed, transcribed (OCR), and ingested - Audio Files: Can be transcribed and ingested - Video Files: Can be transcribed and ingested - Markdown Files: Can be ingested, may be transcripts or transformed files - Other Files: Display only, limited operations</p>"},{"location":"reference/modules/library.html#batch-operations","title":"Batch Operations","text":"<p>Batch operations support multiple files simultaneously:</p> <ol> <li>Batch Transcription: Transcribes multiple audio/video files in parallel</li> <li>Batch Transformation: Transforms multiple PDFs to Markdown</li> <li>Batch Ingestion: Ingests multiple documents into RAG system</li> <li>Bulk Delete: Deletes multiple files at once</li> </ol> <p>Selection: - Use checkboxes to select individual files - Selection persists across folder navigation - Header shows count of selected files</p>"},{"location":"reference/modules/library.html#api-integration","title":"API Integration","text":"<p>Libraries are managed through: - <code>GET /api/libraries</code>: Get user libraries - <code>POST /api/libraries</code>: Create/update library - <code>GET /api/libraries/[id]</code>: Get specific library - <code>PUT /api/libraries/[id]</code>: Update library - <code>DELETE /api/libraries/[id]</code>: Delete library</p>"},{"location":"reference/modules/storage.html","title":"Storage Module","text":"<p>Complete documentation for the Storage module.</p>"},{"location":"reference/modules/storage.html#overview","title":"Overview","text":"<p>The Storage module provides an abstraction layer for file storage operations across multiple backends. It supports local filesystem and OneDrive storage, with Nextcloud support in development.</p>"},{"location":"reference/modules/storage.html#key-files","title":"Key Files","text":""},{"location":"reference/modules/storage.html#core-types","title":"Core Types","text":"<ul> <li><code>src/lib/storage/types.ts</code>: Core type definitions including <code>StorageProvider</code> interface, <code>StorageItem</code>, and <code>StorageValidationResult</code></li> </ul>"},{"location":"reference/modules/storage.html#factory-providers","title":"Factory &amp; Providers","text":"<ul> <li><code>src/lib/storage/storage-factory.ts</code>: Main factory for creating storage providers</li> <li><code>src/lib/storage/filesystem-provider.ts</code>: Local filesystem provider implementation</li> <li><code>src/lib/storage/onedrive-provider.ts</code>: OneDrive provider implementation</li> <li><code>src/lib/storage/storage-factory-mongodb.ts</code>: MongoDB-based storage factory</li> </ul>"},{"location":"reference/modules/storage.html#client-server","title":"Client &amp; Server","text":"<ul> <li><code>src/lib/storage/filesystem-client.ts</code>: Client-side filesystem provider</li> <li><code>src/lib/storage/server-provider.ts</code>: Server-side provider helper</li> </ul>"},{"location":"reference/modules/storage.html#context-hooks","title":"Context &amp; Hooks","text":"<ul> <li><code>src/contexts/storage-context.tsx</code>: React context for storage provider management</li> <li><code>src/hooks/use-storage-provider.tsx</code>: React hook for storage provider access</li> </ul>"},{"location":"reference/modules/storage.html#utilities","title":"Utilities","text":"<ul> <li><code>src/lib/storage/supported-types.ts</code>: Supported library type definitions</li> </ul>"},{"location":"reference/modules/storage.html#exports","title":"Exports","text":""},{"location":"reference/modules/storage.html#types","title":"Types","text":"<ul> <li><code>StorageProvider</code>: Core interface for storage providers</li> <li><code>StorageItem</code>: Unified type for files and folders</li> <li><code>StorageItemMetadata</code>: Metadata for storage items</li> <li><code>StorageValidationResult</code>: Result of validation operations</li> <li><code>StorageError</code>: Error type for storage operations</li> </ul>"},{"location":"reference/modules/storage.html#classes","title":"Classes","text":"<ul> <li><code>StorageFactory</code>: Singleton factory for creating providers</li> <li><code>FileSystemProvider</code>: Local filesystem provider</li> <li><code>OneDriveProvider</code>: OneDrive provider</li> <li><code>FileSystemClient</code>: Client-side filesystem provider</li> <li><code>MongoDBStorageFactory</code>: MongoDB-based factory</li> </ul>"},{"location":"reference/modules/storage.html#functions","title":"Functions","text":"<ul> <li><code>getServerProvider()</code>: Creates server-side storage provider</li> <li><code>isSupportedLibraryType()</code>: Type guard for library types</li> <li><code>getSupportedLibraryTypesString()</code>: UI helper for supported types</li> </ul>"},{"location":"reference/modules/storage.html#usage-examples","title":"Usage Examples","text":""},{"location":"reference/modules/storage.html#creating-a-provider-client-side","title":"Creating a Provider (Client-side)","text":"<pre><code>import { StorageFactory } from '@/lib/storage/storage-factory';\n\nconst factory = StorageFactory.getInstance();\nconst provider = await factory.getProvider(libraryId);\nconst items = await provider.listItemsById('root');\n</code></pre>"},{"location":"reference/modules/storage.html#using-storage-context-react","title":"Using Storage Context (React)","text":"<pre><code>import { useStorage } from '@/contexts/storage-context';\n\nfunction MyComponent() {\n  const { provider, listItems, currentLibrary } = useStorage();\n  // Use provider for storage operations\n}\n</code></pre>"},{"location":"reference/modules/storage.html#server-side-provider","title":"Server-side Provider","text":"<pre><code>import { getServerProvider } from '@/lib/storage/server-provider';\n\nconst provider = await getServerProvider(userEmail, libraryId);\nconst items = await provider.listItemsById('root');\n</code></pre>"},{"location":"reference/modules/storage.html#dependencies","title":"Dependencies","text":"<ul> <li>Core Infrastructure: Uses <code>@/lib/env</code>, <code>@/lib/auth</code>, <code>@/lib/mongodb-service</code></li> <li>Library System: Uses <code>@/types/library</code>, <code>@/lib/services/library-service</code></li> <li>External: Uses Clerk for authentication, MongoDB for data storage</li> </ul>"},{"location":"reference/modules/storage.html#architecture","title":"Architecture","text":"<p>The storage module follows a layered architecture:</p> <ol> <li>Types Layer: Pure type definitions</li> <li>Provider Layer: Concrete provider implementations</li> <li>Factory Layer: Provider creation and management</li> <li>Context Layer: React integration</li> <li>API Layer: Server-side route handlers</li> </ol>"},{"location":"reference/modules/storage.html#supported-storage-backends","title":"Supported Storage Backends","text":"<ul> <li>\u2705 Local File System: Direct filesystem access</li> <li>\u2705 OneDrive: Microsoft OneDrive integration</li> <li>\ud83d\udea7 Nextcloud: In development</li> </ul>"},{"location":"reference/modules/storage.html#error-handling","title":"Error Handling","text":"<p>Storage operations use typed errors (<code>StorageError</code>) with error codes: - <code>HTTP_ERROR</code>: Network/HTTP errors - <code>AUTH_ERROR</code>: Authentication failures - <code>NOT_FOUND</code>: Item not found - <code>VALIDATION_ERROR</code>: Configuration validation failures</p>"},{"location":"reference/modules/storage.html#performance-optimizations","title":"Performance Optimizations","text":"<ul> <li>Caching: Client-side caching for file listings</li> <li>Request Deduplication: Prevents duplicate concurrent requests</li> <li>Lazy Loading: Providers created on-demand</li> <li>Connection Pooling: MongoDB connection reuse</li> </ul>"},{"location":"use-cases/index.html","title":"Use Cases","text":"<p>Short guides for common tasks in Common Knowledge Scout.</p>"},{"location":"use-cases/index.html#basic-use-cases","title":"Basic Use Cases","text":"<ul> <li>Library Setup \u2013 Create and configure a library</li> <li>PDF Transformation \u2013 Transform PDF files to Markdown</li> <li>Media Transformation \u2013 Transcribe audio and video files</li> </ul>"},{"location":"use-cases/index.html#advanced-use-cases","title":"Advanced Use Cases","text":"<ul> <li>Web Scraping \u2013 Scrape web content and import events</li> <li>Publishing \u2013 Publish library publicly</li> <li>Chat &amp; Story Mode \u2013 Explore knowledge with chat</li> </ul>"},{"location":"use-cases/index.html#advanced-features","title":"Advanced Features","text":"<ul> <li>Batch Operations \u2013 Process multiple files simultaneously</li> </ul>"},{"location":"use-cases/index.html#further-information","title":"Further Information","text":"<p>For detailed technical information see: - Architecture Documentation - Reference Documentation - Concepts Documentation</p>"},{"location":"use-cases/batch-operations.html","title":"Batch Operations","text":""},{"location":"use-cases/batch-operations.html#what-is-achieved","title":"What is achieved?","text":"<p>Process multiple files simultaneously for transformation, transcription, or ingestion. Save time by handling multiple operations in parallel.</p>"},{"location":"use-cases/batch-operations.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Active library selected</li> <li>Multiple files available in Library Browser</li> </ul>"},{"location":"use-cases/batch-operations.html#steps","title":"Steps","text":"<ol> <li>Open the Library view</li> <li>Navigate to the folder containing files</li> <li>Select multiple files:</li> <li>Use checkboxes to select individual files</li> <li>Or select all files in a folder</li> <li>Choose the operation:</li> <li>Transformation: Transform PDFs to Markdown</li> <li>Transcription: Transcribe audio/video files</li> <li>Ingestion: Ingest documents into RAG system</li> <li>Configure options:</li> <li>Select target language</li> <li>Choose template (if applicable)</li> <li>Set processing options</li> <li>Click \"Start Batch Processing\"</li> <li>Monitor progress:</li> <li>View overall progress bar</li> <li>See individual file status</li> <li>Check success/failure counts</li> <li>Review results:</li> <li>Successful transformations appear as Shadow Twins</li> <li>Failed files show error messages</li> <li>Retry failed operations if needed</li> </ol>"},{"location":"use-cases/batch-operations.html#result","title":"Result","text":"<p>Multiple files are processed in parallel. Results appear as they complete, with success/failure status for each file. Internally the same three phases are used as for single-file PDF transformation (Extract \u2192 Template \u2192 Ingestion); depending on existing artifacts, individual phases may be skipped automatically.</p>"},{"location":"use-cases/batch-operations.html#tips","title":"Tips","text":"<ul> <li>Batch operations run in the background</li> <li>You can continue working while processing</li> <li>Failed files can be retried individually</li> <li>Progress is saved - you can refresh without losing state</li> <li>Large batches may take time - be patient</li> </ul>"},{"location":"use-cases/batch-operations.html#further-information","title":"Further Information","text":"<ul> <li>Transform Service Documentation</li> <li>PDF Transformation for single files</li> <li>Media Transformation for single files</li> </ul>"},{"location":"use-cases/chat-exploration.html","title":"Chat &amp; Story Mode","text":""},{"location":"use-cases/chat-exploration.html#what-is-achieved","title":"What is achieved?","text":"<p>Explore your knowledge base using natural language queries. The Chat interface uses RAG (Retrieval-Augmented Generation) to find relevant content and generate answers based on your library's documents.</p>"},{"location":"use-cases/chat-exploration.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Active library selected</li> <li>Documents transformed and ingested into the library</li> </ul>"},{"location":"use-cases/chat-exploration.html#how-the-data-gets-there-quick-link","title":"How the data gets there (quick link)","text":"<p>If you want the full \u201cfile \u2192 story \u2192 askable\u201d pipeline explained end-to-end (including Shadow\u2011Twin, ingestion, storage backends and typical failure modes), see:</p> <ul> <li><code>use-cases/file-to-story.md</code></li> </ul>"},{"location":"use-cases/chat-exploration.html#steps","title":"Steps","text":"<ol> <li>Open the Library view</li> <li>Click the Chat icon or open the chat panel</li> <li>Configure chat settings (optional):</li> <li>Answer Length: Short, medium, or long answers</li> <li>Retriever: Chunk-based or summary-based retrieval</li> <li>Target Language: Language for responses</li> <li>Character: Perspective for answers (e.g., expert, beginner)</li> <li>Social Context: Context for answer generation</li> <li>Type your question in the chat input</li> <li>The system will:</li> <li>Analyze your question</li> <li>Retrieve relevant documents</li> <li>Generate an answer based on your library content</li> <li>Display sources used for the answer</li> <li>Continue the conversation with follow-up questions</li> <li>Use Story Mode for narrative-style exploration</li> </ol>"},{"location":"use-cases/chat-exploration.html#result","title":"Result","text":"<p>You receive answers based on your library's content with source citations. The chat history is saved for future reference.</p>"},{"location":"use-cases/chat-exploration.html#tips","title":"Tips","text":"<ul> <li>Use specific questions for better results</li> <li>Check source citations to verify information</li> <li>Story Mode provides narrative-style exploration</li> <li>Chat history is saved automatically</li> <li>Filter by facets/metadata for focused queries</li> </ul>"},{"location":"use-cases/chat-exploration.html#further-information","title":"Further Information","text":"<ul> <li>Chat System Documentation</li> <li>Chat Orchestration</li> </ul>"},{"location":"use-cases/file-to-story.html","title":"File \u2192 Story (End-to-End)","text":""},{"location":"use-cases/file-to-story.html#file-story-askable-end-to-end","title":"File \u2192 Story \u2192 Askable (End-to-End)","text":""},{"location":"use-cases/file-to-story.html#1-goal-from-file-story-askable","title":"1) Goal: \u201cFrom file \u2192 story \u2192 askable\u201d","text":"<p>This page explains the end-to-end path of a file (PDF / audio / video / markdown) through:</p> <ul> <li>Shadow\u2011Twin (transcript + transformation artifacts)</li> <li>Ingestion (MongoDB Vector Search: meta + chunks)</li> <li>Explorer / Chat (story UI + RAG Q&amp;A)</li> </ul> <p>It is designed as an operational overview and links to the deeper architecture docs where needed.</p>"},{"location":"use-cases/file-to-story.html#2-terms-quick-glossary","title":"2) Terms (quick glossary)","text":"<ul> <li>Source: the original file in a library (PDF/audio/video/markdown).</li> <li>Shadow\u2011Twin: derived artifacts for a source (markdown artifacts + binary fragments).</li> <li>Transcript: extracted text as markdown (often minimal frontmatter).</li> <li>Transformation: template-based markdown with frontmatter/metadata (structured \u201cstory input\u201d).</li> <li>Ingestion: converting transformation/transcript into:</li> <li>meta doc (for gallery/explorer + facets)</li> <li>chunk docs (for semantic retrieval)</li> <li>MetaDoc: the per-document \u201cmetadata record\u201d stored in the vector collection (<code>kind: 'meta'</code>).</li> <li>Chunk: a text segment with an embedding (<code>kind: 'chunk'</code>).</li> </ul>"},{"location":"use-cases/file-to-story.html#3-end-to-end-flow-numbered","title":"3) End-to-end flow (numbered)","text":""},{"location":"use-cases/file-to-story.html#step-0-the-file-exists-in-a-library-storage-provider","title":"Step 0 \u2014 The file exists in a Library (Storage Provider)","text":"<p>The source file lives in your library storage (filesystem / OneDrive / \u2026 via a provider abstraction).</p>"},{"location":"use-cases/file-to-story.html#step-1-start-a-pipeline-job-unified-endpoint","title":"Step 1 \u2014 Start a pipeline job (Unified endpoint)","text":"<p>You trigger processing via the unified endpoint:</p> <ul> <li><code>POST /api/pipeline/process</code></li> </ul> <p>This creates an External Job with steps:</p> <ul> <li><code>extract_*</code> (pdf/audio/video)</li> <li><code>transform_template</code></li> <li><code>ingest_rag</code></li> </ul> <p>Reference: <code>docs/architecture/pipeline-phases.md</code></p>"},{"location":"use-cases/file-to-story.html#step-2-job-start-load-source-binary-analyze-shadowtwin","title":"Step 2 \u2014 Job start: load source binary + analyze Shadow\u2011Twin","text":"<p>The worker starts the job:</p> <ul> <li>loads source bytes from the provider (<code>getBinary</code>)</li> <li>analyzes existing Shadow\u2011Twin state (so gates can skip redundant work)</li> </ul>"},{"location":"use-cases/file-to-story.html#step-3-extract-transcribeocr-transcript-artifact","title":"Step 3 \u2014 Extract (transcribe/OCR) \u2192 Transcript artifact","text":"<p>For PDFs/audio/video, phase 1 creates a transcript artifact (markdown).</p> <p>For markdown sources, \u201cextract\u201d is effectively skipped: the source is already text.</p>"},{"location":"use-cases/file-to-story.html#step-4-transform-template-transformation-artifact-story-ready-markdown","title":"Step 4 \u2014 Transform (template) \u2192 Transformation artifact (story-ready markdown)","text":"<p>Template transformation generates the \u201cstory-ready\u201d markdown:</p> <ul> <li>validated/extended frontmatter</li> <li>chapters / summary / teaser / facets, etc.</li> </ul> <p>This is the best ingestion input because it includes structured metadata.</p> <p>Reference: <code>docs/architecture/shadow-twin.md</code>, <code>docs/architecture/template-system.md</code></p>"},{"location":"use-cases/file-to-story.html#step-5-ingest-rag-mongodb-vector-search-meta-chunks","title":"Step 5 \u2014 Ingest (RAG) \u2192 MongoDB Vector Search (meta + chunks)","text":"<p>Ingestion turns the (preferably transformed) markdown into:</p> <ul> <li><code>kind: 'meta'</code> document: for gallery/explorer + facets</li> <li><code>kind: 'chunk'</code> documents: for semantic retrieval</li> <li><code>kind: 'chapterSummary'</code> docs (optional) for chapter-focused retrieval</li> </ul> <p>Reference: <code>docs/analysis/ingestion.md</code>, <code>docs/architecture/mongodb-vector-search.md</code></p>"},{"location":"use-cases/file-to-story.html#step-6-explorer-chat-askable-story","title":"Step 6 \u2014 Explorer &amp; Chat (askable story)","text":"<ul> <li>Explorer/Gallery reads meta documents to render cards (title, teaser, cover, etc.)</li> <li>Chat retrieves relevant chunks using <code>$vectorSearch</code> and generates answers (RAG)</li> </ul> <p>Reference: <code>docs/use-cases/chat-exploration.md</code></p>"},{"location":"use-cases/file-to-story.html#mermaid-sequence-overview-systems-apis","title":"Mermaid: Sequence overview (systems + APIs)","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  participant UI as Library UI\n  participant API as Next.js API\n  participant Jobs as External Jobs (MongoDB)\n  participant Provider as Storage Provider\n  participant ST as Shadow\u2011Twin Store (Mongo/FS)\n  participant Sec as Secretary Service\n  participant V as Vector Store (MongoDB Vector Search)\n\n  User-&gt;&gt;UI: Choose file + start processing\n  UI-&gt;&gt;API: POST /api/pipeline/process\n  API-&gt;&gt;Jobs: create job (steps: extract, transform, ingest)\n\n  API-&gt;&gt;API: best-effort trigger worker tick\n  API-&gt;&gt;API: POST /api/external/jobs/{jobId}/start (worker)\n\n  API-&gt;&gt;Provider: getBinary(sourceId)\n  API-&gt;&gt;ST: analyze existing artifacts (gates)\n\n  alt extract needed (pdf/audio/video)\n    API-&gt;&gt;Sec: submit extract/transcribe request\n    Sec--&gt;&gt;API: callback with transcript markdown\n    API-&gt;&gt;ST: upsert transcript artifact\n  else extract skipped\n    API-&gt;&gt;ST: (use existing transcript/source text)\n  end\n\n  alt template enabled\n    API-&gt;&gt;Sec: transform-by-template\n    Sec--&gt;&gt;API: callback with transformation markdown\n    API-&gt;&gt;ST: upsert transformation artifact\n  end\n\n  alt ingest enabled\n    API-&gt;&gt;V: upsert meta + chunks (+ chapterSummary)\n  end\n\n  UI-&gt;&gt;API: Load artifacts + ingestion status\n  UI-&gt;&gt;API: POST /api/library/{libraryId}/artifacts/batch-resolve\n  UI-&gt;&gt;API: GET /api/chat/{libraryId}/ingestion-status?fileId=...\n  User-&gt;&gt;UI: Ask question\n  UI-&gt;&gt;API: POST /api/chat/{libraryId}/stream\n  API-&gt;&gt;V: $vectorSearch (retrieve chunks)\n  API--&gt;&gt;UI: streamed answer + citations</code></pre>"},{"location":"use-cases/file-to-story.html#4-storage-matrix-what-lives-where","title":"4) Storage matrix (what lives where?)","text":"Data What it is File Storage (Provider) MongoDB (Shadow\u2011Twin) Azure Blob (Binary) MongoDB Vector Search Source file PDF/audio/video/markdown \u2705 \u2716\ufe0f (optional) \u2716\ufe0f Transcript artifact extracted markdown \u2705 (FS mode) \u2705 (mongo mode) \u2716\ufe0f \u2716\ufe0f Transformation artifact template markdown + frontmatter \u2705 (FS mode) \u2705 (mongo mode) \u2716\ufe0f \u2716\ufe0f Binary fragments metadata image references (cover, slides, etc.) (possible) \u2705 \u2716\ufe0f \u2716\ufe0f Binary fragments bytes images, PDFs (optional) \u2705 (FS fallback) \u2716\ufe0f \u2705 \u2716\ufe0f MetaDoc <code>kind: 'meta'</code> \u2716\ufe0f \u2716\ufe0f \u2716\ufe0f \u2705 Chunks <code>kind: 'chunk'</code> \u2716\ufe0f \u2716\ufe0f \u2716\ufe0f \u2705 Chapter summaries <code>kind: 'chapterSummary'</code> \u2716\ufe0f \u2716\ufe0f \u2716\ufe0f \u2705 <p>Notes:</p> <ul> <li>Shadow\u2011Twin \u201cprimary store\u201d is configurable per library (<code>filesystem</code> vs <code>mongo</code>).</li> <li>In mongo mode, binaries are typically served via Azure URLs (fallback exists via <code>/api/storage/filesystem</code> when a <code>fileId</code> exists).</li> </ul>"},{"location":"use-cases/file-to-story.html#5-typical-failure-modes-and-how-to-recognize-them","title":"5) Typical failure modes (and how to recognize them)","text":""},{"location":"use-cases/file-to-story.html#a-missing-templatename-for-transformations-determinism-break","title":"A) Missing <code>templateName</code> for transformations (determinism break)","text":"<p>Symptoms:</p> <ul> <li>transformation not found / wrong transformation chosen</li> <li>cover upload/frontmatter patch fails or updates \u201cthe wrong one\u201d</li> </ul> <p>Fix direction:</p> <ul> <li>treat <code>templateName</code> as required input for transformation operations</li> <li>avoid \u201cpick newest transformation\u201d as a default behavior in new call-sites</li> </ul>"},{"location":"use-cases/file-to-story.html#b-azure-container-missing-misconfigured","title":"B) Azure container missing / misconfigured","text":"<p>Symptoms:</p> <ul> <li>cover/slides/pdf upload fails with \u201ccontainer does not exist\u201d</li> <li>ingestion completes but without expected URLs</li> </ul> <p>Fix direction:</p> <ul> <li>ensure Azure storage configuration is present and the container exists</li> <li>keep FS fallback for development where Azure is unavailable</li> </ul>"},{"location":"use-cases/file-to-story.html#c-ingestion-input-empty-too-short","title":"C) Ingestion input empty / too short","text":"<p>Symptoms:</p> <ul> <li><code>ingest_rag</code> fails early, or results in \u201cno chunks\u201d</li> </ul> <p>Fix direction:</p> <ul> <li>treat empty ingestion input as a hard error (pipeline should not mark success)</li> <li>verify transformation/transcript output first</li> </ul>"},{"location":"use-cases/file-to-story.html#d-vector-search-index-not-ready-missing-token-index-fields","title":"D) Vector Search index not READY / missing token-index fields","text":"<p>Symptoms:</p> <ul> <li><code>$vectorSearch</code> errors</li> <li>errors like \u201cPath 'authors' needs to be indexed as token\u201d</li> </ul> <p>Fix direction:</p> <ul> <li>check index status (can take time: INITIAL_SYNC)</li> <li>ensure the index definition includes token indexing for array fields used in filters</li> </ul>"},{"location":"use-cases/file-to-story.html#6-debug-entry-points-fastest-way-to-locate-the-break","title":"6) Debug entry points (fastest way to locate the break)","text":""},{"location":"use-cases/file-to-story.html#external-job-steps","title":"External Job steps","text":"<p>Look at job steps for:</p> <ul> <li><code>extract_pdf</code> / <code>extract_audio</code> / <code>extract_video</code></li> <li><code>transform_template</code></li> <li><code>ingest_rag</code></li> </ul> <p>Key contract:</p> <ul> <li>job <code>completed</code> must not have any step still <code>pending</code> or <code>running</code></li> </ul>"},{"location":"use-cases/file-to-story.html#ingestion-status-api","title":"Ingestion status API","text":"<ul> <li><code>GET /api/chat/{libraryId}/ingestion-status?fileId=...</code></li> </ul> <p>Use it to verify:</p> <ul> <li>meta doc exists</li> <li>chunkCount / chaptersCount make sense</li> <li>doc is not stale compared to your current artifact</li> </ul>"},{"location":"use-cases/file-to-story.html#chat-stream-processing-steps-live","title":"Chat stream processing steps (live)","text":"<ul> <li><code>POST /api/chat/{libraryId}/stream</code> emits structured steps such as:</li> <li>retriever selection</li> <li>retrieval start/progress</li> <li>(optional) cache checks</li> <li>completion or error</li> </ul> <p>Use these steps to decide whether the failure is:</p> <ul> <li>\u201cretrieval\u201d (Vector Search) vs</li> <li>\u201cgeneration\u201d (LLM) vs</li> <li>\u201cmissing ingestion\u201d (no indexed docs)</li> </ul>"},{"location":"use-cases/file-to-story.html#related-docs-deep-dives","title":"Related docs (deep dives)","text":"<ul> <li>Pipeline phases: <code>docs/architecture/pipeline-phases.md</code></li> <li>Shadow\u2011Twin model: <code>docs/architecture/shadow-twin.md</code></li> <li>Ingestion runtime: <code>docs/analysis/ingestion.md</code></li> <li>Vector search architecture: <code>docs/architecture/mongodb-vector-search.md</code></li> <li>Chat use case: <code>docs/use-cases/chat-exploration.md</code></li> </ul>"},{"location":"use-cases/file-transformation-media.html","title":"Media Transformation (Audio/Video)","text":""},{"location":"use-cases/file-transformation-media.html#what-is-achieved","title":"What is achieved?","text":"<p>Transcribe audio and video files to text. Extract transcripts with speaker identification and save them as searchable Markdown files.</p>"},{"location":"use-cases/file-transformation-media.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Active library selected</li> <li>Audio or video file available in Library Browser</li> </ul>"},{"location":"use-cases/file-transformation-media.html#steps","title":"Steps","text":"<ol> <li>Open the Library view</li> <li>Navigate to the folder containing the audio/video file</li> <li>Select the media file (single file or multiple for batch processing)</li> <li>Click the Transcription icon or use the context menu</li> <li>In the transcription dialog:</li> <li>Select the target language for transcription</li> <li>Optional: Choose a template for structured output</li> <li>Click \"Start Transcription\"</li> <li>Monitor progress in the dialog</li> <li>After completion: The transcript Markdown file appears next to the original</li> </ol>"},{"location":"use-cases/file-transformation-media.html#result","title":"Result","text":"<p>A new Markdown file named <code>[OriginalName].md</code> is created. It contains the transcribed text, speaker identification (if available), and metadata in frontmatter.</p>"},{"location":"use-cases/file-transformation-media.html#tips","title":"Tips","text":"<ul> <li>Transcription runs in the background - you can continue working</li> <li>For video files, transcripts can be extracted from VTT files if available</li> <li>Errors are displayed in an error message</li> <li>Batch processing is supported for multiple files</li> </ul>"},{"location":"use-cases/file-transformation-media.html#further-information","title":"Further Information","text":"<ul> <li>Transform Service Documentation</li> <li>Batch Operations for multiple files</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html","title":"PDF Transformation","text":""},{"location":"use-cases/file-transformation-pdf.html#what-is-achieved","title":"What is achieved?","text":"<p>Transform PDF files into structured Markdown documents. Text, images, and structure are extracted and saved as searchable Markdown files. The transformation process consists of three phases: Extract, Template/Metadata, and Ingestion.</p>"},{"location":"use-cases/file-transformation-pdf.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Active library selected</li> <li>PDF file available in Library Browser</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html#steps","title":"Steps","text":"<ol> <li>Open the Library view</li> <li>Navigate to the folder containing the PDF file</li> <li>Select the PDF file (single file or multiple for batch processing)</li> <li>Click the Transformation icon or use the context menu</li> <li>In the transformation dialog:</li> <li>Select the target language for transformation</li> <li>Optional: Choose a template for structured output</li> <li>Optional: Enable \"Extract OCR images\" for Mistral OCR extracted images</li> <li>Optional: Enable \"Extract page images\" for PDF pages as images</li> <li>Click \"Start Transformation\"</li> <li>Monitor progress in the dialog (three phases: Extract \u2192 Template \u2192 Ingestion)</li> <li>After completion: The transformed Markdown files (Shadow Twins) appear next to the original</li> </ol>"},{"location":"use-cases/file-transformation-pdf.html#transformation-execution-modes","title":"Transformation Execution Modes","text":"<p>The transformation can run in two modes:</p>"},{"location":"use-cases/file-transformation-pdf.html#asynchronous-mode-default","title":"Asynchronous Mode (Default)","text":"<ul> <li>Used for larger files or when processing requires time</li> <li>Creates a background job that processes the PDF in three sequential phases</li> <li>Results are delivered via webhooks</li> <li>Creates two separate files: Transcript (<code>document.md</code>) and Transformed (<code>document.de.md</code>)</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html#synchronous-mode-legacycache","title":"Synchronous Mode (Legacy/Cache)","text":"<ul> <li>Used for small files or when results are cached</li> <li>Returns results immediately in the API response</li> <li>Creates only one file: Transformed (<code>document.de.md</code>) with frontmatter</li> <li>No separate transcript file is created</li> </ul> <p>Note: The mode is automatically selected based on file size and cache availability. Most transformations use the asynchronous mode.</p>"},{"location":"use-cases/file-transformation-pdf.html#transformation-phases","title":"Transformation Phases","text":"<p>The three phases are executed sequentially in asynchronous mode. In synchronous mode, phases 1 and 2 are combined into a single operation.</p>"},{"location":"use-cases/file-transformation-pdf.html#phase-1-extract-extraction","title":"Phase 1: Extract (Extraction)","text":"<ul> <li>What happens: PDF \u2192 Text + Images extraction</li> <li>Output (async mode): Markdown file without frontmatter (<code>document.md</code> - Transcript)</li> <li>Output (sync mode): Directly proceeds to Phase 2, no separate transcript file</li> <li>Images: Extracted as ZIP archives or Base64 (Mistral OCR)</li> <li>Shadow-Twin Directory: Created automatically if images are present (<code>.document.pdf/</code>)</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html#phase-2-templatemetadata","title":"Phase 2: Template/Metadata","text":"<ul> <li>What happens: Frontmatter is added and the document is structured (chapters, topics, etc.).</li> <li>Input (async mode): Markdown without frontmatter (<code>document.md</code>)</li> <li>Input (sync mode): Extracted text directly from Phase 1</li> <li>Output: Markdown with frontmatter (<code>document.de.md</code> - Transformed)</li> <li>Automatic skipping:</li> <li>If the document already has chapter metadata (<code>chapters</code> in frontmatter), the template phase is skipped.</li> <li>If only <code>pages</code> are missing, they are automatically reconstructed from the <code>--- Seite N ---</code> markers in the body (no extra analysis needed).</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html#how-metadata-is-extracted-via-templates","title":"How Metadata is Extracted via Templates","text":"<p>The template phase uses LLM-based extraction to analyze the document content and extract structured metadata:</p> <ol> <li>Template Selection:</li> <li> <p>Template is selected from MongoDB based on:</p> <ul> <li>Job parameters (<code>job.parameters.template</code>)</li> <li>Library configuration (<code>library.config.secretaryService.pdfDefaults.template</code>)</li> <li>Fallback to default templates if none specified</li> </ul> </li> <li> <p>Template Structure:</p> </li> <li>Templates contain:<ul> <li>Frontmatter Schema: Defines metadata fields with placeholders like <code>{{title|Description}}</code></li> <li>System Prompt: Instructions for the LLM on how to extract and structure data</li> <li>Markdown Body: Optional template structure for the output</li> </ul> </li> </ol> <p>Example template field:    <pre><code>title: {{title|Vollst\u00e4ndiger Titel des Dokuments (extraktiv, aus Heading/Frontseite)}}\nchapters: {{chapters|Array von Kapiteln mit title, level (1\u20133), order, startPage, endPage, pageCount, summary, keywords}}\n</code></pre></p> <ol> <li>LLM Processing:</li> <li>The extracted text (from Phase 1) and template content are sent to the Secretary Service (<code>/transformer/template</code> endpoint)</li> <li>The LLM analyzes the document content according to the system prompt</li> <li>The LLM extracts metadata fields defined in the template frontmatter</li> <li> <p>Returns structured JSON with all metadata fields</p> </li> <li> <p>Metadata Sources (as defined in template system prompts):</p> </li> <li>Document content: Headings, text, TOC, metadata sections</li> <li>Filename: Parsed for author, year, title, topic, source, issue, status</li> <li>Directory path: Extracted for document type, series/journal, project, region</li> <li> <p>Acronym mapping: Resolves abbreviations from filename/path/document</p> </li> <li> <p>Response Processing:</p> </li> <li>The Secretary Service returns <code>structured_data</code> as JSON</li> <li>This JSON is normalized and converted to YAML frontmatter</li> <li> <p>Fields are validated and cleaned (e.g., <code>shortTitle</code> max 40 chars, slug normalization)</p> </li> <li> <p>Chapter Analysis (if chapters missing after template):</p> </li> <li>If the template didn't extract chapters, an additional analysis step runs</li> <li>Calls internal <code>/api/chat/{libraryId}/analyze-chapters</code> endpoint</li> <li>Merges detected chapters with any existing chapters</li> <li> <p>Extracts page numbers from <code>--- Seite N ---</code> markers in the text</p> </li> <li> <p>Pages Reconstruction:</p> </li> <li>Important: The <code>pages</code> field is never computed by the template/LLM</li> <li>Always reconstructed from <code>--- Seite N ---</code> markers in the Markdown body</li> <li>Extracts the highest page number found in the document</li> </ol> <p>Example Flow: <pre><code>Extracted Text (Phase 1)\n    \u2193\nTemplate Content (from MongoDB)\n    \u2193\nSecretary Service /transformer/template\n    \u2193 (LLM analyzes text + template instructions)\nStructured JSON Response\n    \u2193 (normalize &amp; validate)\nYAML Frontmatter\n    \u2193 (merge with existing metadata)\nFinal Markdown with Frontmatter\n</code></pre></p>"},{"location":"use-cases/file-transformation-pdf.html#phase-3-ingestion-rag","title":"Phase 3: Ingestion (RAG)","text":"<ul> <li>What happens: Markdown \u2192 Vector storage, MongoDB</li> <li>Images: Uploaded to Azure Storage for frontend access</li> <li>Result: Document is searchable via RAG (Retrieval Augmented Generation)</li> <li>Note: Only executed in asynchronous mode. In synchronous mode, ingestion must be triggered separately if needed.</li> <li>Note: Only executed in asynchronous mode. In synchronous mode, ingestion must be triggered separately if needed.</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html#result-structure","title":"Result Structure","text":"<p>The structure depends on whether images are extracted and which execution mode was used:</p>"},{"location":"use-cases/file-transformation-pdf.html#shadow-twin-directory-when-images-are-present","title":"Shadow-Twin Directory (when images are present)","text":"<p>If images are extracted, a Shadow-Twin directory is created:</p> <p>Asynchronous mode (two files): <pre><code>.document.pdf/\n\u251c\u2500\u2500 document.md          (Transcript - Phase 1 output, no frontmatter)\n\u251c\u2500\u2500 document.de.md       (Transformed - Phase 2 output, with frontmatter)\n\u251c\u2500\u2500 page-001.png        (Extracted images)\n\u251c\u2500\u2500 page-002.png\n\u2514\u2500\u2500 ...\n</code></pre></p> <p>Synchronous mode (one file): <pre><code>.document.pdf/\n\u251c\u2500\u2500 document.de.md       (Transformed - Phase 1+2 combined output, with frontmatter)\n\u251c\u2500\u2500 page-001.png        (Extracted images)\n\u251c\u2500\u2500 page-002.png\n\u2514\u2500\u2500 ...\n</code></pre></p>"},{"location":"use-cases/file-transformation-pdf.html#shadow-twin-files-when-no-images","title":"Shadow-Twin Files (when no images)","text":"<p>If no images are extracted, files are saved directly next to the PDF:</p> <p>Asynchronous mode (two files): <pre><code>document.pdf\ndocument.md          (Transcript - Phase 1 output, no frontmatter)\ndocument.de.md       (Transformed - Phase 2 output, with frontmatter)\n</code></pre></p> <p>Synchronous mode (one file): <pre><code>document.pdf\ndocument.de.md       (Transformed - Phase 1+2 combined output, with frontmatter)\n</code></pre></p> <p>For more detailed information about the Shadow-Twin structure, see the Shadow-Twin Architecture Documentation.</p>"},{"location":"use-cases/file-transformation-pdf.html#file-naming-convention","title":"File Naming Convention","text":"<ul> <li>Transcript File (<code>document.md</code>): </li> <li>Created after Phase 1 (Extract) in asynchronous mode only</li> <li>Contains extracted text without frontmatter</li> <li>No language suffix (original language of source)</li> <li> <p>Not created in synchronous mode (phases are combined)</p> </li> <li> <p>Transformed File (<code>document.de.md</code>):</p> </li> <li>Created after Phase 2 (Template) in asynchronous mode</li> <li>Created after Phase 1+2 (combined) in synchronous mode</li> <li>Contains text with frontmatter and metadata</li> <li>With language suffix (target language for transformation)</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html#parameters","title":"Parameters","text":"<ul> <li><code>includeOcrImages</code>: Request Mistral OCR images as Base64 (default: <code>true</code> for Mistral OCR)</li> <li><code>includePageImages</code>: Extract PDF pages as images and return as ZIP archive (default: <code>true</code> for Mistral OCR)</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html#tips","title":"Tips","text":"<ul> <li>Shadow Twins are automatically linked with the original</li> <li>Transformation runs in the background - you can continue working</li> <li>Errors are displayed in an error message</li> <li>Both transcript and transformed files can coexist (different names)</li> <li>Shadow-Twin directory is hidden (starts with <code>.</code>)</li> </ul>"},{"location":"use-cases/file-transformation-pdf.html#further-information","title":"Further Information","text":"<ul> <li>Shadow-Twin Architecture Documentation</li> <li>PDF Transformation Phases</li> <li>Transform Service Documentation</li> <li>Batch Operations for multiple files</li> </ul>"},{"location":"use-cases/library-setup.html","title":"Library Setup","text":""},{"location":"use-cases/library-setup.html#what-is-achieved","title":"What is achieved?","text":"<p>Create a new library to organize your knowledge. Libraries serve as containers for documents, media files, and transformed content.</p>"},{"location":"use-cases/library-setup.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Authenticated user</li> <li>Access to storage provider (Local Filesystem or OneDrive)</li> </ul>"},{"location":"use-cases/library-setup.html#steps","title":"Steps","text":"<ol> <li>Go to Settings \u2192 Library</li> <li>Click \"Create New Library\" (if no library exists yet)</li> <li>Fill out the form:</li> <li>Name: Enter a meaningful name (at least 3 characters)</li> <li>Storage Type: Choose between \"Local\" (local filesystem) or \"OneDrive\"</li> <li>Storage Path: Enter the path where files should be stored</li> <li>Description (optional): Short description of the library</li> <li>Configure the transcription strategy:</li> <li>Shadow Twin: Transformed files are saved as separate Markdown files</li> <li>Database: Transcripts are stored in the database</li> <li>Click \"Save\"</li> </ol>"},{"location":"use-cases/library-setup.html#result","title":"Result","text":"<p>A new library is created and can be used for files. The library appears in the Library Switcher and can be selected as the active library.</p>"},{"location":"use-cases/library-setup.html#further-information","title":"Further Information","text":"<ul> <li>Library Module Documentation</li> <li>Storage Provider Concepts</li> </ul>"},{"location":"use-cases/publishing.html","title":"Publishing &amp; Gallery","text":""},{"location":"use-cases/publishing.html#what-is-achieved","title":"What is achieved?","text":"<p>Publish your library publicly so others can access and explore your knowledge base. Create a public gallery with a custom URL, API access, and configurable display settings.</p>"},{"location":"use-cases/publishing.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Active library configured</li> <li>Library owner permissions</li> </ul>"},{"location":"use-cases/publishing.html#steps","title":"Steps","text":"<ol> <li>Go to Settings \u2192 Public</li> <li>Enable \"Public Library\" toggle</li> <li>Configure public settings:</li> <li>Slug Name: URL-friendly identifier (lowercase, numbers, hyphens only)</li> <li>Public Name: Display name for your library</li> <li>Description: Public description of your library</li> <li>Icon: Choose an icon from common options (optional)</li> <li>Configure gallery display:</li> <li>Headline: Main headline for the gallery page</li> <li>Subtitle: Subtitle text</li> <li>Description: Gallery description</li> <li>Filter Description: Help text for filters</li> <li>Generate API Key (if needed for programmatic access)</li> <li>Click \"Save\"</li> <li>Your library is now accessible at: <code>/public/[slug-name]</code></li> </ol>"},{"location":"use-cases/publishing.html#result","title":"Result","text":"<p>Your library is publicly accessible. Visitors can browse documents, use the chat interface, and explore your knowledge base without authentication.</p>"},{"location":"use-cases/publishing.html#tips","title":"Tips","text":"<ul> <li>The slug name must be unique across all public libraries</li> <li>API keys provide programmatic access to your library</li> <li>Gallery settings customize the public-facing interface</li> <li>You can disable public access at any time</li> </ul>"},{"location":"use-cases/publishing.html#further-information","title":"Further Information","text":"<ul> <li>Library Module Documentation</li> <li>Public Publishing Settings</li> </ul>"},{"location":"use-cases/web-scraping.html","title":"Web Scraping &amp; Event Import","text":""},{"location":"use-cases/web-scraping.html#what-is-achieved","title":"What is achieved?","text":"<p>Scrape web content and import event data (conferences, workshops, talks) into your library. Extract structured data from web pages, convert them to Markdown format, and organize them by events and tracks.</p>"},{"location":"use-cases/web-scraping.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Active library selected</li> <li>Event Monitor access</li> <li>Event URL or web page with structured content</li> </ul>"},{"location":"use-cases/web-scraping.html#steps","title":"Steps","text":"<ol> <li>Navigate to Event Monitor page</li> <li>Click \"Create Track\" to start a new batch</li> <li>Enter event information:</li> <li>Event Name: Name of the event/conference</li> <li>Track Name: Track or session category</li> <li>Source URL: URL of the web page to scrape</li> <li>Configure scraping options:</li> <li>Select target language for transformation</li> <li>Choose template for structured output (optional)</li> <li>Start the scraping process</li> <li>Monitor progress in the Event Monitor:</li> <li>View job status (pending, running, completed, failed)</li> <li>Filter by event name</li> <li>Check individual job details</li> <li>After completion: Sessions are transformed to Markdown files in your library</li> </ol>"},{"location":"use-cases/web-scraping.html#result","title":"Result","text":"<p>Event sessions are imported as structured Markdown files organized by event and track. Each session contains metadata, transcripts (if available), and associated media files.</p>"},{"location":"use-cases/web-scraping.html#tips","title":"Tips","text":"<ul> <li>Use the Event Filter to focus on specific events</li> <li>Batch operations allow processing multiple tracks simultaneously</li> <li>Failed jobs can be retried individually</li> <li>Archive completed batches for organization</li> </ul>"},{"location":"use-cases/web-scraping.html#further-information","title":"Further Information","text":"<ul> <li>Event Job System Documentation</li> <li>Batch Operations for multiple files</li> </ul>"}]}